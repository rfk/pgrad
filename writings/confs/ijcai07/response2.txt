
While knowledge can indeed be difficult to obtain if agents cannot observe
many actions, our approach offers two ways to overcome this problem:

(1) increasing the ability of agents to observe actions performed
by others increases the number of fluents that can be known
(2) "change actions" (section 3.3) can model agents knowing that the
value of a fluent has changed while not directly observing the action
causing the change.

The ability to explicitly make such tradeoffs is a powerful feature of
our approach.

We also feel that our technique of basing agents' mental states on
explicit observation histories will be useful for modelling belief
as well as knowledge.

p2) We should explicitly state that we are working with standard sitcalc
theories of action, as used by Reiter, Levesque et.al, and clarify that we
must assume significant background knowledge (possibility of concurrent
actions, foundational axioms, s < s' notation, etc) due to space constraints.

p4) Some issues with parentheses and several typos affect the meaning of
our axioms and we welcome your comprehensive list. Of particular
importance is the carelessly ommitted s<=s" conjunct in Unobs and
correct precedence between exists/implies:

  exists o. Observations(agt,c,s)=o and (o\={} -> X)

These are easily remedied.

p5) We should clarify that P_D always produces a regressible formula. Eq10
simply explains the meaning of P_D, while a seperate paper details how to
calculate it.


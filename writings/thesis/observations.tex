

\chapter{Observations and Views}

\label{ch:observations}

This chapter develops an explicit representation of the local perspective
of each agent, so that we can approach reasoning and planning in asynchronous
domains in a systematic way. Existing work on multi-agent domains
in the situation calculus has left this the local perspective largely
implicit; for example, it is customary to introduce different kinds
of sensing or communicating actions by directly modify the axioms
that define the dynamics of knowledge \citep{scherl03sc_knowledge,Lesperance99sitcalc_approach}.
We choose instead to reify the local perspective of each agent by
explicitly talking about what it has observed.

The basic idea is as follows: each occurrence of an action results
in an agent making a set of \emph{observations}. Every situation then
corresponds to a local \emph{view} for that agent: the sequence of
all its observations, excluding cases where the set of observations
was empty.

By having views as explicit terms in the logic, we are then in a position
to ensure that agents only reason and act based on their local local
information. Having factored out the precise details of each agent's
local view, we can develop reasoning techniques and tools that can
be applied in a variety of different domains. To demonstate the appeal
of this decoupling, we show how several different kinds of obserability
and communication can be modelled using our approach. The techniques
in subsequent chapters that build off this foundation - our planning
formalism based on joint executions, our account of knowledge with
hidden actions, our regression rule for common knowledge - can then
be applied without modification in any of these domains.

The chapter begins with some additional background material, discussing
how the information available to each agent is traditionally modelled
in the situation calculus. We then define the notion of observations
and views, and discuss how they can be specified within the structure
of a basic action theory. Section TODO discusses how some common domain
dynamics can be modelled using observations and views, while Section
TODO demonstrates the power and flexibility of the approach by axiomatising
more complex domains that have not previously been approached in the
situation calculus.


\section{Background}

In many single-agent applications of the situation calculus, there
is no need to consider the local perspective of the agent -- since
the agent has complete knowledge and is the only entity acting in
the world, it's local information is precisely equivalent to the global
information about the state of the world. It's local perspective is
simply the current situation.

If the agent has incomplete knowledge of the state of the world, it
may need to perform \emph{sensing actions} to obtain additional information.
An additional sort \noun{Result }is added to $\mathcal{L}_{sitcalc}$,
along with an action description function $SR(a,s)=r$ axiomatising
the result returned by each action. The agent's local perspective
on the world is then given by a \emph{history}, a sequence of pairs
$a\#r$ giving each actions performed and its corresponding sensing
result.

When sensing actions are added to IndiGolog \citep{giacomo99indigolog},
the agent must plan its execution using this history rather than a
raw situation term. This is accomplished without any modifications
to the underlying theory of action, by handling the history as a purely
meta-level structure and modifying the way queries are posed.

TODO: check the names of these macros

First, a pair of macros are defined to convert a history into proper
sentences of the situation calculus that capture the information it
contains. The macro $\mathbf{end}$ gives the situation term corresponding
to a history, while the macro $\mathbf{res}$ produces a formula asserting
that the sensing results were obtained. Let $\epsilon$ be the empty
history, then the definitions are:\begin{gather*}
\mathbf{end}[\epsilon]\isdef S_{0}\\
\mathbf{end}[(a\#r)\cdot h]\isdef do(a,\mathbf{end}[h])\\
\mathbf{res}[\epsilon]\isdef\top\\
\mathbf{res}[(a\#r)\cdot h]\isdef SR(a,\mathbf{end}[h])=r\,\wedge\,\mathbf{res}[h]\end{gather*}


Then, instead of asking whether a query holds at the current situation
$s$:

\[
\Dt\,\models\,\phi[s]\]


The agent asks whether the query holds given its current history $h$:\[
\Dt\cup\mathbf{res}[h]\,\models\,\phi[\mathbf{end}[h]]\]


We are aware of no works extending this meta-level handling of histories
to the multi-agent case.

While the history-based approach of \citep{giacomo99indigolog} allows
an agent to reason based on its local perspective, it is cumbersome
for reasoning \emph{about} that local perspective. Do determine whether
an agent \emph{knows} that a formula holds in a given situation, we
must explicitly specify the agent's history of sensing results for
that situation, which may not be available until run-time. This meta-level
approach is not suitable for rich epistemic reasoning, where we may
want to reason about what the agent (or a group of agents) will or
will not know after a series actions.

This kind of reasoning requires an explicit representation of what
the agent knows, which has been developed for the situation calculus
by \citet{scherl03sc_knowledge}. We will review such epistemic reasoning
in more detail in chapter \ref{ch:knowledge}, but for now we discuss
its use in axiomatising the local perspective of each agent.

The basic use of sensing results in determining an agents knowledge
is defined in \citep{scherl03sc_knowledge} by directly specifyng
this in the successor state axiom for a special {}``knowledge fluent''
$K$. As a variety of richer domains have been modelled using this
formalism, their particular accounts of the local information available
to each have been specified by directly modifying this successor state
axiom.

For example, when multiple agents are introduced in TODO, the successor
state axiom for $K$ is modified to ensure that an agent knows the
results of its own actions, but not the results generated by others.
When communication actions are introduced in TODO, the successor state
axiom for $K$ is modified to ensure that the agent's knowledge is
updated to include the communicated information.

TODO: knowledge with time - action\#time pairs are an ad-hoc version
of views.

In these works there is no explicit representation of the local perspective
of each agent -- rather, the information each agent recieves from
an action is specified only in terms of its effect on the agent's
knowledge. As we will discuss in the coming chapters, this can also
lead to subtle and unintuitive problems in the domain axiomatisation.

Our approach can be seen as a generalisation of the history-based
approach of \citep{giacomo99indigolog}, explicitly representing the
information available to each agent. However, we encode this information
as terms in the logic rather than in the meta-level reasoning machinery.
This allows us to construct a theory of knowledge using the same formalism.

TODO: more justification waffle here.


\section{Definitions}

We begin by defining the notion of an \emph{observation}, which is
fundamental to the entire approach\emph{.} This is simply an internal
notification that an agent receives when some action has occurred.

\begin{defnL}
[{Observations}] An observation is a notification event received
by an agent, making it aware of some change in the state of the world.
When an agent receives such a notification, we say that it {}``observed'',
{}``made'' or {}``perceived'' that observation. 
\end{defnL}
Since {}``observation'' is quite a loaded term, it is worth re-iterating
this point: observations are instantaneous \emph{events} generated
internally by each agent in response to actions occurring in the world.
We make no commitment as to how these events are generated, preferring
a clean delineation between the task of observing change and the dynamics
of knowledge update based on those observations.

The state of the world may only change in response to some action,
so observations can only be made as a result of some action. For simplicity
we assume that agents perceive observations instantaneously, i.e.
in the same instant as the actions that cause them.

To make this idea concrete, let us introduce an additional sort \noun{Observation}
to the language $\mathcal{L}_{sitcalc}$, for the moment without any
particular commitment towards what this sort will contain. We then
add an action description function of the following form to $\Dt_{ad}$:\[
Obs(agt,c,s)=o\]
 This function returns a set of observations, and should be read as
{}``when actions $c$ are performed in situation $s$, agent $agt$
will perceive $o$''. Using a set of observations allows an agent
to perceive any number of observations in response to an action occurrence
- perhaps several observations, perhaps none. When $Obs(agt,c,s)$
is the empty set, the agent makes no observations and the actions
$c$ are completely hidden.

The concept of a \emph{view} follows naturally - it is the sequence
of all the observations made by an agent as the world has evolved.

\begin{defnL}
[{Views}] An agent's view in a given situation $\mathrm{s}$
is the corresponding sequence of observations made by the agent as
a result of each action in $\mathrm{s}$, excluding those actions
for which no observations were made. 
\end{defnL}
We introduce another sort \noun{View} consisting of sequences of sets
of observations, with $\epsilon$ being the empty sequence and the
functional fluent $View$ giving the history of observations associated
with a particular situation. Since these definitions will not change
from one domain to another, they are added to the foundational axioms
$\Sigma$:\begin{align}
Init(s)\,\rightarrow & \, View(agt,s)=\epsilon\nonumber \\
Obs(agt,c,s)=\{\}\,\rightarrow & \, View(agt,do(c,s))=View(agt,s)\nonumber \\
Obs(agt,c,s)\neq\{\}\,\rightarrow & \, View(agt,do(c,s))=Obs(agt,c,s)\cdot View(agt,s)\label{eq:view_defn}\end{align}


The key point here is that the agent's view excludes cases where $Obs(agt,c,s)$
is empty. Thus, the agent may not know how many actions have been
performed in the world. As discussed in the introduction, this property
is fundamentical to modelling asynchronous domains. Mirroring the
terminology of \citet{vanBentham06tree_of_knowledge}, we can now
explicitly define what it means for a domain to be \emph{synchronous.}

\begin{defnL}
[{Synchronous~Action~Theory:}] A basic action theory $\Dt$
is synchronous if every agent observes something whenever an action
occurs:\[
\Dt\,\models\,\forall agt,c,s:\, Poss(c,s)\,\rightarrow Obs(agt,c,s)\neq\{\}\]

\end{defnL}
Observations and views can be seen as localised analogues of actions
and situations respectively. An action is a global event that causes
the state of the world to change, while an observation is an internal
event that causes an agent's knowledge of the state of the world to
change. Similarly, a situation represents a complete, global history
of all the actions that have occurred in the world, while a view is
an agent's local history of all the observations it has made. The
situation is an omniscient perspective on the world, the view a local
perspective. This distinction will be fundamental to the new techniques
we develop throughout this thesis.

Before proceeding with some example axiomatisations, let us briefly
foreshadow how observations and views will be used in the coming chapters.
In chapter \ref{ch:jointexec}, we will define a partially-ordered
action structure to be generated when planning a MIndiGolog execution.
Since agents can only be expected to act based on their local information,
we will require that if $s$ and $s'$ are two situations that could
be reached during execution of the plan, and $View(agt,s)=View(agt,s')$,
then the agent's next action in both situations must be the same.

In chapter \ref{ch:knowledge}, we formalise the notion that an agent's
knowledge should be based only on its local information. So if the
agent belives that the world might be in situation $s$, then it must
also consider possible any other situation $s'$ such that $View(agt,s)=View(agt,s')$.
By decoupling the axiomatisation of knowledge from the specific details
of how each action affects the agent's local information, we develop
a very general formalism that can be applied without modification
in a wide variety of domains.


\section{Axiomatising Observations: some simple cases}

We now proceed to show how these definitions can be used to model
a variety of common cases from the situation calculus literature.


\subsection{Public Actions}

By far the most common assumption about the observaility of actions
is that {}``all actions are public'', which can be rephrased as
{}``when an action occurs, all agents will observe that action''.
Letting the \noun{Observations }sort contain \noun{Action }terms,
this can be captured using the following axiom to define $Obs$:\[
a\in Obs(agt,c,s)\,\equiv\, a\in c\]


When sensing actions are included, it is typically assumed that only
the performing agent as access to the sensing results. This can be
modelled by extending the \noun{Observations} sort to contain \noun{Action\#Result}
pairs, and including the following in the definition for $Obs$:\[
a\#r\in Obs(agt,c,s)\,\equiv\, a\in c\wedge actor(a)=agt\wedge SR(a,s)=r\]


It should be clear that these definitions capture the intuition behind
this most common model of action observability. When we develop our
new axiomatisation of knowledge in chapter TODO, we will demonstrate
that these definitions provide an equivalent account to the standard
knowledge axioms defined by \citet{scherl03sc_knowledge}.

This approach leads to syncrhonous domains, since it entails the following:\[
Poss(c,s)\rightarrow Obs(agt,c,s)\neq\{\}\]



\subsection{Private Actions}

Another common model for action observability is to assume that {}``all
actions are private'', which can be rephrased as {}``when an action
occurs, only the performing agent will observe it''. This can be
modelled using the following axioms for $Obs$:

\[
a\in Obs(agt,c,s)\,\equiv\, a\in c\wedge actor(a)=agt\]


\[
a\#r\in Obs(agt,c,s)\,\equiv\, a\in c\wedge actor(a)=agt\wedge SR(a,s)=r\]


As noted in \citep{Lesperance99sitcalc_approach}, this approach means
that agents may need to consider arbitrarily-long sequences of hidden
actions. By explicitly formalising this situation, we proide the first
account of effective reasoning in such domains.


\subsection{Communicative Actions}

Communication in the situation calculus is tradionally modelled using
explitic communicative actions. These actions are axiomatised as per
standard actions, but special-case handling is introduced in the axioms
for knowledge in order to model their communicative effects.

The standard message is $inform(agt_{s},agt_{r},\phi)$, where the
sender $agt_{s}$ informs the reciever $agt_{r}$ of the truth of
some formula $\phi$. If we assert that only truthful speech acts
are allowed, this requires no further axiomatisation:\[
Poss(inform(agt_{s},agt_{r},\phi),s)\,\equiv\,\phi[s]\]


In \citep{shapiro01casl_feat_inter} encrypted speech acts are introduced,
to ensure that only the intended recipient of a message is able to
access its contents. While it would be straightforward to copy this
approach in our formalism, it is also unnecessary - we can directly
limit the accessibility of the message contents to the receiving agent
like so:\[
inform(sender,recver)\in Obs(agt,c,s)\,\equiv\,\exists m:\, inform(sender,recver,m)\in c\]
 \[
inform(sender,recver,m)\in Obs(agt,c,s)\,\equiv\, inform(sender,recver,m)\in c\wedge agt\in\{sender,recver\}\]



\section{New Axiomatisations}

We now introduce some new axiomatisations of knowledge that have not
been dealt with explicitly in the situation calculus.


\subsection{Explicit Observability Axioms}

We now discuss one straightforward way to generalise our approach
for partial observability of actions. A new action description predicate
$CanObs(agt,a,s)$ is used to indicate that agent $agt$ would observe
action $a$ being performed in situation $s$. If $CanObs(agt,a,s)$
is false, then that action will be hidden. We can then formulate the
$Obs()$ function according to:\[
a\in Obs(agt,c,s)\equiv a\in c\wedge CanObs(agt,a,s)\]


There is also a subtle limitation in the standard handling of sensing
actions: only the agent performing a sensing action can be aware of
its result. Such a restriction is common but certainly not universal.
For example, if an agent waiting for a train activates a speaker to
determine when it will arrive, the result of this sensing action would
provide information to any other agent within earshot. To generalise
the formalism, an analogous predicate $CanSense(agt,a,s)$ is used
to indicate when sensing information is available to an agent. We
then include bare action terms in an agent's observations when it
observes the action but not its result, and \emph{$Action\#Result$}
terms when it also senses the result:\begin{gather*}
a\in Obs(agt,c,s)\equiv a\in c\wedge CanObs(agt,a,s)\wedge\neg CanSense(agt,a,s)\\
a\#r\in Obs(agt,c,s)\equiv a\in c\wedge SR(a,s)=r\wedge CanObs(agt,a,s)\wedge CanSense(agt,a,s)\end{gather*}


We feel that this formulation provides a good balance between simplicity
and expressiveness; it allows the observability of actions to vary
according to the state of the world, but provides agents with a complete
description of each action that they are capable of observing.


\subsection{Observing the Effects of Actions}


\subsection{Delayed Communication}

Delayed communication is typically modelled using separate $send$
and $recv$ actions. The $recv$ action can be modelled as a natural
action as introduced in Section TODO, since it must occur unless something
happens to prevent it.

This axiomatisation mirrors the standard account of long-running tasks,
with a fluent $PendingMessage(agt_{s},agt_{r},m,t)$ indicating that
some message is pending and will be delivered at time $t$. We have:\[
natural(recv(agt_{s},agt_{r},m))\]
 \begin{multline*}
PendingMessage(agt_{s},agt_{r},m,t_{m},do(c\#t,s))\,\equiv send(agt_{s},agt_{r},m)\in c\wedge t_{m}=t+delay(agt_{s},agt_{r},m,s)\\
\vee PendingMessage(agt_{s},agt_{r},m,t_{m},s)\wedge\left(recv(agt_{s},agt_{r},m)\not\in c\vee t\neq t_{m}\right)\end{multline*}
 \[
Poss(recv(agt_{s},agt_{r},m)\#t,s)\equiv PendingMessage(agt_{s},agt_{r},m,t,s)\]


Thus a $send$ action causes the message to become pending, with its
delivery time determined by the function $delay$. Once the delay
time has elapsed, the natural action $recv$ will be triggered and
the message delivered.

If the agents have incomplete knowledge about the $delay$ function,
this can easily model domains in which the message delay is unpredicatble.


\subsection{Delayed Observations}

Delayed observations can be modelled in a simlar way to delayed communications.

TODO: OK, so model them.


\section{Discussion}

In this chapter we have developed a new account of the local perspective
of each agent as the world evolves. We have shown that it can easily
model the standard, implicit accounts found in the existnig situation
calculus literature, as well as several more compelx cases which have
not, to our knoweldge, been treated.

This approach clearly paralles the view-based approach to knowlege
of TODO:refs, although we have not yet axiomatised an agent's knowledge
in terms of its view - this will be done in chapter TODO.


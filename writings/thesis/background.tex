

\chapter{Background}

\label{ch:background}

This chapter covers general background material for the thesis, and
serves as a brief literature review. More specific background material
may be found at the beginning of subsequent chapters.

We begin by introducing the base language of the situation calculus
in section \ref{sec:Background:The-Situation-Calculus}, along with
the {}``cooking agents'' example domain which will be used throughout
the thesis. Section \ref{sec:Background:Golog} introduces the Golog
family of programming languages, which are the standard formalism
for representing complex tasks in the situation calculus. Reasoning
about knowledge is covered in section \ref{sec:Background:Epistemic-Reasoning}.
Finally, section \ref{sec:Background:Mozart/Oz} introduces the Mozart
programming system, which forms the basis of our implementation. Basic
familiarity with with formal logic (including first-order, second-order,
and modal logic) is assumed throughout; readers requiring background
on such material may find a gentle introduction in \citep{kelly96logic}
and a more detailed treatment in \citep{fitting96fol_book,blakcburn02modal_logic}.

While there are no new results presented in this chapter, it does
introduce some novel notation which will be needed later in the thesis.
It is introduced here to maintain consistency of the presentation.


\section{The Situation Calculus\label{sec:Background:The-Situation-Calculus}}

The situation calculus is a formalism for describing and reasoning
about dynamic worlds. It was first introduced by \citet{McCHay69sitcalc}
and has since been significantly expanded and formalised \citep{reiter91frameprob,pirri99contributions_sitcalc}.
We use the particular variant due to Reiter et. al. at the University
of Toronto, sometimes called the {}``Toronto school'' or {}``situations-as-histories''
version \citep{levesque98sc_foundations,pirri99contributions_sitcalc}.

A brief overview is presented below. Readers familiar with the situation
calculus should note our generalised characterisation of the background
theory $\Dt_{bg}$, our generalisation of the $Poss$ fluent to action
description predicates, and the parameterised {}``future situation''
predicate $s<_{\alpha}s'$.


\subsection{Notation\label{sec:Background:SC:Notation}}

The language $\mathcal{L}_{sitcalc}$ of the situation calculus is
a many-sorted language of first-order logic with equality, augmented
with a second-order induction axiom, containing the following disjoint
sorts:

\begin{itemize}
\item \emph{\noun{Action}} terms are functions denoting individual instantaneous
events that can cause the state of the world to change; 
\item \noun{Situation} terms are histories of the actions that have occurred
in the world, with the initial situation represented by $S_{0}$ and
successive situations built using the function $do\,:\, Action\times Situation\rightarrow Situation$; 
\item \noun{Object} terms represent any other object in the domain. 
\end{itemize}
\emph{Fluents} are predicates or functions that represent properties
of the world that may change between situations, and so take a situation
term as their final argument. Predicates and functions that do not
take a situation term are called \emph{rigid}. We use the term \emph{primitive
fluent} to describe fluents that are directly affected by actions,
while non-primitive fluents can be expressed as logical combinations
of other fluents. No functions other than $S_{0}$ and $do$ take
values of sort \noun{Situation.}

$\mathcal{L}_{sitcalc}$ contains the standard alphabet of logical
connectives, countably infinitely many variables of each sort, countably
infinitely many predicates of each arity, etc; for a complete definition,
consult the foundational paper by \citet{pirri99contributions_sitcalc}.
We follow standard naming conventions for the situation calculus:
upper-case roman names indicate constants; lower-case roman names
indicate variables; greek names indicate meta-variables or formula
templates. All axioms universally close over their free variables
at outermost scope. The notation $\vars{t}$ indicates a vector of
terms of context-appropriate arity and type. The connectives $\wedge$,
$\neg$, $\exists$ are taken as primitive, with $\vee$, $\rightarrow$,
$\equiv$, $\forall$ defined in the usual manner.

In multi-agent domains it is customary to introduce the sort \noun{Agent
}as a sub-sort of \noun{Object} to explicitly represent the agents
operating in the world, and we will do so here. The first argument
of each action term gives the performing agent.

\medskip{}


For concreteness, let us present some formulae from an example domain
that will be used throughout the thesis. In the {}``cooking agents''
domain a group of robotic chefs inhabit a kitchen containing various
ingredients and utensils, and they must cooperate to prepare a meal.
Some example statements from this domain include {}``Ann is not holding
the knife initially'', {}``Bob is holding the knife after he picks
it up'' and {}``It is only possible to pick up an object if nobody
is holding it''. Formally:\begin{gather*}
\neg Holding(Ann,Knife1,S_{0})\\
Holding(Bob,Knife1,do(pickup(Bob,Knife1),S_{0}))\\
Poss(pickup(agt,obj),s)\equiv\neg\exists agt_{2}:\, Holding(agt_{2},obj,s)\end{gather*}


\medskip{}


Here $Holding$ is a primitive fluent while $Poss$ is defined in
terms of $Holding$. As we shall see, the behavior of two fluents
would be axiomatised quite differently.

\medskip{}
Complex properties of the state of the world are represented using
\emph{uniform formulae}. These are basically logical combinations
of fluents referring to a common situation term. For the moment we
restrict ourselves to \emph{objective} uniform formulae; the complete
definition includes statements about knowledge and will be introduced
following that material.

\begin{defnL}
[{Uniform~Terms}] Let $s$ be a fixed situation term, $r$
an arbitrary rigid function symbol, $f$ an arbitrary fluent function
symbol, and $x$ a variable that is not of sort \noun{Situation}.
Then the terms uniform in $s$ are the smallest set of syntactically-valid
terms satisfying:\[
\tau\,::=s\,|\, x\,|\, r(\vars{\tau})\,|\, f(\vars{\tau},s)\]

\begin{defnL}
[{Objective~Uniform~Formulae}] Let $s$ be a fixed situation
term, $R$ an arbitrary rigid predicate, $F$ an arbitrary fluent
predicate, $\tau$ an arbitrary of term uniform in $s$, and $x$
an arbitrary variable that is not of sort \noun{Situation}. Then the
objective formulae uniform in $s$ are the smallest set of syntactically-valid
formulae satisfying:\[
\phi::=F(\vars{\tau},s)\,|\, R(\vars{\tau})\,|\,\tau_{1}=\tau_{2}\,|\,\phi_{1}\wedge\phi_{2}\,|\,\neg\phi\,|\,\exists x:\phi\]

\end{defnL}
\end{defnL}
The meta-variable $\phi$ is used throughout to refer to an arbitrary
uniform formula. Since they represent properties of the world, it
is frequently useful to evaluate uniform formulae at several different
situation terms. The notation $\phi[s']$ represents a uniform formula
with the particular situation $s'$ inserted into all its fluents.
We will often suppress the situation term in $\phi$ to simplify the
presentation, using $\phi^{-1}$ to represent a uniform formula with
the situation argument removed from all its fluents. For example,
if $\phi=Holding(Ann,Knife,s)\wedge Holding(Bob,Bowl,s)$, then we
have:\begin{gather*}
\phi[s']\,=\, Holding(Ann,Knife,s')\wedge Holding(Bob,Bowl,s')\\
\phi^{-1}\,=\, Holding(Ann,Knife)\wedge Holding(Bob,Bowl)\end{gather*}


Note that these are strictly meta-level operations, corresponding
to possibly quite complex sentences from the logic. They are \emph{not
}terms from the logic itself.


\subsection{Axioms\label{sec:Background:SC:Axioms}}

The dynamics of a particular domain are captured by a set of sentences
from $\mathcal{L}_{sitcalc}$ called a \emph{basic action theory}.
Queries about the behaviour of the world are posed as logical entailment
queries relative to this theory.

\begin{defnL}
[{Basic~Action~Theory}] A basic action theory, denoted
$\Dt$, is a set of situation calculus sentences (of the specific
syntactic form outlined below) describing a particular dynamic world.
It consists of the following disjoint sets: the foundational axioms
of the situation calculus ($\Sigma$); action description axioms defining
preconditions etc for each action ($\Dt_{ad}$); successor state axioms
describing how primitive fluents change between situations ($\Dt_{ssa}$);
axioms describing the value of primitive fluents in the initial situation
($\Dt_{S_{0}}$); and axioms describing the static background facts
of the domain ($\Dt_{bg}$):\[
\Dt=\Sigma\cup\Dt_{ad}\cup\Dt_{ssa}\cup\Dt_{S_{0}}\cup\Dt_{bg}\]

\end{defnL}
These axioms must satisfy some simple consistency criteria to constitute
a valid domain description; see \citep{pirri99contributions_sitcalc}
for the detail. We assume an arbitrary, but fixed, basic action theory.


\subsubsection{Background Axioms}

The set $\Dt_{bg}$ characterises the static aspects of the domain,
and contains all axioms defining rigid predicates or functions. It
contains unique names axioms asserting that action terms with different
types or arguments are in fact different, e.g.:\begin{gather*}
pickup(agt,obj)\neq drop(agt,obj)\\
pickup(agt_{1},obj_{1})=pickup(agt_{2},obj_{2})\,\rightarrow\, agt_{1}=agt_{2}\,\wedge\, obj_{1}=obj_{2}\end{gather*}


It also contains domain closure axioms for the sorts \noun{Action,
Agent} and \noun{Object}, and defines the function $actor(a)$ to
give the agent performing an action.


\subsubsection{Successor State Axioms}

The set $\Dt_{ssa}$ contains one \emph{successor state axiom} for
each primitive fluent in the domain, providing a monotonic solution
to the frame problem for that fluent \citep{reiter91frameprob}. These
axioms have the following general form: \[
F(\vars{x},do(a,s))\equiv\Phi_{F}^{+}(\vars{x},a,s)\,\,\vee\,\, F(\vars{x},s)\wedge\neg\Phi_{F}^{-}(\vars{x},a,s)\]


Here $\Phi_{F}^{+}$ and $\Phi_{F}^{-}$ are formulae uniform in $s$.
This may be read as {}``$F$ is true after performing $a$ if $a$
made it true, or it was previously true and $a$ did not make it false''.
For example, the $Holding$ fluent may be specified using:\begin{flalign*}
Holding(agt,obj,do(a,s))\,\equiv\,\, & a=pickup(agt,obj)\\
 & \vee\, Holding(agt,obj,s)\wedge a\ne drop(agt,obj)\end{flalign*}



\subsubsection{Action Description Predicates}

The set $\Dt_{ad}$ generalises the standard \emph{action precondition
axioms} \citep{pirri99contributions_sitcalc} to define fluents describing
various aspects of the performance of an action, which we call \emph{action
description predicates}. The predicate $Poss(a,s)$ is the canonical
example, indicating whether it is possible to perform an action in
a given situation. The set $\Dt_{ad}$ contains a single axiom of
the form $Poss(a,s)\equiv\Pi_{Poss}(a,s)$ defining the complete set
of preconditions for the action variable $a$, where $\Pi_{Poss}(a,s)$
is uniform in $s$.

Note that this is a slight departure from the standard approach of
\citep{pirri99contributions_sitcalc}, in which the preconditions
for each action type are specified individually. The more restrictive
approach presented here embodies a domain-closure assumption on the
available actions. For example, if there are finitely many action
types then $\Pi_{Poss}$ is simply the disjunction of the preconditions
for each action type. The single-axiom form is necessary when quantifying
over {}``all possible actions'' and has been widely used in the
literature \citep{vassos08progression_future_queries,savelli06sc_quantum_levels}. 

In principle, any number of predicates and functions can be defined
in this way - a common example is the sensing-result function $SR(a,s)$
introduced in section TODO - and the general notation of action description
predicates allows us to treat all of them uniformly. We will use the
meta-variable $\alpha$ for an arbitrary action description predicate.


\subsubsection{Foundational Axioms}

The foundational axioms $\Sigma$ ensure that situations form a branching-time
account of the world state. There is a distinguished situation $S_{0}$
called the \emph{initial situation}. Situations in general form a
tree structure with the initial situation at the root and $do(a,s)$
constructing the successor situation resulting when the action $a$
is performed in $s$. All situations thus produced are distinct:\[
do(a_{1},s_{1})=do(a_{2},s_{2})\,\rightarrow\, a_{1}=a_{2}\,\wedge\, s_{1}=s_{2}\]


We abbreviate the performance of several successive actions by writing:\[
do([a_{1},\dots,a_{n}],s)\,\isdef\, do(a_{n},do(\dots,do(a_{1},s)))\]


The relation $s\sqsubset s'$ indicates that $s'$ is in the future
of $s$ and is defined as follows:\begin{gather*}
\neg(s\sqsubset S_{0})\\
s\sqsubset do(a,s')\equiv s\sqsubseteq s'\end{gather*}


Here $s\sqsubseteq s'$ is the standard abbreviation for $s\sqsubset s'\vee s=s'$.
There is also a second-order induction axiom asserting that all situations
must be constructed in this way, which is needed to prove statements
that universally quantify over situations:\[
\forall P:\,\left[P(S_{0})\wedge\forall s,a:\,\left(P(s)\rightarrow P(do(a,s))\right)\right]\,\rightarrow\,\forall s:\, P(s)\]


The notation for {}``in the future of'' can be extended to consider
only those futures in which all actions satisfy a particular action
description predicate. We include a relation $<_{\alpha}$ for each
action description predicate $\alpha$, with the following definitions:\begin{gather*}
\neg\left(s<_{\alpha}S_{0}\right)\\
s<_{\alpha}do(a,s')\equiv s\leq_{\alpha}s'\wedge\alpha(a,s')\end{gather*}


The \emph{legal situations} are those in which every action was possible
to perform in the preceding situation. These are of fundamental importance,
as they are the only situations that could be reached in the real
world. The \emph{root} of a situation is the initial situation from
which it was constructed:\begin{gather*}
root(S_{0})=s\\
root(do(c,s))=root(s)\\
Legal(s)\,\equiv\, root(s)\leq_{Poss}s\end{gather*}



\subsubsection{Initial State Axioms}

The set $\Dt_{S_{0}}$ describes the actual state of the world before
any actions are performed. It is a collection of sentences uniform
in $S_{0}$ stating what holds in the initial situation.


\subsection{Reasoning}

One of the attractions of the situation calculus is the existence
of effective reasoning procedures for certain types of query. These
are generally based on syntactic manipulation of a query into a form
that is more amenable to reasoning -- for example, because it can
be proven without using some of the axioms from $\Dt$.


\subsubsection{Types of Reasoning}

TODO: reasoning in the {}``fluent domain''

In the general case, answering a query about a basic action theory
$\Dt$ is a theorem-proving task in second-order logic (denoted SOL)
due to the induction axiom included in the foundational axioms:\[
\Dt\models_{SOL}\psi\]
 This is clearly problematic for effective automated reasoning, but
fortunately there exist particular syntactic forms for which some
of the axioms in $\mathcal{D}$ are not required.

If a query existentially quantifies over situation terms, it can be
answered without the induction axiom (denoted $I$) and thus using
only first-order logic (FOL) \citep{pirri99contributions_sitcalc}:\[
\Dt\models_{SOL}\exists s:\,\psi(s)\,\,\,\,\mathrm{iff}\,\,\,\,\Dt-\{I\}\models_{FOL}\exists s:\,\psi(s)\]


In some instances it is possible to transform queries into forms where
more of the axioms from $\Dt$ can be ignored. For example, \citet{Lin94-StateConstraints}
show how to reduce some reasoning tasks to what we call \emph{static
domain reasoning}, where only the background axioms need to be considered:\[
\Dt_{bg}\models\forall s:\,\phi[s]\]


TODO: more on static domain reasoning.

Simpler still are queries uniform in the initial situation, which
can be answered using only first-order logic and a limited set of
axioms:\[
\mathcal{D}\models_{SOL}\phi[S_{0}]\,\,\,\,\,\mathit{\mathrm{iff}}\,\,\,\,\,\Dt_{S_{0}}\cup\Dt_{bg}\models_{FOL}\phi[S_{0}]\]


We call such reasoning \emph{initial} \emph{situation reasoning}.\emph{
}Since the axioms $\Dt_{S_{0}}\cup\Dt_{bg}$ often satisfy the closed-world
assumption, provers such as Prolog can be employed to handle this
type of query quite effectively.


\subsubsection{Regression}

TODO: regressing functional fluents\\


The principle tool for effective reasoning in the situation calculus
is the regression meta-operator $\Reg_{\Dt}$ \citep{pirri99contributions_sitcalc},
a syntactic manipulation that can transform a formula uniform in $do(a,s)$
into an equivalent formula that is uniform in $s$:\[
\Dt\,\models\,\phi[do(a,s)]\equiv\Reg_{\Dt}(\phi[do(a,s)])[s]\]


Its operation is defined by a set of \emph{regression rules} such
as those shown below.

\begin{defnL}
[{Regression~Operator}] Let $\phi$ be a formula uniform in $do(a,s)$,
$R$ be a rigid predicate $\alpha$ be an action description predicate
with axiom $\alpha(a,s)\equiv\Pi_{\alpha}(a,s)$ in $\Dt_{ad}$, and
$F$ be a primitive fluent with axiom $F(\vars{x},s)\equiv\Phi_{F}(\vars{x},s)$
in $\Dt_{ssa}$. Then the \emph{regression} of $\phi$, denoted $\Reg_{\Dt}(\phi)$,
is defined according to the following rules:\begin{flalign*}
\Reg_{\Dt}(\exists x:\,\phi)\isdef\, & \exists x:\,\Reg_{\Dt}(\phi)\\
\Reg_{\Dt}(\phi_{1}\wedge\phi_{2})\isdef\, & \Reg_{\Dt}(\phi_{1})\wedge\Reg_{\Dt}(\phi_{2})\\
\Reg_{\Dt}(\neg\phi)\isdef\, & \neg\Reg_{\Dt}(\phi)\\
\Reg_{\Dt}(Poss(a,s))\isdef\, & \Reg_{\Dt}(\Pi_{Poss}(a,s))\\
\Reg_{\Dt}(F(\vars{x},do(a,s)))\isdef\, & \Phi_{F}(\vars{x},s)\end{flalign*}
 
\end{defnL}
Each application of the regression operator replaces action description
predicates with their definitions from $\Dt_{ad}$ and primitive fluents
with their successor state axioms from $\Dt_{ssa}$, {}``unwinding''
a single action from each situation term in the query. Since $\Dt$
is fixed, we drop the subscript and simply write $\Reg$ for regression. 

Repeated applications of this operator, denoted by $\Reg^{*}$, can
transform a query about some future situation into a query about the
initial situation only, which is much easier to answer. The axioms
$\Dt_{ad}$ and $\Dt_{ssa}$ are essentially {}``compiled into''
the query. The trade-off is that the length of the regressed query
may be exponential in the length of $\phi$. While an efficiency gain
is not guaranteed, regression has proven a very effective technique
in practice \citep{levesque97golog,pirri99contributions_sitcalc}.

Note that we are using the single-step regression operator, as defined
in e.g. \citep{scherl03sc_knowledge}. It is also common to find a
single-pass version of the regression opeator, as defined in \citep{pirri99contributions_sitcalc},
which operates like $\Reg^{*}$ defined above. It is straightforward
to define the single-pass regression in terms of the single-step operator,
but not vice-versa, so we utilise the more primitive operator here.

When dealing with situation-suppressed uniform formulae, we will use
a two-argument operator $\Reg(\phi,a)$ to indicate the regression
of $\phi$ over the action $a$. It should be read as a shorthand
for $\Reg(\phi[do(a,s)])^{-1}$ using the situation-suppression operator
from section \ref{sec:Background:SC:Notation}.

One shortcoming of the regression operator is the potential for an
exponential growth in the length of the query \citep{reiter91frameprob}.
While this cannot be completely overcome in general, there are certain
restrictions that can be placed on the domain to ensure it is not
a problem. TODO: find references: context-free SSAs, local-effect
SSAs.


\subsubsection{Decidability}

Even given the use of regression to reduce the number of axioms required,
reasoning still requires first-order logic and is thus only semi-decidable
in general. Practical systems implemented on top of the situation
calculus typically enforce additional restrictions on the domain in
order to gain decidability. For example, implementations in Prolog
typically assume that the axioms about the initial situation satisfy
the closed-world assumption, so initial situation reasoning can be
performed using Prologs more effecient theorem proving instead of
a full first-order prover.

Another option is to assume the \noun{Action} and \noun{Object} domains
are finite, allowing static domain reasoning to be performed using
propositional logic, which is decidable \citep{giacomo99impl_robots,levesque04krr_book}.
Recent work by \citet{yu07twovar_sitcalc} shows how domains can be
restricted to the two-variable fragment of first-order logic, which
is also decidable.\\



\subsubsection{TODO: Progression}

While regression has proven quite an effective technique in practice,
it has an obvious shortcoming modelling domains with long histories
- the computation required to reason about the current state of the
world increases with each action performed.

An alternative approach is \emph{progression}, in which the initial
state of the world $\Dt_{S_{0}}$ is updated with each action performed
to give a new set of axioms about the current situation. The intuition
is that although this increase the upfront complexity when an action
is performed, this work is amortized over many queries about the updated
state. \citet{thielscher04case_for_progression} produced quite compelling
data that progression gives better runtime performance in domains
with many actions. Why, then, do we focus only on regression in this
paper?

The theoretical foundations of progression in the situation calculus
were laid out by \citet{reiter97progression} and come with an important
caveat: the progression of a first-order database is not always first-order
definable. While it is possible to define first-order progressions
of a database that are valid for restricted classes of query, a first-order
progressed database cannot be complete \citep{vassos08progression_future_queries}.
As such, work on progression in the situation calculus has focussed
on restricted queries or restricted databases for which progression
can be defined \citep{liu05sc_progression_knowledge,vassos07progression}.

By contrast, the regression operator is both sound and complete for
answering a broad range of queries. TODO: more hereon why regression
is great

In this thesis, we develop formalisms and reasoning techniques for
problems which have not been approach before in the situation calculus.
Our first priority must be a sound and complete reasoning tool, for
which regression is a good match. Advanced techniques such a progression
may be developed at a later date.


\subsection{Extensions}

The base language of the situation calculus may seem quite simplistic,
lacking many features that would be desirable for modelling rich multi-agent
domains. However, a number of important extensions have been proposed
which increase the domain features that can be modelled while maintaining
the elegance and simplicity of the base situation calculus. We will
now discuss several such extensions that are important when modelling
mtul-agent domains.


\subsubsection{Concurrent Actions}

In the basic situation calculus only a single action can occur at
any instant. While suitable for most single-agent domains, this limitation
is emphatically not suitable for multi-agent systems - several actions
can easily occur simultaneously if performed by different agents.
Modeling this \emph{true concurrency} is necessary to avoid problems
with conflicting or incompatible actions. There is also the potential
to utilize concurrency to execute tasks more efficiently. Clearly
a solid account of concurrency is required for programming multi-agent
teams.

The work of \citep{lin92sc_conc,reiter96sc_nat_conc} adds true concurrency
to the situation calculus by replacing action terms with \emph{sets}
of actions that are performed simultaneously. The additional sort
\noun{Concurrent} is added to $\mathcal{L}_{sitcalc}$, and the axioms
for set theory are added to $\Dt_{bg}$. All functions and predicates
that take an action are modified to take sets of actions instead.
For example, $do(a,s)$ becomes $do(\{a_{1},a_{2},...\},s)$. Successor
state axioms are modified to test for set membership rather than equality
of action terms. For example, the axiom for $Holding$ would become:\begin{multline*}
Holding(agt,obj,do(c,s))\equiv pickup(agt,obj)\in c\\
\vee\,\, Holding(agt,obj,s)\,\wedge drop(agt,obj)\not\in c\end{multline*}


This seemingly simple modification introduces a complication - a combination
of actions is not guaranteed to be possible even if each of the individual
actions are. For example, two agents may not be able to acquire the
same resource at the same time. This is known as the precondition
interaction problem \citep{pinto94temporal} and is an area of ongoing
research. We make no explicit commitment towards a solution for this
problem. Rather, we assume that the axioms in $\Dt_{ad}$ are structured
to account for it.

TODO: better story about precondition interaction and $\Dt_{ad}$


\subsubsection{TODO: Time}

An explicit notion of time can make coordination between agents easier,
as joint actions may be performed at a particular time. It also allows
a richer description of the world, particularly in domains such as
the cooking agents where time can play an important part in tasks
to be performed.

The standard approach to time in the situation calculus is that of
\citep{pinto94temporal,reiter96sc_nat_conc}. An additional sort \noun{Timepoint}
is introduced, which can be any appropriate-behaved sequence such
as integers or reals. The axiomatisation of timepoints is added to
$\Dt_{bg}$, and each action gains an extra argument indicating the
time at which is was performed. The functions $time$ and $start$
are introduced to give the performance time of an action and the start
time of a situation respectively. The start time of the initial situation
is typically defined to be zero.

However, this approach requires an additional predicate $Coherent$
to ensure that the performance time is the same for all members in
a set of concurrent actions. The $Poss$ fluent for concurrent actions
must be further refined to ensure that only coherent sets of actions
are possible:\begin{multline*}
Poss(c,s)\equiv\forall a.\left[a\in c\rightarrow Poss(a,s)\right]\\
\wedge\, time(c)>start(s)\,\wedge\, Coherent(c)\end{multline*}


To avoid this extra complexity, we follow the approach taken in the
related formalism of the Fluent Calculus \citep{martin03conc_flux}
and attach the temporal component to the situation term, rather than
to each individual action.

TODO: finish this


\subsubsection{TODO: Long-Running Tasks}

This representation of time is accompanied by a standard approach
to actions with a finite duration: they are decomposed into instantaneous
$start$ and $end$ actions and a fluent indicating that the action
is in progress. For example, a long-running task may be represented
by the actions $beginTask$ and $endTask$ along with a fluent $doingTask$.


\subsubsection{TODO: Natural Actions}

These are a special class of exogenous actions, those actions which
occur outside of an agent's control \citep{reiter96sc_nat_conc}.
They are classified according to the following requirement: natural
actions must occur at their predicted times, provided no earlier actions
prevent them from occurring. For example, a timer will ring at the
time it was set for, unless it is switched off. The action $endTask$
from above is another example - it must occur whenever it is possible,
which is at the time when the agent finishes the task. In domains
where many agents may be simultaneously engaged in many long-running
tasks, strong semantic support for natural actions will therefore
be of significant benefit.

Natural actions are indicated by the truth of the predicate $Natural(a)$.
The times at which natural actions may occur are specified by the
$Poss$ predicate as usual. For example, suppose that the fluent $TimerSet(m,s)$
represents the fact that a timer is set to ring in $m$ minutes in
situation $s$. The possibility predicate for the $ringTimer(t)$
action would be:\begin{multline*}
Poss(ringTimer(t),s)\equiv\\
\exists m.\left[TimerSet(m,s)\wedge t=start(s)+m\right]\end{multline*}
 The timer may thus ring only at its predicted time. To enforce the
requirement that natural actions \emph{must} occur whenever possible,
a predicate $Legal(s)$ is introduced which is true only for situations
that respect this requirement. Legal situations are the only situations
that could be brought about in the real world:\begin{multline*}
Legal(S_{0})\equiv True\\
\shoveleft{Legal(do(c,s))\equiv Legal(s)\wedge Poss(c,s)}\\
\wedge\,\forall a.\left[Natural(a)\wedge Poss(a,s)\rightarrow\left[a\in c\vee t<time(a)\right]\right]\end{multline*}
 An important concept when dealing with natural actions is the least
natural time point (LNTP) of a situation, defined as the earliest
time at which a natural action may occur. We assume that the theory
of action avoids certain pathological cases, so that absence of an
LNTP implies that no natural actions are possible.\begin{multline*}
Lntp(s,t)\equiv\\
\exists a.\left[Natural(a)\wedge Poss(a,s)\wedge time(a)=t\right]\wedge\\
\forall a.\left[Natural(a)\wedge Poss(a,s)\rightarrow t\leq time(a)\right]\end{multline*}



\subsubsection{TODO: State Constraints}

TODO: state constraints\citep{Lin94-StateConstraints}


\subsection{Applications}

The most prominent application of the situation calculus has been
the programming language Golog \citep{levesque97golog} and its descendants,
which will be discussed in detail in section \ref{sec:Background:Golog}.
That the Situation Calculus and Golog are viable tools for specifying
and implementing agent behavior is highlighted by the many successful
applications of the techniques in different planning tasks, including:
open-world planning \citep{Finzi00open_world_sitcalc}; planning with
natural actions \citep{pirri00planning_nat_acts}; planning under
uncertainty \citep{baier03golog_planning}; control and coordination
in robotic soccur \citep{Ferrein2005readylog}; and specifying the
behavior of computer-controlled characters in video games \citep{jacobs05unrealgolog}.

In more theoretical settings, the situation calculus has formed the
basis for reasoning about multi-agent games \citep{delgrande01sitcalc_cleudo}
and system specifications \citep{shapiro02casl,lesperance05ecasl}.
It has formed the basis for a standard process specification language
in manufactoring \citep{gruninger04psl} and has been applied to the
automated composition of semantic web services \citep{mcilraith02golog_web_services}.

TODO: more on applications


\subsection{TODO: Related Formalisms}

There are a wide range of related formalisms for reasoning about knowledge,
action and change, which we do not directly consider in this thesis.

TODO: fluent calculus \citep{thielscher99fluentcalc}

TODO: event calculus \citep{kowalski86event_calculus}

We find the notation and meta-theory of the situation calculus particularly
suitable for expressing our main ideas. Moreover, the strong underlying
similarities between the major action formalisms should allow the
these ideas to transcend the specifics of the situation calculus \citet{thielscher06reconcile_sc_fc,thielscher07unifying_action_calculus,vanbentham07ml_sitcalc}.


\section{Golog\label{sec:Background:Golog}}

Golog is a declarative agent programming language based on the situation
calculus \citep{levesque97golog}. Testimony to its success are its
wide range of applications and many extensions to provide additional
functionality \citep{giacomo00congolog,giacomo99indigolog,Ferrein2005readylog}.
We use the name {}``Golog'' to refer to the family of languages
based on this technique, including ConGolog \citep{giacomo00congolog}
and IndiGolog \citep{giacomo99indigolog}.


\subsection{Notation}

To program an agent using Golog one specifies a situation calculus
theory of action, and a program consisting of actions from the theory
connected by programming constructs such as if-then-else, while loops,
and nondeterministic choice. Table \ref{tbl:Background:Golog-Operators}
lists some of the operators available in various incarnations of the
language.%
\begin{table}[h]
 

\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Operator  & Meaning\tabularnewline
\hline
\hline 
$a$  & Execute action $a$ in the world\tabularnewline
\hline 
$\phi?$  & Proceed if condition $\phi$ is true\tabularnewline
\hline 
$\delta_{1};\delta_{2}$  & Execute $\delta_{1}$followed by $\delta_{2}$\tabularnewline
\hline 
$\delta_{1}|\delta_{2}$  & Execute either $\delta_{1}$ or $\delta_{2}$\tabularnewline
\hline 
$\pi(x,\delta(x))$  & Nondet. select arguments for $\delta$\tabularnewline
\hline 
$\delta*$  & Execute $\delta$ zero or more times\tabularnewline
\hline 
$\mathbf{if}\,\phi\,\mathbf{then}\,\delta_{1}\,\mathbf{else}\,\delta_{2}$  & Exec. $\delta_{1}$ if $\phi$ holds, $\delta_{2}$ otherwise\tabularnewline
\hline 
$\mathbf{while\,}\phi\mathbf{\, do}\,\delta$  & Execute $\delta$ while $\phi$ holds\tabularnewline
\hline 
$\mathbf{proc}P(\overrightarrow{x})\delta(\overrightarrow{x})\mathbf{end}$  & Procedure definition\tabularnewline
\hline 
$\delta_{1}||\delta_{2}$  & Concurrent execution\tabularnewline
\hline 
$\Sigma\delta$  & Plan execution offline\tabularnewline
\hline
\end{tabular}
\par\end{centering}

\caption{Golog Operators\label{tbl:Background:Golog-Operators} }

\end{table}


Readers familiar with dynamic logic will recognise some of these operators,
but others are unique to first-order formalisms such as Golog. Many
Golog operators are nondeterministic and may be executed in a number
of different ways. It is the task of the agent to plan a deterministic
instantiation of the program, a sequence of actions that can legally
be performed in the world. Such a sequence is called a \emph{legal
execution} of the Golog program.

To get a feel for how these operators can be used, consider some example
programs. Figure \ref{fig:Background:Golog:Washing-Dishes} shows
a simple program for Bob to wash the dishes. It makes use of the nondeterministic
{}``pick'' operator to select a dish that needs cleaning, until
no such dishes remain. The legal executions of this program are sequences
of $clean(Bob,d)$ actions, one for each dirty dish in the domain,
performed in any order.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t][1\totalheight]{0.85\columnwidth}%
\begin{flalign*} \mathbf{while}\,\exists d:\, Dirty(d)\,\mathbf{do}\\
 \pi(d,\, clean(Bob,d))\\
 \mathbf{end}\end{flalign*} %
\end{minipage}} 
\par\end{centering}

\caption{A Golog program for wasing the dishes\label{fig:Background:Golog:Washing-Dishes}}

\end{figure}


Figure \ref{fig:Background:Golog:MakeSalad} shows a program that
we will return to throughout the thesis, giving instructions for how
to prepare a simple salad. The procedure $ChopTypeInto$ (not shown)
directs the specified agent to acquire an ingrediate of the specified
type, chope it, and place it into the indicated bowl. The procedure
$MakeSalad$ nondeterministically selects an agent to do this for
a lettuce, a carrot, and a tomato, and allows the chopping to proceed
concurrently if possible. Note the nondeterminism in this program
- the agent assigned to handling each ingredient is not specified
($\pi$ construct), nor is the order in which they should be added
($||$ construct). There is thus considerable scope for cooperation
between agents to effectively carry out this task.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t][1\totalheight]{0.85\columnwidth}%
\begin{multline*}
\mathbf{proc}\, MakeSalad(dest)\\
\left[\pi(agt)(ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\pi(agt)(ChopTypeInto(agt,Carrot,dest))\,||\\
\left.\pi(agt)(ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\pi(agt)\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right]\,\,\mathbf{end}\end{multline*}
 %
\end{minipage}} 
\par\end{centering}

\caption{A Golog program for making a salad\label{fig:Background:Golog:MakeSalad}}

\end{figure}



\subsection{Semantics}

Two predicates $Trans$ and $Final$ define the semantics for each
operator. $Trans(\delta,s,\delta',s')$ holds when executing a step
of program $\delta$ can cause the world to move from situation $s$
to situation $s'$, after which $\delta'$ remains to be executed.
It thus characterises single steps of computation. $Final(\delta,s)$
holds when program $\delta$ may legally terminate its execution in
situation $s$. We base our work on the semantics of IndiGolog, which
builds on ConGolog and is the most feature-full of the standard Golog
variants. The full semantics are available in the references, but
as an example consider equation (\ref{eqn:trans_conc_orig}), which
specifies the concurrent-execution operator as an \emph{interleaving}
of computation steps. It states that it is possible to single-step
the concurrent execution of $\delta_{1}$ and $\delta_{2}$ by performing
either a step from $\delta_{1}$ or a step from $\delta_{2}$, with
the remainder $\gamma$ left to execute concurrently with the other
program:\begin{multline}
Trans(\delta_{1}||\delta_{2},s,\delta',s')\equiv\\
\shoveright{\exists\gamma.Trans(\delta_{1},s,\gamma,s')\wedge\delta'=(\gamma||\delta_{2})}\\
\vee\,\exists\gamma.Trans(\delta_{2},s,\gamma,s')\wedge\delta'=(\delta_{1}||\gamma)\label{eqn:Background:trans_conc_orig}\end{multline}
 Clearly there are two notions of concurrency to be considered: the
possibility of performing several actions at the same instant (\emph{true
concurrency}), and the possibility of interleaving the execution of
several programs (\emph{interleaved concurrency}). These were combined
in \citet{pinto99tcongolog} by modifying Golog to incorporate sets
of concurrent actions. However, they give a semantics which may call
for actions to be performed that are not possible and which can result
in unintuitive program behaviour. A key aspect of our work is a more
robust integration of these two notions of concurrency.

If the theory of action $\mathcal{D}$ is enriched with $Trans$ and
$Final$, planning an execution of a Golog program $\delta$ is basically
a theorem proving task as shown in equation (\ref{eqn:golog_execution}).
Here $Trans*$ indicates reflexive transitive closure. The situation
$s$ gives a sequence of actions forming a legal execution of the
program.\begin{equation}
\mathcal{D}\models\exists s.\left[Trans*(\delta,S_{0},\delta',s)\wedge Final(\delta',s)\right]\label{eqn:Background:golog_execution}\end{equation}
 In IndiGolog agents can also proceed without planning a full terminating
execution of their program, by searching for a legal {}``next step''
action $a$ such that $\mathcal{D}\models\exists a\,.\, Trans*(\delta,s,\delta',do(a,s))$.
The search operator ($\Sigma$) controls which parts of the program
are subject to full execution planning, providing fine-grained control
over nondeterminism and the amount of planning work required.


\subsection{Extensions}

There has been a wide range of Golog extensions developed which we
will not consider in this thesis. Among them have been extensions
to include decision-theoretic \citep{boutilier00dtgolog} and game-theoretic
aspects \citep{finzi03gtgolog,finzi05pogtgolog}, additional control
operators such as partial ordered sequencs of actions \citep{son00htn_golog}
and hierarchical task networks \citep{Gabaldon02htn_in_golog,Son04golog+htn+time},
controlling cooperating members of a team \citep{farinelli07team_golog},
and accounting for contiuous change and event triggering \citep{grosskreutz00ccgolog}.

While we will not consider these Gologs in any detail, we do note
that each has been a relatively straightforward matter of extending
the underlying situation calculus theory and/or the semantics of the
Golog operators, and as a resul there has been rich cross-pollination
between different works. We therefore expect that our work in turn
may be combined with some of these extensions to provide an even richer
formalism.


\section{Epistemic Reasoning\label{sec:Background:Epistemic-Reasoning}}

In multi-agent domains, it is important to be able to reason not only
from the global perspective of the system designer, but also from
the local perspective of each individual agent -- after all, agents
can only be expected to act based on their own local information.
This requires \emph{epistemic} reasoning, or reasoning about the knowledge
of an agent, the standard tool for which is modal logic. We will focus
on epistemic reasoning in the situation calculus; for a general overview
consult \citep{fagin95}.


\subsection{Logics of Knowledge}

The standard semantics of epistemic logic are given by the Kripke
structures of modal logic, based on the idea of \emph{possible worlds}.
If an agent is unsure about the state of the world, then there must
be several candidate states of the world that it considers possible.
The agent is then said to \emph{know} a proposition if it is true
in all worlds considered possible. In modal epistemic logics this
is typically written as $[K_{agt}]\phi$, but we will consistently
use the standard situation calculus notation of $\Knows(agt,\phi,s)$.

While this works well for a static knowledge base, there is also the
question of how each agent's knowledge changes over time as actions
are performed in the world. Various formal systems have been devised
to represent the interaction between knowledge and action, including
those of \citet{fagin95}, \citet{parikh85dist_knowledge} and \citet{baltag98pa_ck}.
Recent work on the foundations of epistemic dynamic logic has shown
these different perspectives to be essentially equivalent \citep{vanBentham06tree_of_knowledge,pacuit07history_structures},
and we will present quite a high-level overview here.

A system is considered to have a set of possible events which could
occur, and the system state at any time is given by a sequence of
events. Each agent has some subset of these events which it can observe,
and in any state of the system thus has a local history of events
that it has observed. From the agent's perspective, the system may
be in any of the states that would produce its current local history.
This equivalance relation between the states of the system defines
the agent's possible worlds, and thus its knowledge.

TODO: do I need a picture or something here? It's a pretty important
concept


\subsection{Knowledge in the Situation Calculus}

Epistemic reasoning was first introduced to the situation calculus
by \citet{moore80know_act}, and formalised extensively by \citet{scherl03sc_knowledge}
whose paper is now the canonical reference for these techniques. Their
work has been extended to include concurrent actions \citep{scherl03conc_knowledge}
and multiple agents \citep{shapiro98specifying_ma_systems}. We further
extend this family of techniques in this paper.

The semantics of knowledge are based on a reification of the {}``possible
worlds'' semantics of modal logic, using situation terms rather than
abstract worlds. A special fluent $K(agt,s',s)$ is used to indicate
that {}``in situation $s$, the agent $agt$ considers the alternate
situation $s'$ to be possible''. The macro $\Knows$ is then defined
as a shorthand for the standard possible-worlds definition of knowledge,
stating that an agent knows $\phi$ when $\phi$ is true in all situations
considered possible: \begin{equation}
\Knows(agt,\phi,s)\isdef\forall s':\, K(agt,s',s)\rightarrow\phi[s']\label{eqn:Background:knows_def}\end{equation}


Readers familiar with modal logic will recognise $K(agt,s',s)$ as
the situation calculus analogue of the modal reachability relation
$K_{agt}$, and the macro $\Knows(agt,\phi,s)$ as the equivalent
of the modal box operator $[K_{agt}]\phi$.

TODO: regression, synchronicity


\subsection{Group-Level Knowledge}

TODO: group-level knowledge, important of common knowledge, inability
to do regression


\subsection{Belief}

When reasoning about knowledge, it is generally assumed that the \emph{actual}
state of the world is among those considered possible, so that an
agent's knowledge is always true:\[
\Knows(agt,\phi,s)\,\rightarrow\,\phi[s]\]


If this is not the case, one is performing \emph{doxastic} or belif-based
reasoning.


\subsection{Alternative Formalisms }

decidability/weakening \citep{demolombe00tractable_sc_belief} \citep{petrick02knowledge_equivalence}


\subsection{Applications}

TODO: epistemic feasibility of plans \citep{giacomo04sem_delib_indigolog,Lesperance01epi_feas_casl}


\section{Mozart/Oz\label{sec:Background:Mozart/Oz}}

The Mozart system \citep{vanroy99mozart} is an implementation of
the Oz programming language \citep{vanRoyHaridi04ctm} with strong
support for logic programming and distributed computing. While a full
explanation of its features is well outside the scope of this thesis,
we provide a short introduction to the subset of its features we will
be using -- in particular, doing prolog-style logic programming in
Oz. Familiarity with logic programming in the style of prolog is assumed.

Terms, variables and unification in Mozart work similarly to prolog,
although arguments in compound terms are separated by whitespace rather
than a comma. Predicates are implemented as ordinary procedures and
cannot be defined as a set of independent clauses. Figure \ref{fig:Background:Naive-List-Reverse}
shows a Mozart implementation of a classic Prolog example predicate,
naive list reverse. Some things to note about this example include:

\begin{itemize}
\item The syntax for procedure definition is $\mathbf{proc}\,\{Name\, Arg\,\dots\,\}$ 
\item The syntax for procedure calls is $\{Name\, Arg\,\dots\,\}$ 
\item The $\mathbf{case}$ statement is used to pattern match the contents
of a variable 
\item Local variables must be explicitly introduced using the keyword $\mathbf{in}$ 
\item Mozart separates functionality into modules, such as $List$ 
\end{itemize}
%
\begin{figure}[t]
 \programinput{listings/background/Reverse.oz}

\caption{Naive List Reverse implemented in Mozart/Oz\label{fig:Background:Naive-List-Reverse}}

\end{figure}


Procedures in Mozart are deterministic by default, and there is no
default search strategy for exploring different alternatives. Instead,
Mozart provides independent facilities for creating choicepoints and
for exploring procedures that contain choicepoints. The result is
a much more flexible, although syntactically more cumbersome, approach
to logic programming \citep{lpinoz99}.

The creation of choice points is explicit in Mozart, and performed
using the $\mathbf{choice}$ keyword. To demonstrate, consider another
classic Prolog example: the nondeterministic list member predicate
demonstrated in figure \ref{fig:Background:Nondet-Member}. In the
case of the empty list, $Member$ simply fails. For a non-empty list,
$Member$ explicitly creates a \emph{choice point} with two options
- either bind $E$ to the head of the list, or bind $E$ to a member
of the tail of the list.

%
\begin{figure}[t]
 \programinput{listings/background/Member.oz}

\caption{Nondeterministic List Member implemented in Mozart/Oz\label{fig:Background:Nondet-Member}}

\end{figure}


It is at this point that the use of Mozart for logic programming differs
most from Prolog. If the $Member$ procedure is simply invoked directly,
it will suspend its execution when the $\mathbf{choice}$ statement
is reached. To resolve the nondeterminism, one must execute the procedure
inside an explicit \emph{search} \emph{object}. These objects are
responsible for exploring the various choicepoints until a non-failing
computation is achieved. They operate by executing the procedure in
a separate \emph{computation space} through which the state of the
underlying computation can be managed \citep{schulte00constraint_services}.

As a demonstration, figure \ref{fig:Background:All-Pairs} uses the
$Member$ procedure to define a procedure $Pairs$, which nondeterministically
selects a pair of elements from a pair of lists. The procedure $AllPairs$
then uses the builtin $Search.base.all$ object to find all solutions
from this procedure, returning a list of all possible pairs from the
two lists. By encapsulating the calls to nondeterministic procedures
inside a search object, $AllPairs$ will not expose any choicepoints
to code that calls it.

Also of note in figure \ref{fig:Background:All-Pairs} is the use
of a \emph{closure} over the procedure $Pair$ to create the one-argument
procedure $FindP$. Search objects work with a one-argument procedure,
which is expected to bind its argument to a result. The dollar symbol
is used to translate a statement (in this case the $\mathbf{proc}$
definition) into an expression. The value that would be bound to the
dollar synbol by the statement becomes the return value of the expression,
so $FindP=proc\,\{\$\, P\}$ is equivalent to $proc\,\{FindP\, P\}$.

%
\begin{figure}[t]
 \programinput{listings/background/Pairs.oz}

\caption{Finding all pairs in Mozart/Oz\label{fig:Background:All-Pairs}}

\end{figure}


The power of this decoupled approach to nondeterminism becomes apparent
when defining new search strategies, which can then be used to evaluate
any procedure. For example, it is straightforward to implement breadth-first
or iterative-deepening strategies to replace the standard depth-first
traversal of the $Search.base$ object \citep{schulte00constraint_services}.

Coupled with Mozart's strong support for distributed computing, these
programmable search strategies offer a unique opportunity - it becomes
possible to implement a parallel search object which can automatically
distribute work between several networked machines. Moreover, this
parallel search can be applied without modification to any nondeterministic
procedure. Mozart comes with a built-in $ParallelSearch$ object,
which is described in detail in \citep{schulte00oz_parallel} and
which is our main motivation for the use of Oz in this thesis.

To demonstrate the power of the approach, consider figure \ref{fig:Background:Parallel-All-Pairs},
which describes a parallel-search version of the $AllPairs$ procedure.
In this instance we define $FindP$ as a \emph{functor}, a Mozart
abstraction for code that is portable between machines. This functor
imports the module $MyList$ containing the procedures we defined
earlier, and exports a one-argument procedure $Script$ which will
be executed by the parallel search object. The parallel search object
$Seacher$ launches one instance of Mozart on the machine {}``mango''
and two instances on the machine {}``rambutan'', then is asked to
enumerate all solutions for $FindP$.

%
\begin{figure}[t]
 \programinput{listings/background/PPairs.oz}

\caption{Finding all pairs in Mozart/Oz\label{fig:Background:Parallel-All-Pairs}}

\end{figure}


In chapter \ref{ch:mindigolog} we will use this parallel search object
to automatically share the workload of planning a Golog execution
amongst a team of cooperating agents.

As a multi-paradigm programming language with significant research
history, there is much more to Oz than we have described here. However,
these brief examples should be sufficient for a reader well-versed
in Prolog to understand the Oz code used throughout this thesis. For
more information and further examples, consult the general Oz tutorial
\citep{haridi99oz_tutorial} or the specialised tutorial on logic
programming in Oz \citep{lpinoz99}, which are both available online.

\label{ch:references} \bibliographystyle{plainnat} \bibliographystyle{plainnat}
\bibliography{../../library/references}




\chapter{Joint Executions}

\label{ch:jointexec}

This chapter constructs a new representation for the actions to be
performed by a team of agents during the cooperative execution of
a shared task. Dubbed \emph{joint executions}, they are partially-ordered
branching sequences of events. Joint executions allow independent
actions to be performed independently, while using each agent's local
view to ensure that synchronisation is always possible when required.

The output of the standard Golog execution planning process is a raw
situation term; a complete, ordered sequence of all actions that are
to be performed. This is suboptimal for generating and representing
plans in an asynchronous multi-agent setting in three ways:

\begin{itemize}
\item it does not permit branching to utilise information obtained at run-time 
\item it enforces a strict execution order on actions that are potentially
independent, requiring inter-agent synchronisation when it is not
actually necessary 
\item it requires a strict execution order on actions that may be unobservable,
demanding inter-agent synchronisation that is not actually feasible 
\end{itemize}
As we have demonstrated in Chapter \ref{ch:mindigolog}, restricting
the domain to be synchronous and completely known lets the agents
make effective use of raw situation terms for planning. In asynchronous
domains with incomplete knowledge they are no longer sufficient, and
the Golog execution planner is required to generate a much richer
representation of the actions to be performed.

To build such a representation, we take inspiration from a model of
concurrent computation known as \emph{prime event} \emph{structures},
which are partially-ordered branching sequences of events \citep{npw79event_structures}.
A \emph{joint execution} is defined as a particular kind of prime
event structure that is rich enough to capture the concurrent execution
of independent actions, and can branch on the results of sensing actions.
We use our explicit account of an agent's local view to identify joint
executions that can feasibly be executed based on the local information
available to each agent at runtime.

Joint executions are formalised in a way that translates well into
an implementation. They can be built up one action at a time in much
the same way as ordinary situation terms. If the theory of action
meets some simple restrictions, joint executions can also be reasoned
about using standard regression techniques. We demonstrate an implementation
that performs offline execution planning for an asynchronous, partially
observable domain, and discuss the challenges faced when attempting
a cooperative online execution in such domains.

Joint executions thus allow us to represent the actions that a team
of agents are to perform in service of some shared task, without requiring
constant synchronisation between the agents, and without assuming
that agents know all the actions that have been performed, while utilising
existing reasoning methods and planning machinery. This is a significant
increase in power over existing approaches to planning for multi-agent
teams in the situation calculus.

The chapter proceeds as follows: after some more detailed background
information in Section \ref{sec:JointExec:Background}, we formally
define and axiomatise joint executions in Section \ref{sec:JointExec:JEs}.
Section \ref{sec:JointExec:Planning} then characterises the Golog
execution planning problem in terms of joint executions rather than
raw situation terms, and Section \ref{sec:JointExec:Reasonable} identifies
a restricted kind of joint execution that can be reasoned about effectively
using standard regression techniques. In Section \ref{sec:JointExec:Implementation}
we present an overview of our new MIndiGolog execution planner that
generates joint executions, and show some examples of its output.
Finally, Section \ref{sec:JointExec:Discussion} concludes with some
general discussion and an outline of our ongoing work in this area.


\section{Background\label{sec:JointExec:Background}}

The above discussion highlights three important properties of a plan
representation formalism intended for use in asynchronous multi-agent
domains: it must be \emph{partially-ordered} to allow agents to operate
independently, \emph{branching} to allow information to be collected
at run-time, and \emph{feasible to execute} based on the local information
available to each agent. While each of these aspects have been studied
in isolation in the situation calculus, our work is the first to combine
them into a single formalism that is suitable for asynchronous multi-agent
domains.


\subsection{Partial Ordering}

There has been little work on partial-order planning in the situation
calculus, most likely because the use of situations heavily biases
the reasoning machinery towards totally-ordered sequences of actions.
While \citet{son00htn_golog} allow the programmer to specify a partial
order on actions by adding operators to the Golog language, the actual
plans produced by their system are still ordinary situation terms.
One exception is \citep{plaisted97sc_aspect}, which extends the situation
calculus with explicit {}``aspects'' and allows partial ordering
between actions that affect different aspects of the world state.
By contrast, we seek to leverage the existing meta-theory of the standard
situation calculus.

Partial-order planning is the mainstay of the closely-related \emph{event
calculus} formalism \citep{kowalski86event_calculus}. In this formalism,
actions are represented as occurring at specific times, rather than
in a specific order as in the situation calculus. Constraints placed
on the relative occurrence times of actions then determine a partial
ordering. \citet{Shanahan97ec_planning} has shown that abductive
theorem proving in the event calculate generates partially-ordered
plans, and the mechanics of the theorem prover naturally mirror various
concepts from the goal-based partial-order planning literature, such
as conflicts, threats and links \citep{peot92conditional_nonlinear}.

The close similarities between the situation and event calculi are
well understood, as are the advantages of the event calculus when
working with partially-ordered action sequences \citep{belleghem97sitcalc_evtcalc}.
Indeed, it is possible to implement a Golog interpreter on top of
the event calculus, and the execution plans it generates are partially-ordered
sets of actions \citep{pereira04ec_golog}. Perhaps we should simply
adopt a formalism such as the event calculus that is naturally partially-ordered,
rather than trying to construct a partially-ordered representation
on top of the naturally sequential situation calculus?

Having a partial-order representation is important, but it is not
the complete picture. While we don't want the agents to have to synchronise
their actions unnecessarily, we also need to ensure the converse:
that when an explicit ordering between actions is \emph{necessary},
the required synchronisation is actually \emph{feasible} based on
the local information available to each agent. It is not clear how
techniques such as \citep{pereira04ec_golog} would extend to the
asynchronous multi-agent case.

By taking advantage of our explicit account of the local information
available to each agent, the formalism developed in this chapter enables
these dual requirements - that some actions don't need to be ordered,
while other actions cannot be ordered - to be captured in an elegant
way. Moreover, we do not need to step outside the bounds of existing
situation calculus theory, and can utilise existing regression techniques
for effective automated reasoning.


\subsection{Branching}

Several single-agent formalisms based on the situation calculus have
introduced some form of branching into the structures returned by
the planner, including the conditional action trees of of sGolog \citep{lakemeyer99golog_cats}
and the branching IndiGolog plans of \citep{giacomo04sem_delib_indigolog}.
These structures typically branch based on the truth or falsehood
of test conditions included in the program. For example, the structural
definition of conditional action trees in \citep{lakemeyer99golog_cats}
includes the following branching case:\[
c=[\phi,c_{1},c_{2}]\]


This instructs the agent to execute the sub-tree $c_{1}$ if $\phi$
is true and the sub-tree $c_{2}$ if $\phi$ is false. An alternate
approach, exemplified by the {}``robot programs'' of \citet{levesque98what_robots_can_do},
is to have the plan branch directly on the results returned by actions
rather than on a test condition. Branching on the binary result of
a sensing action is represented in this formalism by the following
structure:\[
branch(action,\delta_{1},\delta_{2})\]


Here the agent continues execution with program $\delta_{1}$ if the
action returns true, and with $\delta_{2}$ if the action returns
false. Plans that branching directly on the results of actions are
typically longer, but easier for the agent to execute reactively since
it does not need to introspect its knowledge base to decide a test
condition.


\subsection{Feasibility\label{sec:JointExec:BG:Feasibility}}

To allow an agent to execute a plan that depends on information collected
at run-time, it is not sufficient to simply introduce branching into
the plan representation formalism. One must also ensure that, at execution
time, the agent will always \emph{know} which branch of the plan to
take. For example, suppose this simple branching plan will provably
achieve a goal:\[
\mathbf{if}\,\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


The agent can only execute this program if it knows whether or not
$\phi$ holds; otherwise, although one of the branches is guaranteed
to achieve the goal, the agent does not know which branch to take.
Feasibility is typically guaranteed by including sensing actions to
ensure that the test conditions become known when needed:\[
sense_{\phi}\,\,;\,\mathbf{if\,}\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


This requirement that an agent {}``knows how'' to execute a plan
is formalised by various notions of \emph{epistemic feasibility},
including those of \citep{levesque98what_robots_can_do,levesque00knowing_how,Lesperance01epi_feas_casl,giacomo04sem_delib_indigolog,baier06programs_that_sense}.

One approach to ensuring feasibility, embodied by \citep{levesque00knowing_how,giacomo04sem_delib_indigolog,baier06programs_that_sense},
is to represent plans by arbitrary programs formulated in a control
language such as Golog. One then semantically characterises the class
of epistemically feasible programs, using direct assertions about
the knowledge of each agent at each stage of execution. While this
allows for potentially very rich, very succinct plans, it is not clear
how to systematically generate an epistemically feasible plan using
such a general characterisation.

Another approach, advocated by \citep{levesque96what_is_planning,levesque98what_robots_can_do}
and used in the implementation section of \citep{giacomo04sem_delib_indigolog},
is to restrict the structure of plans so that they are always epistemically
feasible. For example, the {}``robot programs'' of \citep{levesque98what_robots_can_do}
are restricted to simple operators such as:\begin{gather*}
action\\
seq(\delta_{1},\delta_{2})\\
branch(action,\delta_{1},\delta_{2})\\
loop(branch(action,\delta,exit))\end{gather*}


These programs do not contain test conditions, but rather branch and
loop directly according to the sensing results returned from each
action. There is therefore no potential for confusion when executing
such programs; they are essentially equivalent to a kind of finite
automaton that can be executed reactively. Nevertheless, \citet{levesque98what_robots_can_do}
show that these programs are universal, in the sense that any achievable
goal can be achieved by suitable a robot program. We are not aware
of any work extending this approach to represent programs intended
for cooperative execution by a team of agents.

These existing notions of epistemic feasibility can be broadly characterised
as \emph{knowing what}. At each stage of execution, each agent must
know what its next action is. In synchronous domains with public actions,
as typically studied in the situation calculus, this is sufficient
to ensure the feasibility of executing a plan.

In asynchronous domains it is not enough for an agent to know \emph{what}
its next action is; it must also know \emph{when} that action should
be performed. For example, suppose that the following simple plan
provably achieves a goal:\[
action_{1}(agt_{1})\,;\, action_{2}(agt_{2})\]


In a synchronous domain this plan can be executed directly. But suppose
the domain is asynchronous, and $agt_{2}$ is unable to observe the
occurrence of $action_{1}$. Since $agt_{2}$ has no way of knowing
whether or not $action_{1}$ has been performed yet, it will not know
when to perform $action_{2}$ and the plan cannot be executed.

In this chapter we ensure plan feasibility by restricting the structure
used to represent plans, in an approach similar to \citep{levesque98what_robots_can_do}
but without looping constructs. We use the explicit account of an
agent's local view developed in the previous chapter to ensure that
each agent will always have enough information to determine what action
to perform next, and when to perform it.


\subsection{Event Structures}

To tackle cooperative execution in a multi-agent setting, we have
adopted a model of concurrent computation known as \emph{event structures}
\citep{npw79event_structures}. The particular variant we are interested
in are \emph{prime event structures}, which are defined as follows.

\begin{defnL}
[{Prime~Event~Structure}] A prime event structure is a
four-tuple $(\mathcal{V},\gamma,\prec,\oplus)$ where: $\mathcal{V}$
is a set of events; $\gamma$ is a function assigning a label to each
event; $\prec$ is the precedence relation, a strict partial order
on events; $\oplus$ is the conflict relation, a binary symmetric
relation indicating events that are mutually exclusive. 
\end{defnL}
The labels assigned by $\gamma$ give the action associated with each
event. By using a labelling scheme rather than identifying events
directly with actions, multiple events can result in the same action
being performed. The precedence relation restricts the order in which
events can occur, so that if $e1\prec e2$ then $e1$ must occur before
$e2$. The conflict relation allows the structure to represent branching,
by having the occurrence of some events preclude the occurrence of
others.

Figure \ref{fig:example-pes} shows a simple example of a prime event
structure. The arrows represent the precedence relation, so in this
diagram we have $e1\prec e3\prec e7$, but $e3\not\prec e4$. The
conflict relation is represented using a dotted line, so we have $e2\oplus e3$
and only one of these two events is permitted to occur. Conflict is
also inherited through the precedence relation, so $e6\oplus e7$
in this diagram.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/example_pes}}}{\tiny {}
} 
\par\end{center}%
\end{minipage}} 
\par\end{centering}

\caption{An example Prime Event Structure.}


\label{fig:example-pes} 
\end{figure}


As it can be cumbersome to specify $\prec$ and $\oplus$ in their
entirety, we will instead specify only the direct \emph{enablers}
and \emph{alternatives} for each event, denoted by $ens(i)$ and $alts(i)$
respectively. Construction of $(\prec,\oplus)$ from $(ens,alts)$
is a straightforward transitive closure. Indeed, it only the enablers
and alternatives that are represented explicitly in Figure \ref{fig:example-pes},
by arrows and dotted lines respectively.

A \emph{configuration} is a sequence of events consistent with $\prec$
in which no pair of events conflict. Each configuration represents
a potential partial run of execution of the system. Event structures
thus form a directed acyclic graph of the events that could occur
during execution of the system. As shown in \citep{pratt91modeling_conc_with_geom},
these structures are a canonical representation of a variety of formalisms
for representing concurrent execution, and it is straightforward to
execute them in a purely reactive fashion.


\section{Joint Executions\label{sec:JointExec:JEs}}

This section defines \emph{joint execution}s as a restricted kind
of prime event structure suitable for representing the actions of
a team of agents in an asynchronous domain. We begin with a high-level
intuitive description to motivate these structures, and then formally
define them using a set of axioms to be included in the theory of
action $\Dt$. Since we intend for agents to synthesise joint executions
as the output of a planning process, they must exist as concrete terms
in the logic.


\subsection{Motivation}

To make things more concrete, consider again the {}``cooking agents''
example domain from Chapter \ref{ch:mindigolog} and the $MakeSalad$
program shown in Figure \ref{fig:MIndiGolog:MakeSalad}. In a completely-known,
synchronous domain, the execution found for this program by our MIndiGolog
interpreter was a linear sequence of concurrent actions as shown in
Figure \ref{fig:MIndiGolog:MakeSalad-in-MIndiGolog} on page \pageref{fig:MIndiGolog:MakeSalad-in-MIndiGolog}.

Let us now suppose that the cooking agents domain is asynchronous,
and all actions other than $release$ and $acquire$ are private.
The execution found by a MIndiGolog interpreter for such a domain
cannot assume that the agents perform their actions in lock-step.
Rather, it should allow the agents to process their respective ingredients
independently, synchronising their actions only on the $release$/$acquire$
sequence necessary to gain control of shared utensils.

An appropriate partially-ordered representation of the actions to
be performed for $MakeSalad$ would then look something like the structure
shown in Figure \ref{fig:JE:MakeSalad1}. For simplicity, we do not
consider time or natural actions in this chapter, and have collapsed
the {}``mix'' and {}``chop'' tasks into primitive actions. Without
expanding on the details at this stage, it should be clear that this
structure captures the same basic workflow as the synchronous execution
of $MakeSalad$ from Chapter \ref{ch:mindigolog}, but without imposing
a strict ordering between the independent actions of different agents.

Indeed, Figure \ref{fig:JE:MakeSalad1} is the joint execution produced
for the $MakeSalad$ program by our new execution planner detailed
in Section \ref{sec:JointExec:Implementation}, although with certain
details suppressed for brevity. It may be helpful to keep this structure
in mind as we develop the formal definitions contained in this section.

%
\begin{figure}[!h]
 \framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25]{listings/jointexec/salad1_plan}}}{\tiny {}
} 
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad$ Program}


\label{fig:JE:MakeSalad1} 
\end{figure}



\subsection{Intuitions}

We define a joint execution as a special kind of prime event structure
as follows:

\begin{defnL}
[{Joint~Execution}] A joint execution is a tuple $(\mathcal{A},\mathcal{O},ens,alts,\gamma,<)$
where: action events $\mathcal{A}$ represent actions to be performed;
outcome events $\mathcal{O}$ represent possible outcomes of actions;
$(\mathcal{A}\cup\mathcal{O},ens,alts,\gamma)$ forms a prime event
structure with precedence relation $\prec$; $<$ is a total order
on events that is consistent with $\prec$. 
\end{defnL}
A joint execution contains two disjoint sets of events: \emph{action}
events $\mathcal{A}$ representing the actions to be performed, and
\emph{outcome} events $\mathcal{O}$ representing the possible outcomes
of each action. For each action event $i\in\mathcal{A}$, its enablers
$ens(i)$ is a set of outcome events, its alternatives $alts(i)$
is empty, and its label $\gamma(i)$ is the action to be performed.
For each outcome event $i\in\mathcal{O}$, $ens(i)$ is a single action
event for which it is a possible outcome, $alts(i)$ is the set of
all other outcome events $j$ such that $ens(j)=ens(i)$, and $\gamma(i)$
is an outcome as produced by the $Out({a},s)$ function for the action
$\gamma(ens(i))$.

Each action event thus represents a single action to be performed,
which enables several alternative outcome events corresponding to
the potential results returned by that action; since the action can
only produce one actual outcome when it is executed, the enabled outcome
events are all mutually conflicting. Each of these outcome events
can then enable further action events, and so forth.

%
\begin{figure}[!b]
 \framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/example_je}}}{\tiny {} }%
\end{minipage}}

\caption{A simple joint execution.}


\label{fig:example-je} 
\end{figure}


A simple example of a joint execution is shown in Figure \ref{fig:example-je},
again using the {}``cooking agents'' example domain. Here elliptical
nodes are action events and box nodes are the resulting outcome events.
The action $checkFor$ senses the presence of a type of ingredient,
returning either $T$ or $F$, and thus producing two conflicting
outcome events. In this example the agent $Jim$ senses for the availability
of eggs, and if this returns true he acquires one; otherwise, he acquires
a tomato. Meanwhile agent $Joe$ acquires a lettuce, independent of
the actions $Jim$ is performing.

Since we are explicitly considering concurrent actions, there are
many different possible ways that the events in this structure could
translate into action occurrences. The independent actions $checkFor(Jim,Egg)$
and $acquire(Joe,Lettuce1)$ could be performed in either order, or
even concurrently.

These structures are clearly much richer than ordinary situation terms,
as they permit branching and partial-ordering between actions. Still,
they correspond to sets of ordinary situation terms in a straightforward
way. Recall that a \emph{configuration} is a partial run of execution
of a prime event structure. Clearly any configuration ending in an
outcome event corresponds to a unique situation term and also a unique
history term, as it is a sequence of alternating actions and their
outcomes.

We will call a set of unordered, non-conflicting outcome events a
\emph{branch}. A branch identifies a set of partial runs of the joint
execution. In Figure \ref{fig:example-je}, the sets $\{O3\}$, $\{O1,O3\}$
and $\{O5,O3\}$ are examples of branches. A \emph{leaf} is a special
case of a branch, where every event is either in the leaf, conflicts
with something in the leaf, or precedes something in the leaf; it
thus represents potential \emph{terminating} runs of the joint execution
execution. In Figure \ref{fig:example-je} there are two leaves, $\{O3,O4\}$
and $\{O3,O5\}$, generated by the two alternate outcomes of the $checkFor$
action.

A \emph{history} of a branch is a history term (as defined in Chapter
\ref{ch:observations}) that can be generated by performing actions
and observing outcomes from the joint execution until all events in
the branch have occurred. By these definitions, the set of histories
of all leaves gives every possible history that could be produced
by performing the joint execution through to a terminating configuration.

A joint execution has one additional component over a standard prime
event structure: a \emph{total} order on events $<$ that is consistent
with the partial order $\prec$ induced by the enabling relation.
We call this the \emph{canonical ordering}, and it allows any branch
to be unambiguously translated into a single \emph{canonical history}.
When we come to use joint executions for planning, we will use the
canonical history to avoid having to reason about all the (potentially
exponentially-many) histories of each leaf. The canonical ordering
is essentially arbitrary; in practice it is determined by the order
of insertion of events into the structure.


\subsection{Structural Axioms}

We introduce new sorts \noun{Event }and \noun{JointExec} to $\Lsit$,
and will collect the axioms defining joint executions in a separate
axiom set $\Dt_{je}$. Events are opaque identifiers with which a
joint execution associates a label, a set of enablers, and a set of
alternatives. In practise we identify events with the integers, although
our definitions require only a total ordering relation over events.
Labels are either \noun{Action} or \noun{Outcome} terms. A joint execution
is then a term containing:

\begin{itemize}
\item a set of \emph{events}, which are opaque ids having total order $<$ 
\item a mapping from each event to a \emph{label}, which is either an action
or an outcome 
\item a mapping from each event to its \emph{enablers}, a set of lower-numbered
events 
\item a mapping from each event to its \emph{alternatives}, a set of events 
\end{itemize}
We will use the function $jexec$ as a constructor for joint execution
terms, specifying each of the four features above as an argument,
and using sets of $key\#value$ pairs to represent a mapping as in
the previous chapter.

First, we require a unique names axiom to specify that a joint execution
is uniquely defined by its four components, and a domain closure axiom
to specify that all joint executions are constructed in this way.
Assuming the variables are restricted to appropriate sorts by $\Lsit$,
the following axioms suffice:\begin{gather*}
\forall ex:\,\exists es,ls,ns,as:\,\, ex=jexec(es,ls,ns,as)\\
\\jexec(es,ls,ns,as)=jexec(es',ls',ns',as')\,\equiv\,\,\,\,\,\,\,\,\\
\,\,\,\,\,\,\,\, es=es'\wedge ls=ls'\wedge ns=ns'\wedge as=as'\end{gather*}


We introduce four functions to access the components of a joint execution:\begin{gather*}
events(ex)=es\,\equiv\exists ls,ns,as:\, ex=jexec(es,ls,ns,as)\\
lblmap(ex)=ls\,\equiv\exists es,ns,as:\, ex=jexec(es,ls,ns,as)\\
ensmap(ex)=ns\,\equiv\exists es,ls,as:\, ex=jexec(es,ls,ns,as)\\
altsmap(ex)=as\,\equiv\exists es,ls,ns:\, ex=jexec(es,ls,ns,as)\end{gather*}


We also define the following shortcut accessors to get the value from
each mapping for a particular event $i$:\begin{gather*}
lbl(ex,i,l)\equiv i\#l\in lblmap(ex)\\
ens(ex,i,ns)\equiv i\#ns\in ensmap(ex)\\
alts(ex,i,as)\equiv i\#as\in altsmap(ex)\end{gather*}


For notational convenience we will often write these as functions,
e.g. $ens(ex,i)=ns$ rather than $ens(ex,i,ns)$, but this should
be understood as an abbreviation since not every joint execution will
contain every event.

We must also define the \emph{precedes} and \emph{conflicts} relations
in terms of enablers and alternatives. These will be written as binary
infix operators $\prec_{ex}$ and $\oplus_{ex}$ respectively. Since
they are transitive closures they require a second-order axiomatisation.
First, the precedence relation is defined as a simple transitive closure
over enablers:\begin{multline*}
\forall P,ex,i,j:\left[\left(i\in ens(ex,j)\,\rightarrow P(i,j)\right)\wedge\left(\forall k:P(i,k)\wedge k\in ens(ex,j)\rightarrow P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\prec_{ex}j\right)\end{multline*}


Then we can define the conflict relation by specifying that $i\oplus_{ex}j$
if they are alternatives to each other, or they have conflicting predecessors:\begin{multline*}
\forall P,ex,i,j:\,\left[\left(i\in alts(ex,j)\,\rightarrow P(i,j)\right)\right.\\
\left.\wedge\,\left(\forall i',j':\, P(i',j')\wedge i'\preceq_{ex}i\wedge j'\preceq_{ex}j\,\rightarrow\, P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\oplus_{ex}j\right)\end{multline*}


Next we need axioms defining our terminology of \emph{branches} and
\emph{leaves}. A branch is a set of unordered non-conflicting outcome
events:\begin{multline*}
Branch(ex,br)\,\equiv\,\forall i,j\in br:\, IsOutcome(lbl(ex,i))\wedge IsOutcome(lbl(ex,j))\\
\wedge\,\neg(i\oplus_{ex}j)\,\wedge\, i\not\prec_{ex}j\,\wedge\, j\not\prec_{ex}\, j\end{multline*}


A \emph{leaf} is defined as a special case of a branch, so that everything
either precedes or conflicts with something in the leaf:\begin{multline*}
Leaf(ex,lf)\,\equiv\, Branch(ex,lf)\\
\wedge\forall i\in events(ex):\, i\in lf\,\equiv\,\neg(\exists i'\in lf:\,\, i\oplus_{ex}i'\,\vee\, i\prec_{ex}i')\end{multline*}


Finally, we say a joint execution is \emph{proper} if it respects
the basic structural intuitions we discussed in the previous section.
Every event must be proper according to its type, and events cannot
be enabled by higher-numbered events:\begin{gather*}
Proper(ex)\,\equiv\,\forall i\in events(ex):\, ProperAct(ex,i)\vee ProperOut(ex,i)\\
\wedge\forall i,j:\,\left(i\in events(ex)\wedge j\in ens(ex,i)\,\rightarrow\, j<i\right)\end{gather*}


Note that this does not result in a loss of expressivity, since we
we want event $i$ to precede event $j$, then $j$ cannot also precede
$i$ and we simply give $j$ the higher event number. This restriction
will play an important role in Section \ref{sec:JointExec:Reasonable}.

An action event is proper if it has no alternatives, enables at least
one outcome event, and is enabled by a branch. Restricting the enablers
to be a branch ensures that they do not contain any redundant or conflicting
information.\begin{gather*}
ProperAct(ex,i)\,\equiv\, IsAction(lbl(ex,i))\\
\wedge Branch(ex,ens(ex,i))\wedge alts(ex,i)=\{\}\wedge\exists j:\, ens(ex,j)=\{i\}\end{gather*}


An outcome event is proper if it is enabled by a unique action event,
and has as its alternatives the set of all other events enabled by
that action.\begin{gather*}
ProperOut(ex,i)\,\equiv\, IsOutcome(lbl(ex,i))\\
\wedge\exists j:\, ens(ex,i)=\{j\}\wedge IsAction(lbl(ex,j))\\
\wedge\forall k:\,\left(k\in alts(ex,i)\,\equiv\, ens(ex,k)=\{j\}\right)\end{gather*}


These definitions enforce the basic structure of a joint execution
according to the intuitions discussed in the previous section, but
do not constrain it to be something that could actually be performed
in the world -- for example, outcomes can be enabled by actions that
will never actually produce that outcome. Like situation terms, we
focus first on getting the appropriate structure, and then specify
additional conditions that joint executions must satisfy in order
to be legal in the real world.


\subsection{Performing Events}

We introduce a predicate $Perform$ that axiomatises how events from
a joint execution can be performed. Since we explicitly consider concurrent
actions, this predicate selects a \emph{set} of action events to be
performed: \begin{gather*}
Perform(ex,es_{a},es_{o},ex')\equiv\,\,\,\,\, es_{a}\neq\{\}\wedge es_{o}\neq\{\}\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\, IsAction(lbl(ex,i))\wedge ens(ex,i)=\{\}\right)\\
\wedge\,\forall i:\,\left(i\in es_{o}\,\rightarrow\exists j:\, ens(ex,i)=\{j\}\wedge j\in es_{a}\right)\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\,\exists j:\, j\in es_{o}\wedge ens(ex,j)=\{i\}\right)\\
\wedge\,\forall i,j:\,\left(i\in es_{o}\wedge j\in es_{o}\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall i:\,\left(i\in events(ex')\,\equiv\, i\not\in es_{a}\wedge i\not\in es_{o}\wedge\neg\exists j:\,(j\in es_{o}\wedge i\oplus_{je}j)\wedge\right)\\
\wedge\,\forall i,lb:\,\left(i\#lb\in lblmap(ex')\equiv\, lbl(ex,i)=lb\wedge i\in events(ex')\right)\\
\wedge\,\forall i,as:\,\left(i\#as\in altsmap(ex')\equiv alts(ex,i)=as\wedge i\in events(ex')\right)\\
\wedge\,\forall i,ns:\,\left(i\#ns\in ensmap(ex')\equiv(ens(ex,i)-es_{o})=ns\wedge i\in events(ex')\right)\end{gather*}


The first four lines of this definition select $es_{a}$ and $es_{o}$
as sets of action and outcome events respectively. The events in $es_{a}$
are any subset of the action events in the joint execution that have
no enablers, and are therefore possible to perform. The set $es_{o}$
contains one outcome event enabled by each event in $es_{a}$.

The remaining four lines specify how the events remaining in the joint
execution are updated: events that conflict with the performed events
are removed, and the performed events are removed from all lists of
enablers.

As an example, consider again the simple joint execution shown in
Figure \ref{fig:example-je}. The possible values of $es_{a}\#es_{o}$
generated by $Perform$ for this joint execution are:\begin{gather*}
\{A1\}\#\{O1\}\\
\{A1\}\#\{O2\}\\
\{A2\}\#\{O3\}\\
\{A1,A2\}\#\{O1,O3\}\\
\{A1,A2\}\#\{O2,O3\}\end{gather*}


This predicate is clearly quite non-deterministic, permitting any
subset of the enabled events to be performed. The different choices
made by $Perform$ correspond to different potential orderings of
events when performing the joint execution.


\subsection{Histories}

Every branch identifies a family of potential partial runs of the
execution, which are given by the branch's \emph{histories}. The predicate
$History$ constructs a branch history by recursively performing events
that do not conflict with the branch, until all events in the branch
have been performed. This predicate depends on $Perform$ to identify
an enabled set of action events $es_{a}$ and outcome events $es_{o}$,
the labels of which are translated into action and outcome terms $c$
and $y$ respectively. \begin{gather*}
History(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


The second and third lines of this definition select sets $es_{a}$
and $es_{o}$ that do not conflict with the given branch. The fourth
line constructs the concurrent action $c$ as the union of each action
in the set $es_{a}$, while the fifth line constructs the corresponding
outcome $y$ as the agent-wise union of the outcomes in the set $es_{o}$.
Such pairs $c\#y$ are repeatedly selected until every event in the
branch is performed.

Clearly, if there are many unordered events then there are many potential
histories for a given branch; in fact there may be exponentially-many
histories in general. In Section \ref{sec:JointExec:Reasonable} we
show how to avoid reasoning about each history individually, which
is crucial if these structures are to be of practical use. Instead,
we reason about only the \emph{canonical} \emph{history,} the unique
history obtained by performing events in the strict order determined
by the $<$ relation:\begin{gather*}
CHistory(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\exists i:\, es_{a}=\{i\}\wedge\forall j\in events(ex):\, i<j\,\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


For convenience, we also define a predicate $Sit$ that gives the
situation terms corresponding to the branch histories:\[
Sit(ex,br,s)\,\equiv\,\exists h:\, History(ex,br,h)\wedge Sit(h)=s\]



\subsection{The Agent-Local Perspective}

Since we intend for joint executions to be performed reactively by
a team of agents in an asynchronous environment, we must also formalise
the relationship between a joint execution and each agent's local
view. First, we define the $View$ function over a history in the
obvious way:\begin{gather*}
View(agt,\epsilon)=\epsilon\\
y[agt]=\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=View(agt,h)\\
y[agt]\neq\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=y[agt]\cdot View(agt,h)\end{gather*}


We will say that an action event $i$ is \emph{enabled by a view}
if there is a history of its enablers that corresponds to that view:
\[
EnabledByView(ex,i,agt,v)\equiv\exists h:\, History(ex,ens(ex,i),h)\wedge View(agt,h)=v\]


Since an agent's view does not have complete information, $EnabledByView$
identifies events that \emph{might} be enabled given the agent's local
information. Since agents can only be expected to act based on their
local information, we will need to further restrict the structure
of joint executions so that this information is sufficient for each
agent to determine which action to perform.


\subsection{Feasible Joint Executions}

We are now in a position to restrict joint executions so that they
are \emph{feasible}, meaning that the agents would actually be able
to cooperatively perform them in the world. This is accomplished using
two structural restrictions.

The first restriction corresponds to the idea of \emph{knowing when}
to perform an action. If an action event $i$ is enabled by an outcome
event $j$, then $j$ must not be hidden from the agent performing
$i$. Otherwise, it has no way of enforcing the required ordering
between the two events. Let $actor(ex,i)$ be the agent responsible
for performing an action event $i$, then we have the following requirement:\begin{multline*}
KnowsWhen(ex)\,\isdef\,\\
\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\,\wedge j\in ens(ex,i)\\
\rightarrow\, lbl(ex,i)[actor(ex,i)]\neq\{\}\end{multline*}


Figure \ref{fig:not-knows-when} shows an example of a joint execution
that does not meet this requirement. This plan calls for $Jim$ to
place an egg in the bowl, and then for $Joe$ to mix the bowl's contents.
However, since $Joe$ cannot observe the occurrence of $Jim$'s action,
he cannot enforce the ordering between these two events and the plan
cannot be executed.

The second restriction corresponds to the idea of \emph{knowing what}
action to perform. For any given view $v$, there may be multiple
events enabled by that view, and the agent has no means of knowing
precisely which event is actually enabled. To ensure it always knows
what to do, we require that all such events call for the same action
to be performed:

\begin{multline*}
KnowsWhat(ex)\,\isdef\,\\
\forall agt,v,i,j:\,\, EnabledByView(ex,i,agt,v)\wedge EnabledByView(ex,j,agt,v)\\
\rightarrow lbl(ex,u)=lbl(ex,j)\end{multline*}
 While the agent may not know precisely which \emph{event} is enabled,
its local information is enough to determine the specific \emph{action}
that it is to perform. Figure \ref{fig:not-knows-what} shows an example
of a joint execution that does not meet this requirement. This plan
calls for $Jim$ to check for the availability of eggs, then for $Joe$
to acquire an appropriate ingredient depending on whether they are
available. But since $Joe$ cannot distinguish between outcome events
$O1$ and $O2$, he doesn't know what action to perform and the plan
cannot be executed.

%
\begin{figure}[!t]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/unfeas_je2}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhen$ restriction}


\label{fig:not-knows-when} 
\end{figure}


%
\begin{figure}[!t]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/unfeas_je}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhat$ restriction}


\label{fig:not-knows-what} 
\end{figure}


TODO: KnowsWhat isn't quite right yet

We say a joint execution is \emph{feasible} if it meets both these
restrictions:\[
Feasible(ex)\,\isdef\, KnowsWhat(ex)\wedge KnowsWhen(ex)\]


The important property of feasible joint executions is that an agent's
local view is always sufficient to determine the next action it should
perform.

\begin{thm}
Let $ex$ be a feasible joint execution, then:\[
\Dt\cup\Dt_{je}\,\models\, TODO:\, what?\]

\end{thm}

\subsection{Legal Joint Executions}

So far, we have not restricted joint executions to correspond to any
sort of \emph{legal} run of execution. A joint execution may have
action events enabling outcome events that they would never produce
under the given theory of action. It may call for actions to be performed
in situations where they are not legal, or allow actions to be performed
concurrently that could be in conflict.

To avoid such undesirable cases, we identify \emph{legal} joint executions
as ones that are constrained enough to be performed in the real word.
We will say that a particular leaf of a joint execution is legal if
every history of that leaf is legal:\[
Legal(ex,lf)\,\isdef\,\forall h:\, History(ex,lf,h)\,\rightarrow\, Legal(h)\]


This ensures that the leaf is constrained enough to prevent precondition
interaction between independent action events, that its outcome events
are correct for their corresponding actions, etc. However, the agents
will generally not have enough information to determine whether a
particular leaf is legal, since this would imply that they already
know what sensing results will occur. We call an entire joint execution
legal if is proper and contains a legal leaf:\[
Legal(ex)\,\isdef\, Proper(ex)\,\wedge\,\exists lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\]


This definition does not require that we establish \emph{which} leaf
is legal, only that we are able to prove that \emph{some} leaf must
be legal. Since the leaves of a joint execution represent all its
possible terminating configurations, this requirement means that a
legal joint execution can legally be performed to completion in the
world.

The definition is also \emph{permissive}, in that there may be leaves
of the joint execution that are provably never be legal. Since the
outcomes along these leaves will not occur in reality, the agents
will never follow them at execution time. This permissiveness will
therefore not affect an agent's ability to carry out the plan in practice.


\subsection{Summary}

This section has formally defined a \emph{joint execution}, a partially-ordered
branching action structure that we claim is particularly well suited
for representing the actions to be performed by a team of agents in
service of a shared task. The partially-ordered nature of joint executions
allows them to explicitly account for inter-agent synchronisation
of actions in the face of partial observability, while their branching
nature allows them to account for incomplete information that must
be augmented with runtime sensing results.

In asynchronous domains, where raw situation terms cannot feasibly
be executed in the world, joint executions are an ideal alternative
as a plan representation structure for use by the Golog execution
planning process. In the next section we identify precisely what such
a planning process would entail.


\section{Planning with Joint Executions\label{sec:JointExec:Planning}}

With the above definitions and axioms in place, we are now in a position
to plan the cooperative execution of a shared Golog program using
joint executions rather than raw situation terms. For the moment we
focus on \emph{offline} execution planning, in the style of the original
Golog and ConGolog. Recall that the semantics of execution planning
in Golog involve finding a situation term $s$ satisfying:\[
\Dt\cup\Dt_{golog}\,\models\,\exists s:\,\Do(\delta,S_{0},s)\]


Before extending this query to search for a joint execution, notice
an important consequence of our definitions: if two events can occur
in either order if and only if they can also occur concurrently. Since
the standard Golog/ConGolog semantics do not permit true concurrency,
they would force all events to be ordered and we would gain no benefit
from using joint executions. We must therefore adopt the concurrency
semantics of MIndiGolog from Chapter \ref{ch:mindigolog}, which permit
true concurrency of actions.

The execution planning problem then reduces to the task of finding
a \emph{legal}, \emph{feasible} joint execution such that for every
leaf, if that leaf is legal, then it constitutes a legal execution
of the program:\begin{multline}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\label{eq:JE-Plan-Defn}\end{multline}


This query neatly captures dual soundness and completeness requirements.
For soundness, it requires that for every leaf of the joint execution,
\emph{if} that leaf is legal then it will be a legal execution of
the program $\delta$. For completeness, it requires that there must
in fact be \emph{some} leaf that is legal, so the joint execution
can actually be performed in the world. The joint execution must contain
enough branching to account for any incomplete knowledge the agents
have about the state of the world.

%
\begin{algorithm}[t]
\caption{Offline Execution Algorithm using Joint Executions}


\label{alg:je_offline_exec} \begin{algorithmic}

\STATE

\STATE $v\,\Leftarrow\,\epsilon$

\STATE Find a joint execution $ex$ such that:\begin{multline*}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\end{multline*}


\WHILE{$ex$ contains action events to be performed by me}

\STATE Find an action $a$ such that\[
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists i:\, EnabledByView(ex,i,agt,v)\wedge lbl(ex,i)=a\]


\IF {there is such an action}

\STATE Execute action $a$

\ENDIF

\STATE Wait for a new observation $o$

\STATE $v\,\Leftarrow\, o\cdot v$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


Algorithm \ref{alg:je_offline_exec} presents a simple modification
of the Golog offline planning algorithm that can be used by each agent
to plan the execution of a shared program $\delta$ and then perform
it in the world. A restricted version of this algorithm is used by
our implementation that will be described in Section \ref{sec:JointExec:Implementation}.

Since this algorithm is to be executed independently by each agent
in the team, it must identify actions to perform using on the agent's
local view. Since we restrict the joint execution to be feasible,
Theorem TODO guarantees that the $EnabledByView$ query is sufficient
to identify which action to perform next. If we did not have this
restriction, Algorithm \ref{alg:je_offline_exec} would not be correct.

If we turn out attention to \emph{online} execution in the style of
IndiGolog, things are not so straightforward. Although we have not
presented the axioms for doing so, it is simple enough to extend the
leaves of a joint execution one action at a time in the style of the
IndiGolog execution algorithm presented in Algorithm \ref{alg:indigolog_exec}.
The difficulty comes in trying to coordinate this process across multiple
agents when they have differing knowledge about the state of the world.

To demonstrate the issues involved, consider the hypothetical, \textbf{\emph{incorrect}}
online execution algorithm presented in Algorithm \ref{alg:je_online_exec_invalid},
which mirrors the ReadyLog execution algorithm used by our first MIndiGolog
implementation. Since joint executions are a branching structure,
the agent must extend each leaf of the joint execution with a new
step of execution of the program; if any leaf cannot be extended then
execution will potentially fail. To avoid this and reduce its planning
workload, the agent discards leaves that it knows are not legal before
planning the next step of execution.

%
\begin{algorithm}[t]
\caption{An Incorrect, Hypothetical Online Execution Algorithm}


\label{alg:je_online_exec_invalid} \begin{algorithmic}

\STATE

\STATE $v\,\Leftarrow\,\epsilon$

\STATE $ex\,\Leftarrow\, jexec(\{\},\{\},\{\},\{\})$

\WHILE{$\delta$ is not final according to my current view $v$}

\STATE Discard any leaves of $ex$ incompatible with $v$

\STATE Extend each leaf of $ex$ with a legal step of $\delta$

\STATE Find an action in $ex$ that is enabled by $v$

\IF {there is such an action}

\STATE Execute that action

\ENDIF

\STATE Wait for a new observation $o$

\STATE $v\,\Leftarrow\, o\cdot v$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


However, the implicit coordination scheme used by ReadyLog and MIndiGolog
depends on all agents generating the same {}``next step'' at every
iteration. It is therefore incorrect for the agent to discard leaves
based only on its local information -- it must retain any leaves that
its teammates could still consider possible, in order to guarantee
that they generate the same plan. Worse, it must also consider that
its teammates will retain leaves that they think \emph{it }could still
consider possible, and so-on ad infinitum.

The difficulty here is the well-known correspondence between coordination
and common knowledge. In order to extend this execution algorithm
to the case of incomplete information, the agents must plan based
on what is \emph{commonly known} at each stage of execution, rather
based on their own individual view. Unfortunately the situation calculus
offers no tools for reasoning about common knowledge, not even in
synchronous domains.

Coordinating the online execution of a shared Golog program in asynchronous
domains clearly requires more explicit reasoning about the knowledge
of each agent, and the common knowledge of the team. In the coming
chapters of this thesis we will explore the foundations for such reasoning,
but we are yet to incorporate it into our implementation. Our joint-execution
based MIndiGolog planner is therefore currently limited to offline
execution planning.


\section{Reasonable Joint Executions\label{sec:JointExec:Reasonable}}

While joint executions can clearly provide a powerful formal account
of execution planning for asynchronous multi-agent domains, in their
current form they are not suitable for an effective implementation.
The difficulty arises from the definition of $History(ex,br,h)$,
which due to the partial ordering on events can generate an exponentially-large
number of possible histories. To verify that a joint execution is
legal, the planner needs to examine each of these histories individually.

To overcome this difficulty and produce an effective implementation,
we identify a restricted class of joint executions in which all possible
histories of a branch are provably equivalent. Such executions can
be reasoned about using the canonical ordering over events, rather
than having to enumerate each possible distinct history.


\subsection{Independent Actions}

To construct families of situation terms that are all equivalent,
we need a way to identify \emph{independent actions.} Intuitively,
we want independent actions to be able to be performed in either order,
or even concurrently, without affecting what holds in the resulting
situation, or the preconditions or outcomes of each action. This section
formally identifies the conditions that independent actions must satisfy.

For simplicity, we identify actions that are independent regardless
of the situation they are performed in. Let us assume that the theory
of action $\Dt$ is equipped with a rigid predicate $indep(a,a')$
identifying actions that are independent. We identify sets of mutually-independent
actions with this simple definition:\[
mIndep(c)\isdef\forall a,a':\, a\in c\wedge a'\in c\,\rightarrow\, indep(a,a')\]
 We then restrict the theory of action to satisfy the following conditions:

\begin{defnL}
[{Independent~Actions}] A theory of action $\Dt$ correctly
specifies independent actions when it contains a rigid predicate $indep(a,a')$
and entails the following, where $\mathcal{F}$ is a meta-variable
ranging over fluents:\label{def:Independent-Actions}
\end{defnL}
\begin{enumerate}
\item $\Dt\,\models\, indep(a,a')\equiv indep(a',a)$
\item $\Dt\,\models\, Legal(\{a\},s)\equiv Legal(\{a\},do(\{a'\},s))$
\item $\Dt\,\models\, Out(\{a\},s)=Out(\{a\},do(\{a'\},s))$
\item $\Dt\,\models\,\mathcal{F}(do(\{a\},do(\{a'\},s)))\equiv\mathcal{F}(do(\{a'\},do(\{a\},s)))$
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(Legal(c,s)\equiv\,\forall a\in c:\, Legal(\{a\},s)\right)$
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(o\in Out(c,s)[agt]\equiv\exists a\in c:\, o\in Out(\{a\},s)[agt]\right)$
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\forall a\in c:\left(\,\mathcal{F}(do(c,s))\equiv\mathcal{F}(do(\{a\},do(c-\{a\},s)))\right)$
\end{enumerate}
The first restriction simply ensures that Independence is symmetrical.
The next three restrictions ensure that independent actions do not
interfere with each other's preconditions, outcomes or effects. The
final three restrictions ensure that there is no interference between
preconditions, outcomes or effects when independent actions are performed
concurrently.

The following theorems are direct consequences of correctly specifying
independent actions; indeed, they are the motivation for the restrictions
in Definition \ref{def:Independent-Actions}.

\begin{thm}
Let $h$ and $h'$ be two histories of the same length, containing
the same action\#outcome pairs, and differing only by transposition
of $(\{a\}\#y)$ and $(\{a'\}\#y')$. If $indep(a,a')$ holds, then
$h$ is legal if and only if $h'$ is legal.\label{thm:Indep-Trans-Equiv}
\end{thm}
\begin{proof}
Let $h_{p}$ be the common prefix of these histories and $h_{s}$
the common suffix:\begin{gather*}
h\,=\, h_{s}\cdot(\{a\}\#y)\cdot(\{a'\}\#y')\cdot h_{p}\\
h'\,=\, h_{s}\cdot(\{a'\}\#y')\cdot(\{a\}\#y)\cdot h_{p}\end{gather*}


By properties 2 and 3 from Definition \ref{def:Independent-Actions},
we have:\begin{gather*}
Legal(\{a\},Sit(h_{p}))\,\equiv\, Legal(\{a\},Sit((\{a'\}\#y')\cdot h_{p}))\\
Out(\{a\},Sit(h_{p}))\,=\, Out(\{a\},Sit((\{a'\}\#y')\cdot h_{p}))\end{gather*}


And vice-versa. If $h_{s}$ is empty, this is sufficient to establish
$Legal(h)$ iff $Legal(h')$ as desired. Alternately, suppose $h_{s}$
contains $n$ items, then we can apply regression $n$ times to state
the legality of the $h_{s}$ component as a uniform formula evaluated
at $Sit((\{a\}\#y)\cdot(\{a'\}\#y')\cdot h_{p})$. By property 4,
whether this formula holds will be unaffected by the order of $\{a\}$
and $\{a'\}$ and we have the equivalence as desired.
\end{proof}
\begin{thm}
Let $h$ and $h'$ be two histories that differ only by the concurrent
execution of adjacent mutually-independent actions, and the corresponding
agent-wise union of their outcomes. Then $h$ is legal iff $h'$ is
legal.\label{thm:Indep-Conc-Equiv}
\end{thm}
\begin{proof}
Assume that the histories differ by concurrent execution of a single
action. Let $h_{p}$ be the common prefix of these histories and $h_{s}$
the common suffix:\begin{gather*}
h\,=\, h_{s}\cdot(\{a\}\#y)\cdot(\{c\}\#y')\cdot h_{p}\\
h'\,=\, h_{s}\cdot(c\cup\{a\}\#y'')\cdot h_{p}\end{gather*}


Furthermore, we're given that:\begin{gather*}
agt\#o\in y''\,\equiv\, o\in y[agt]\vee\, o\in y'[agt]\\
mIndep(c\cup\{a\})\end{gather*}


By mutual independence, and properties 2 and 5, we have: \begin{gather*}
Legal(\{a\},Sit((\{c\}\#y')\cdot h_{p}))\,\equiv\, Legal(\{a\},Sit(h_{p}))\\
Legal(c\cup\{a\},Sit(h_{p})\,\equiv\, Legal(\{a\},Sit(h_{p}))\wedge\forall a'\in c:\, Legal(\{a'\},Sit(h_{p}))\end{gather*}


Similarly for outcomes, using properties 3 and 6:\begin{gather*}
Out(\{a\},Sit((\{c\}\#y')\cdot h_{p}))\,=\, Out(\{a\},Sit(h_{p}))\\
o\in Out(c\cup\{a\},Sit(h_{p}))[agt]\,\equiv o\in\left(Out(\{a\},Sit(h_{p}))\cup Out(c,Sit(h_{p}))\right)[agt]\end{gather*}


This is sufficient to establish $Legal(h)$ iff $Legal(h')$ if $h_{s}$
is empty. Alternately, suppose $h_{s}$ contains $n$ items, then
we can apply regression $n$ times to state the legality of the $h_{s}$
component as a uniform formula evaluated at $Sit((c\cup\{a\}\#y'')\cdot h_{p})$.
By property 7, whether this formula holds will be unaffected if $\{a\}$
is executed separately, and we have the equivalence as desired.

If the histories differ by concurrent execution of more than a single
action, we can simply unfold them into a sequence of histories differing
by only one action, with each being legal iff its adjacent history
is legal.
\end{proof}
Note that we make no attempt to derive action independence from the
theory of action, but simply assume an appropriate predicate $indep(a,a')$
is available for the purposes of planning. This predicate need not
identify \emph{all }independent actions, although the more actions
that can be identified as independent, the better for our implementation.


\subsection{Reasonability}

We can now define a \emph{reasonabl}e joint execution as one in which
every pair of action events is either ordered, in conflict, or independent:

\begin{defnL}
[{Reasonable~Joint~Execution}] A joint execution is reasonable
if it satisfies the following restriction:\begin{multline*}
\Dt\,\models\,\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\wedge IsAction(lbl(ex,j))\\
\rightarrow\, i\prec_{ex}j\,\vee\, j\prec_{ex}i\,\vee\, i\oplus_{ex}j\,\vee\, indep(lbl(ex,i),lbl(ex,j))\end{multline*}

\end{defnL}
We call such executions {}``reasonable'' because a planner can reason
about then effectively, using the unique canonical history of each
leaf rather than enumerating each individual history.

\begin{thm}
Let $ex$ be a reasonable joint execution, then:\begin{multline*}
\Dt\cup\Dt_{je}\,\models\,\forall lf:\, Leaf(ex,lf)\,\rightarrow\,\\
\left[Legal(ex,lf)\,\equiv\,\exists h:\, CHistory(ex,lf,h)\,\wedge\, Legal(h)\right]\end{multline*}

\end{thm}
\begin{proof}
By definition, a leaf is legal if every possible history of that leaf
is legal, so the \emph{if} direction is trivial. For the \emph{only-if}
direction, assume that the canonical history of the leaf if legal.
Since the histories of a leaf can differ only by the order of execution
of unordered action events, and all unordered action events in a reasonable
execution are independent, every history of the leaf differs from
the canonical history by transposition or concurrent execution of
independent action events.

By Theorems \ref{thm:Indep-Trans-Equiv} and \ref{thm:Indep-Conc-Equiv},
every leaf history is legal iff some leaf history is legal. So if
the canonical history is legal, we have legality of every history
and hence legality of the leaf as required.
\end{proof}
This result is key to our implementation of a MIndiGolog execution
planner based on joint executions - by restricting its search to reasonable
executions, it can verify the legality of each leaf by querying the
legality of the canonical leaf history, which can be done using standard
regression techniques. 

We trade completeness for efficiency here - there can certainly be
non-reasonable joint executions that are valid plans of execution
according to equation \eqref{eq:JE-Plan-Defn}, but it is computationally
too expensive to search for them in practice.


\section{Implementation\label{sec:JointExec:Implementation}}

We have modified our MIndiGolog execution planner from Chapter \ref{ch:mindigolog}
to perform offline execution planning and generate a joint execution
rather than a raw situation term. For details on obtaining the full
source code see Appendix \eqref{ch:code}; for the full axiomatisation
of our example domain see Appendix \eqref{ch:cookingagents}.

As mentioned in Section \eqref{sec:JointExec:JEs}, Figure \ref{fig:JE:MakeSalad1}
shows the output of our planner when run on the $MakeSalad$ program
from Chapter \eqref{ch:mindigolog}. Since all actions in this execution
have a single outcome, the outcome events have been suppressed for
brevity.

In the cooking agents domain, actions are independent if they deal
with different objects. As seen in Figure \ref{fig:JE:MakeSalad1},
the use of a partial order structure facilitates independent execution
between the agents, with each processing a different ingredient and
only synchronising on the availability of the required resources.
This execution provides the maximum potential for concurrency given
the resource constraints of the domain, and is clearly a significant
improvement over totally ordered sequences of actions as produced
by the earlier MIndiGolog planner.

However, the simple $MakeSalad$ program does not demonstrate a key
feature of joint executions: branching. Consider instead the program
$MakeSalad2$ shown in Figure \ref{fig:MIndiGolog:MakeSalad2}. In
this case the agents are unsure whether there are any eggs available,
so the sensing action $checkFor$ is required. If there are eggs then
they should make an egg salad, otherwise they should make the standard
vegetable salad. Note that since lettuce appears in both dishes, they
are permitted to begin processing that ingredient before checking
for the eggs.

%
\begin{figure}
\begin{centering}
\framebox{%
\parbox[t][1\totalheight]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, MakeSalad2(dest)\\
\left[\pi(agt,ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\left.ChopEggOrVeg(dest)\right]\,;\\
\pi(agt,\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
endTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right])\,\,\mathbf{end}\\
\\\\\mathbf{proc}\, ChopEggOrVeg(dest)\\
\pi(agt,\, checkFor(agt,Egg))\,;\\
\mathbf{if}\\
\exists e:\, IsType(e,Egg)\wedge\neg Used(e)\\
\mathbf{then}\\
\left[\pi(agt,ChopTypeInto(agt,Egg,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Cheese,dest))\right]\\
\mathbf{else}\\
\left[\pi(agt,ChopTypeInto(agt,Carrot,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\mathbf{endif}\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for making Egg or Veg Salad\label{fig:MIndiGolog:MakeSalad2}}

\end{figure}


The joint execution found by our implementation for $MakeSalad2$
is shown in Figure \ref{fig:JE:MakeSalad2-Exec}. The event nodes
in this diagram are colour-coded into three groups: white nodes can
occur independently of the sensing results from $checkFor$; light-grey
nodes can only occur if $checkFor$ returns false; dark-grey nodes
can only occur if $checkFor$ returns true.

%
\begin{figure}[H]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25]{listings/jointexec/salad2_plan}}}{\tiny {}} 
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad2$ program}


\label{fig:JE:MakeSalad2-Exec} 
\end{figure}


\newpage{}

We see from this joint execution that $Joe$ can indeed prepare the
lettuce without needing to know whether eggs are available. $Jim$
is assigned to check for the eggs, and acquires either an egg or a
tomato depending on the outcome of his sensing action. Importantly,
$Jon$ has to wait until $Jim$ acquires his ingredient before he
knows whether to process the cheese, or the carrot. This is due to
him being unable to directly observe the outcome of the $checkFor$
action.

By basing branching and synchronisation directly on the observations
made by each agent, joint executions allow us to capture this kind
of rich branching and partial-order structure while ensuring that
the agents can still feasibly execute the plan based solely on their
local information.

In the following sections we highlight some key aspects of our implementation.


\subsection{Program Steps}

The $Trans$ predicate of MIndiGolog is modified to generate \emph{steps}
instead of constructing a new situation term. These are records that
describe not only the next action to perform, but also meta-data about
that action's role in the overall program. Step records have the following
attributes.

\begin{itemize}
\item action: the action performed in that step, or $nil$ if it is an internal
program transition 
\item test: an additional fluent formula that must hold immediately before
performing the step 
\item thread: a sequence of 'l' and 'r' characters indicating the concurrent
thread in which the step is performed 
\item outcome: the outcome of performing the action. 
\end{itemize}
These steps track the necessary information for the planner to determine
whether two actions can be performed independently. A sequence of
steps can be converted to a history term in the obvious way using
the action and outcome attributes.

The thread-naming scheme used here is similar to that of \citep{fritz08congolog_sin_trans}.
Each time $Trans$ chooses to execute a step from the left-hand side
of a concurrency operator it appends an {}``l'' to the thread name,
and each time it chooses the right-hand side it appends an {}``r''.
If one step's thread name is a prefix of another step's thread name,
then those two steps must be performed in the order they are generated;
if not, they are steps from different threads and can potentially
be performed concurrently.

The procedure implementing $Trans$ takes a program and a sequence
of steps as input, returning an new step of execution along with the
remainder of the program to be executed. The code below is representative
of this procedure:

\programinput{listings/jointexec/Trans.oz}

In particular, note that the evaluation of test conditions is performed
by using the input sequence of steps as a history. The planner ensures
that this sequence corresponds to the canonical history of the leaf
that is being planned for, so we can be sure that the test will hold
in all possible histories of the leaf if it holds in the given canonical
history.

We say that two steps are \emph{ordered} if any of the following holds:
their action terms are not independent; one's thread is a prefix of
the other; one's action falsifies the test condition associated with
the other. When building a joint execution, ordered steps are forced
to be executed in the order they were generated by the planner, while
unordered steps may be performed independently.


\subsection{Building Joint Executions}

Our implementation builds up joint executions by inserting one action
at a time, in much the same way that the standard Golog planning loop
builds up situation terms. The procedure $Insert$ is called with
the step object whose action is to be inserted, the leaf for which
it is a new step, and a function that will be used to determine the
action's enablers. The joint execution automatically determines the
possible outcomes of the action and inserts corresponding outcome
events.

\programinput{listings/jointexec/JointExec.oz}

The call to $FixActionInvariants$ ensures that the joint execution
remains feasible, by inserting additional action events if it discovers
two histories that have identical views for the performing agent.
Currently this is done using a brute-force search through all possible
histories, but it is able to prune many histories that are known now
to include the required observations.

When determining the enablers for a new action, the joint execution
has potentially many choices, and generates choice points accordinly.
It processes all existing events on the leaf in turn, first checking
if they are \emph{orderable} according to the restrictions on feasible
joint executions. If they are orderable, the function $MustPrec$
is called to determine whether they must be ordered according to the
semantics of the program. If they are orderable, but need not be ordered,
a choice point is generated.

\programinput{listings/jointexec/FindEnablers.oz}


\subsection{Planning Loop}

The main execution planning loop operates by building up a joint execution
one leaf at a time. At each iteration, the current state of the plan
is represented by the joint execution build so far, along with a list
of program\#history\#leaf tuples tracking each leaf in the joint execution.
The history here corresponds to the canonical history of the leaf,
and the program represents what remains to execute on that leaf. The
planning loop can only terminate when each leaf has a program that
is final in its canonical history.

The top level procedure $Plan$ takes a program as input, and calls
$MakePlan$ with an empty joint execution and a single, empty leaf:

\programinput{listings/jointexec/Planner.oz}

$MakePlan$ is a recurisve proceeding implementing the planning loop:

\programinput{listings/jointexec/MakePlan.oz}

Each iteration of the planning loop proceeds as follows. First, it
searches for an \emph{open leaf,} one for which a terminating execution
of the program has not yet been found. If no open leaves are found,
planning can terminate. Otherwise, the procedure $FindTrans1$ is
called to find a new step of execution for that leaf. The action is
inserted into the joint execution, which returns a list of new leaves,
one for each possible outcome of the action. Each of these outcomes
is added to the list of leaves to be processed, and the loop repeats.

The procedure to find an open leaf must also deal with any new events
that were inserted into the joint execution to maintain its feasibility
invariants. The procedure $HandleExistingEvents$ rolls the leaf forward
to account for these new events, or fails if an event was added that
does not for part of a legal program execution.

\programinput{listings/jointexec/FindOpenBranch.oz}

Of particular interest is the procedure $FindTrans1$, which uses
the encapsulated search functionality of Mozart to yield possible
next steps according to an estimate of their potential for concurrency.
The procedure $LP.yieldOrdered$ yields the solutions of the given
search context, sorted using the procedure $CompareSteps$. This procedure
(not shown) gives preference to steps that can be performed concurrently
with as many existing actions as possible.

\programinput{listings/jointexec/FindTrans1.oz}

This use of encapsulated search allows our implementation to find
highly concurrent executions, such as the one shown in Figure \eqref{fig:JE:MakeSalad2-Exec}.


\section{Discussion\label{sec:JointExec:Discussion}}

In this chapter we have defined a \emph{joint execution} as a special
kind of prime event structure. We contend that such structures are
highly suitable for planning the actions to be performed by a team
of agents in service of some shared task, such as executing a shared
Golog program.

On one hand, joint executions are restricted enough to be practical
for such use. By ensuring that the joint execution is \emph{feasible},
the agent are guaranteed to be able to carry it out in a purely reactive
fashion using only their local information. By restricting ourselves
to \emph{reasonable }joint executions, each leaf can be easily converted
into a single history term for the purposes of reasoning, and can
be extended one action at a time.

Joint executions are also significantly more flexible than previous
approaches. They allow independent actions to be performed without
synchronisation, in any order. The agents need never know precisely
what actions have been executed, only those that enable them to perform
their next action. Synchronisation is automatically achieved when
required by explicitly reasoning about what actions each agent can
observe, rather than requiring that all actions be public.

To demonstrate the utility of these structures, we have implemented
a new version of our MIndoGolog interpreter that produces joint executions
as its output, and demonstrated they the resulting executions can
enable significant independence among agents when cooperative executing
the plan.\\


An alternate approach to coordinating concurrent execution in Golog-like
languages is the TeamGolog language developed in \citep{farinelli07team_golog},
where agents explicitly synchronise through communication and a shared
state. By contrast, our approach constructs synchronisation implicitly
by reasoning about the actions that can be observed by each agent.
This has the advantage of requiring no changes to the form or semantics
of the agents' control program, but the disadvantage that joint execution
construction may fail if too many actions are unobservable. It would
be interesting to combine these approaches by automatically incorporating
explicit communication when implicit synchronisation is not possible.

There is, of course, an extensive body of work on partial-order planning
in the context of goal-based planning. Unsurprisingly, the joint execution
structure we develop here has deep similarities to the structures
used in conditional partial-order planners such as \citep{peot92conditional_nonlinear}.
It is, however, intentionally specific to the situation calculus.
We make no use of many concepts common in partial-order goal-based
planning (causal links, threats, conflicts, etc) because we do not
deal explicitly with goals, but with steps generated by an underlying
transition semantics. Our approach can be considered roughly equivalent
to \emph{deordering} of a totally-ordered plan as described in \citep{backstrom99reordering}
-- we plan as if actions are performed in the specific order identified
by the canonical leaf history, but allow actions to be performed out-of-order
if they are independent.

Our use of a restrictive plan representation that branches directly
on the sensing results returned by actions has strong paralles with
the {}``robot programs'' of \citep{levesque96what_is_planning,levesque05planning_with_loops},
but is significantly less expressive. In particular, joint executions
do not allow looping constructs and thus lack the universality of
general robot programs. It would be interesting to incorporate loops
in our structures, but how to do so if far from clear in the face
of partial observability.

TODO: don't use explicit mental attitudes, mutual beliefs etc. JE's
more akin to recipes in SharedPlans. Assume agents all have the common
goal of executing the given shared program. But it could be used as
part of larger system.

By explicitly formalising the local perspective of each agent, we
have given an account of planning with coordination and feasibility
guarantees without needing to perform explicit epistemic reasoning.
On the one hand, this means we can implement a practical planning
system without concern for the compuational difficulties involved
in epistemic reasoning. But this has also limited us to purely offline
planning, when each agent can reasonably be expected to have the same
knowledge about the domain.

As discuss in Section TODO, extending the use of joint executions
for online execution in asyncrhonous domains poses a significant challenge,
and seems to require explicit reasoning about knowledge and common
knowledge. The remainder of this thesis is devoted to developing the
beginnings of such a reasoning system.


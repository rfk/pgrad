

\chapter{Joint Executions}

\label{ch:jointexec}

This chapter constructs a new representation for the actions to be
performed by a team of agents during the cooperative execution of
a shared task. Dubbed \emph{joint executions}, they are partially-ordered
branching sequences of events. Joint executions allow independent
actions to be performed independently, while using each agent's local
view to ensure that synchronisation is always possible when required.

The output of the standard Golog execution planning process is a raw
situation term; a complete, ordered sequence of all actions that are
to be performed. This is suboptimal for representing plans in an asynchronous
multi-agent setting in three ways:

\begin{itemize}
\item it does not permit branching to utilise information obtained at run-time 
\item it enforces a strict execution order on actions that are potentially
independent, requiring inter-agent synchronisation when it is not
actually necessary 
\item it requires a strict execution order on actions that may be unobservable,
demanding inter-agent synchronisation that is not actually feasible 
\end{itemize}
As we have demonstrated in Chapter \ref{ch:mindigolog}, restricting
the domain to be synchronous and completely known lets the agents
make effective use of raw situation terms for planning. In asynchronous
domains with incomplete knowledge they are no longer sufficient, and
the Golog execution planner is required to generate a much richer
representation of the actions to be performed.

To build such a representation, we take inspiration from a model of
concurrent computation known as \emph{prime event} \emph{structures},
which are partially-ordered branching sequences of events \citep{npw79event_structures}.
A \emph{joint execution} is defined as a particular kind of prime
event structure that is rich enough to capture the concurrent execution
of independent actions, and can branch on the results of sensing actions.
We use our explicit account of an agent's local view to identify joint
executions that can feasibly be executed based on the local information
available to each agent at runtime.

Joint executions are formalised in a way that translates well into
an implementation. They can be built up one action at a time in much
the same way as ordinary situation terms. If the theory of action
meets some simple restrictions, joint executions can also be reasoned
about using standard regression techniques. We demonstrate an implementation
that performs offline execution planning for an asynchronous, partially
observable domain, and discuss the challenges faced when attempting
a cooperative online execution in an asynchronous domain.

Joint executions thus allow us to represent the actions that a team
of agents are to perform in service of some shared task, without requiring
constant synchronisation between the agents, and without assuming
that agents know all the actions that have been performed, while utilising
existing reasoning methods and planning machinery. This is a significant
increase in power over existing approaches to planning for multi-agent
teams in the situation calculus.

The chapter proceeds as follows: after some more detailed background
information in Section \ref{sec:JointExec:Background}, we formally
define and axiomatise joint executions in Section \ref{sec:JointExec:JEs}.
Section \ref{sec:JointExec:Planning} then characterises the Golog
execution planning problem in terms of joint executions rather than
raw situation terms, and Section \ref{sec:JointExec:Reasonable} identifies
a restricted kind of joint execution that can be reasoned about effectively
using standard regression techniques. In Section \ref{sec:JointExec:Implementation}
we present an overview of our new MIndiGolog execution planner that
generates joint executions, and show some examples of its output.
Finally, Section \ref{sec:JointExec:Discussion} concludes with some
general discussion and an outline of our ongoing work in this area.


\section{Background\label{sec:JointExec:Background}}

The above discussion highlights three important properties of a plan
representation formalism intended for use in asynchronous multi-agent
domains: it must be \emph{partially-ordered} to allow agents to operate
independently, \emph{branching} to allow information to be collected
at run-time, and \emph{feasible to execute} based on the local information
available to each agent. While each of these aspects have been studied
in isolation in the situation calculus, our work is the first to combine
them into a single formalism that is suitable for asynchronous multi-agent
domains.


\subsection{Partial Ordering}

There has been little work on partial-order planning in the situation
calculus, most likely because the use of situations heavily biases
the reasoning machinery towards totally-ordered sequences of actions.
While \citet{son00htn_golog} allow the programmer to specify a partial
order on action by adding operators to the Golog language, the actual
plans produced by their system are still raw situation terms. One
exception is \citep{plaisted97sc_aspect}, which extends the situation
calculus with explicit {}``aspects'' and allows partial ordering
between actions that affect different aspects of the world state.
By contrast, we seek to leverage the existing meta-theory of the standard
situation calculus.

Partial-order planning is the mainstay of the closely-related \emph{event
calculus} formalism \citep{kowalski86event_calculus}. In this formalism,
actions are represented as occurring at specific times, rather than
in a specific order as in the situation calculus. Constraints placed
on the relative occurrence times of actions then determine a partial
ordering. \citet{Shanahan97ec_planning} has shown that abductive
theorem proving in the event calculate generates partially-ordered
plans, and the mechanics of the theorem prover naturally mirror various
concepts from the goal-based partial-order planning literature, such
as conflicts, threats and links \citep{peot92conditional_nonlinear}.

The close similarities between the situation and event calculi are
well understood, as are the advantages of the event calculus when
working with partially-ordered action sequences \citep{belleghem97sitcalc_evtcalc}.
Indeed, it is possible to implement a Golog interpreter on top of
the event calculus, and the execution plans it generates are partially-ordered
sets of actions \citep{pereira04ec_golog}. Perhaps we should simply
adopt a formalism such as the event calculus that is naturally partially-ordered,
rather than trying to construct a partially-ordered representation
on top of the naturally sequential situation calculus?

Having a partial-order representation is important, but it is not
the complete picture. While we don't want the agents to have to synchronise
their actions unnecessarily, we also need to ensure the converse:
that when an explicit ordering between actions is \emph{necessary},
the required synchronisation is actually \emph{feasible} based on
the local information available to each agent. It is not clear how
techniques such as \citep{pereira04ec_golog} would extend to the
asynchronous multi-agent case.

By taking advantage of our explicit account of the local information
available to each agent, the formalism developed in this chapter enables
these dual requirements - that some actions don't need to be ordered,
while other actions must not be ordered - to be captured in an elegant
way. Moreover, we do not need to step outside the bounds of existing
situation calculus theory, and can utilise existing techniques for
effective automated reasoning.


\subsection{Branching}

Several single-agent formalisms based on the situation calculus have
introduced some form of branching into the structures returned by
the planner, including the conditional action trees of of sGolog \citep{lakemeyer99golog_cats}
and the branching IndiGolog plans of \citep{giacomo04sem_delib_indigolog}.
These structures typically branch based on the truth or falsehood
of test conditions included in the program. For example, the structural
definition of conditional action trees in \citep{lakemeyer99golog_cats}
includes the following branching case:\[
c=[\phi,c_{1},c_{2}]\]


This instructs the agent to execute the sub-tree $c_{1}$ if $\phi$
is true and the sub-tree $c_{2}$ if $\phi$ is false. An alternate
approach, exemplified by the {}``robot programs'' of \citep{levesque98what_robots_can_do},
is to have the plan branch directly on the results returned by actions
rather than on a test condition. Branching on the binary result of
a sensing action is represented in this formalism by the following
structure:\[
branch(action,\delta_{1},\delta_{2})\]


Here the agent continue execution with program $\delta_{1}$ if the
action returns true, and with $\delta_{2}$ if the action returns
false. Branching directly on the results of actions typically leads
to longer plans, but is easier for the agent to execute at runtime.


\subsection{Feasibility\label{sec:JointExec:BG:Feasibility}}

To allow an agent to execute a plan that depends on information collected
at run-time, it is not sufficient to simply introduce branching into
the plan representation formalism. One must also ensure that, at execution
time, the agent will always \emph{know} which branch of the plan to
take. For example, suppose this simple branching plan will provably
achieve a goal:\[
\mathbf{if}\,\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


The agent can only execute this program if it knows whether or not
$\phi$ holds; otherwise, although one of the branches is guaranteed
to achieve the goal, the agent does not know which branch to take.
Feasibility is typically guaranteed by including sensing actions to
ensure that the test conditions become known when needed:\[
sense_{\phi}\,\,;\,\mathbf{if\,}\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


This requirement that an agent {}``knows how'' to execute a plan
is formalised by various notions of \emph{epistemic feasibility},
including those of \citep{levesque98what_robots_can_do,levesque00knowing_how,Lesperance01epi_feas_casl,giacomo04sem_delib_indigolog,baier06programs_that_sense}.

One approach to ensuring feasibility, embodied by \citep{levesque00knowing_how,giacomo04sem_delib_indigolog,baier06programs_that_sense},
is to represent plans by arbitrary programs formulated in a control
language such as Golog. One then semantically characterises the class
of epistemically feasible programs, using direct assertions about
the knowledge of each agent at each stage of execution. While this
allows for potentially very rich, very succinct plans, it is not clear
how to systematically generate an epistemically feasible plan using
such a general characterisation.

Another approach, advocated by \citep{levesque96what_is_planning,levesque98what_robots_can_do}
and used in the implementation section of \citep{giacomo04sem_delib_indigolog},
is to restrict the structure of plans so that they are always epistemically
feasible. For example, the {}``robot programs'' of \citep{levesque98what_robots_can_do}
are restricted to simple operators such as:\begin{gather*}
action\\
seq(\delta_{1},\delta_{2})\\
branch(action,\delta_{1},\delta_{2})\\
loop(branch(action,\delta,exit))\end{gather*}


These programs do not contain test conditions, but rather branch and
loop directly according to the sensing results returned from each
action. There is therefore no potential for confusion when executing
such programs; they are essentially equivalent to a kind of finite
automaton that can be executed reactively. Nevertheless, \citet{levesque98what_robots_can_do}
show that these programs are universal, in the sense that any achievable
goal can be achieved by suitable a robot program. We are not aware
of any work extending this approach to represent programs intended
for cooperative execution by a team of agents.

These existing notions of epistemic feasibility can be broadly characterised
as \emph{knowing what}. At each stage of execution, each agent must
know what its next action is. In synchronous domains with public actions,
as typically studied in the situation calculus, this is sufficient
to ensure the feasibility of executing a plan.

In asynchronous domains it is not enough for an agent to know \emph{what}
its next action is; it must also know \emph{when} that action should
be performed. For example, suppose that the following simple plan
provably achieves a goal:\[
action_{1}(agt_{1})\,;\, action_{2}(agt_{2})\]


In a synchronous domain this plan can be executed directly. But suppose
the domain is asynchronous, and $agt_{2}$ is unable to observe the
occurrence of $action_{1}$. Since $agt_{2}$ has no way of knowing
whether or not $action_{1}$ has been performed yet, it will not know
when to perform $action_{2}$ and the plan cannot be executed.

In this chapter we ensure plan feasibility by restricting the structure
used to represent plans, in an approach similar to \citep{levesque98what_robots_can_do}
but without looping constructs. We use the explicit account of an
agent's local view developed in the previous chapter to ensure that
each agent will always have enough information to determine what action
to perform next, and when to perform it.


\subsection{Event Structures}

To tackle cooperative execution in a multi-agent setting, we have
adopted a model of concurrent computation known as \emph{event structures}
\citep{npw79event_structures}. The particular variant we are interested
in are \emph{prime event structures}, which are defined as follows.

\begin{defnL}
[{Prime~Event~Structure}] A prime event structure is a
four-tuple $(\mathcal{V},\gamma,\prec,\oplus)$ where: $\mathcal{V}$
is a set of events; $\gamma$ is a function assigning a label to each
event; $\prec$ is the precedence relation, a strict partial order
on events; $\oplus$ is the conflict relation, a binary symmetric
relation indicating events that are mutually exclusive. 
\end{defnL}
The labels assigned by $\gamma$ give the action associated with each
event. By using a labelling scheme rather than identifying events
directly with actions, multiple events can result in the same action
being performed. The precedence relation restricts the order in which
events can occur, so that if $e1\prec e2$ then $e1$ must occur before
$e2$. The conflict relation allows the structure to represent branching,
by having the occurrence of some events preclude the occurrence of
others.

Figure \ref{fig:example-pes} shows a simple example of a prime event
structure. The arrows represent the precedence relation, so in this
diagram we have $e1\prec e3\prec e7$, but $e3\not\prec e4$. The
conflict relation is represented using a dotted line, so we have $e2\oplus e3$
and only one of these two events is permitted to occur. Conflict is
also inherited through the precedence relation, so $e6\oplus e7$
in this diagram.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/example_pes}}}
\par\end{center}%
\end{minipage}}
\par\end{centering}

\caption{An example Prime Event Structure.}


\label{fig:example-pes} 
\end{figure}


As it can be cumbersome to specify $\prec$ and $\oplus$ in their
entirety, we will instead specify only the direct \emph{enablers}
and \emph{alternatives} for each event, denoted by $ens(i)$ and $alts(i)$
respectively. Construction of $(\prec,\oplus)$ from $(ens,alts)$
is a straightforward transitive closure. Indeed, it only the enablers
and alternatives that are represented explicitly in Figure \ref{fig:example-pes},
by arrows and dotted lines respectively.

A \emph{configuration} is a sequence of events consistent with $\prec$
in which no pair of events conflict. Each configuration represents
a potential partial run of execution of the system. Event structures
thus form a directed acyclic graph of the events that could occur
during execution of the system. As shown in \citep{pratt91modeling_conc_with_geom},
these structures are a canonical representation of a variety of formalisms
for representing concurrent execution, and it is straightforward to
execute them in a purely reactive fashion.


\section{Joint Executions\label{sec:JointExec:JEs}}

This section defines \emph{joint execution}s as a restricted kind
of prime event structure capable of capturing the actions of a team
of agents in an asynchronous domain. We begin with a high-level intuitive
description to motivate these structures, and then formally define
them using a set of axioms to be included in the theory of action
$\Dt$. Since we intend for agents to synthesise joint executions
as the output of a planning process, they must exist as concrete terms
in the logic.


\subsection{Motivation}

To make things more concrete, consider again the {}``cooking agents''
example domain from Chapter \ref{ch:mindigolog} and the $MakeSalad$
program shown in Figure \ref{fig:MIndiGolog:MakeSalad}. In a completely-known,
synchronrous domain, the execution found for this program by our MIndiGolog
interpreter was a linear sequence of concurrent actions as shown in
Figure \ref{fig:MIndiGolog:MakeSalad-in-MIndiGolog} on page \pageref{fig:MIndiGolog:MakeSalad-in-MIndiGolog}.

Let us now suppose that the cooking agents doman is asynchronous,
with all actions other than $release$ and $acquire$ being private.
The execution found by a MIndiGolog interpreter for such a domain
cannot assume that the agents perform their actions in lock-step.
Rather, it should allow the agents to process their respective ingredients
independently, syncrhonising their actions only on the $release$/$acquire$
sequence necessary to gain control of shared utensils.

An appropriate partially-ordered representation of the actions to
be performed for $MakeSalad$ would then look something like the structure
shown in Figure \ref{fig:JE:MakeSalad1}. For simplicity, we do not
consider time or natural actions in this chapter, and have collapsed
the {}``mix'' and {}``chop'' tasks into primitive actions. Without
expanding on the details at this stage, it should be clear that this
structure captures the same basic workflow as the syncrhonous execution
of $MakeSalad$ from Chapter \ref{ch:mindigolog}, but without imposing
a strict ordering between the actions of different agents.

Indeed, Figure \ref{fig:JE:MakeSalad1} is the joint execution produced
for the $MakeSalad$ program by the new execution planner detailed
in Section \ref{sec:JointExec:Implementation}, although with some
of its details suppressed. It may be helpful to keep this structure
in mind as we develop the formal definitions contained in this section.

%
\begin{figure}[!h]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25]{listings/jointexec/salad1_plan}}}
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad$ Program}


\label{fig:JE:MakeSalad1} 
\end{figure}



\subsection{Intuitions}

We define a joint execution as a special kind of prime event structure
as follows:

\begin{defnL}
[{Joint~Execution}] A joint execution is a tuple $(\mathcal{A},\mathcal{O},ens,alts,\gamma,<)$
where: action events $\mathcal{A}$ represent actions to be performed;
outcome events $\mathcal{O}$ represent possible outcomes of actions;
$(\mathcal{A}\cup\mathcal{O},ens,alts,\gamma)$ forms a prime event
structure with precedence relation $\prec$; $<$ is a total order
on events that is consistent with $\prec$. 
\end{defnL}
A joint execution contains two disjoint sets of events: \emph{action}
events $\mathcal{A}$ representing the actions to be performed, and
\emph{outcome} events $\mathcal{O}$ representing the possible outcomes
of each action. For each action event $i\in\mathcal{A}$, its enablers
$ens(i)$ is a set of outcome events, its alternatives $alts(i)$
is empty, and its label $\gamma(i)$ is the action to be performed.
For each outcome event $i\in\mathcal{O}$, $ens(i)$ is a single action
event for which it is a possible outcome, $alts(i)$ is the set of
all other outcome events $j$ such that $ens(j)=ens(i)$, and $\gamma(i)$
is an outcome as produced by the $Outcome(a,s)$ function for the
action $\gamma(ens(i))$.

Each action event thus represents a single action to be performed,
which enables several alternative outcome events corresponding to
the potential results returned by that action; since the action can
only produce one actual outcome when it is executed, the enabled outcome
events are all mutually conflicting. Each of these outcome events
can then enable further action events, and so forth.

%
\begin{figure}[!b]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/example_je}}}{\tiny {} }%
\end{minipage}}

\caption{A simple joint execution.}


\label{fig:example-je} 
\end{figure}


A simple example of a joint execution is shown in Figure \ref{fig:example-je},
again using the {}``cooking agents'' example domain. Here elliptical
nodes are action events and box nodes are the resulting outcome events.
The action $checkFor$ senses the presence of a type of ingredient,
returning either $T$ or $F$, and thus producing two conflicting
outcome events. In this example the agent $Jim$ senses for the availability
of eggs, and if this returns true he acquires one; otherwise, he acquires
a tomato. Meanwhile agent $Joe$ acquires a lettuce, independently
of the actions $Jim$ is performing.

Since we are explicitly considering concurrent actions, there are
many different possible ways that the events in this structure could
translate into action occurrences. The independent actions $checkFor(Jim,Egg)$
and $acquire(Joe,Lettuce1)$ could be performed in either order, or
even concurrently.

These structures are clearly much richer than ordinary situation terms,
as they permit branching and partial-ordering between actions. Still,
they correspond to sets of ordinary situation terms in a straightforward
way. Recall that a \emph{configuration} is a partial run of execution
of a prime event structure. Clearly any configuration ending in an
outcome event corresponds to a unique situation term and also a unique
history term, as it is a sequence of alternating actions and their
outcomes.

We will call a set of unordered, non-conflicting outcome events a
\emph{branch}. A branch identifies a set of partial runs of the joint
execution. In Figure \ref{fig:example-je}, the sets $\{O3\}$, $\{O1,O3\}$
and $\{O5,O3\}$ are examples of branches. A \emph{leaf} is a special
case of a branch, where every event is either in the leaf, conflicts
with something in the leaf, or precedes something in the leaf; it
thus represents potential \emph{terminating} runs of the joint execution
execution. In Figure \ref{fig:example-je} there are two leaves, $\{O3,O4\}$
and $\{O3,O5\}$, generated by the two alternate outcomes of the $checkFor$
action.

A \emph{history} of a branch is a history term (as defined in Chapter
\ref{ch:observations}) that can be generated by performing actions
and observing outcomes from the joint execution until all events in
the branch have occurred. By these definitions, the set of histories
of all leaves gives every possible history that could be produced
by performing the joint execution through to a terminating configuration.

A joint execution has one additional component over a standard prime
event structure: a \emph{total} order on events $<$ that is consistent
with the partial order $\prec$ induced by the enabling relation.
We call this the \emph{canonical ordering}, and it allows any branch
to be unambiguously translated into a single \emph{canonical history}.
When we come to use joint executions for planning, we will use the
canonical history to avoid having to reason about all the (potentially
exponentially-many) histories of each leaf. The canonical ordering
is essentially arbitrary; in practice it is determined by the order
of insertion of events into the structure.


\subsection{Structural Axioms}

We introduce new sorts \noun{Event }and \noun{JointExec} to $\Lsit$,
and will collect the axioms defining joint executions in a separate
axiom set $\Dt_{je}$. Events are opaque identifiers with which a
joint execution associates a label, a set of enablers, and a set of
alternatives. For simplicity we will identify events with the integers,
although our definitions require only the successor function and ordering
relation. Labels are either \noun{Action} or \noun{Outcome} terms.
A joint execution is then a term containing:

\begin{itemize}
\item a set of \emph{events}, which are integer ids 
\item a mapping from each event to a \emph{label}, which is either an action
or an outcome 
\item a mapping from each event to its \emph{enablers}, a set of lower-numbered
events 
\item a mapping from each event to its \emph{alternatives}, a set of events 
\end{itemize}
We will use the function $jexec$ as a constructor for joint execution
terms, specifying each of the four features above as an argument,
and using sets of $key\#value$ pairs to represent a mapping as in
the previous chapter.

First, we require a unique names axiom to specify that a joint execution
is uniquely defined by its four components, and a domain closure axiom
to specify that all joint executions are constructed in this way.
Assuming the variables are restricted to the appropriate sorts, the
following axioms suffice:\begin{gather*}
\forall ex:\,\exists es,ls,ns,as:\,\, ex=jexec(es,ls,ns,as)\\
\\jexec(es,ls,ns,as)=jexec(es',ls',ns',as')\,\equiv\,\,\,\,\,\,\,\,\\
\,\,\,\,\,\,\,\, es=es'\wedge ls=ls'\wedge ns=ns'\wedge as=as'\end{gather*}


We introduce four functions to access the components of a joint execution:\begin{gather*}
events(ex)=es\,\equiv\exists ls,ns,as:\, ex=jexec(es,ls,ns,as)\\
lblmap(ex)=ls\,\equiv\exists es,ns,as:\, ex=jexec(es,ls,ns,as)\\
ensmap(ex)=ns\,\equiv\exists es,ls,as:\, ex=jexec(es,ls,ns,as)\\
altsmap(ex)=as\,\equiv\exists es,ls,ns:\, ex=jexec(es,ls,ns,as)\end{gather*}


We also define the following shortcut accessors to get the value from
each mapping for a particular event $i$:\begin{gather*}
lbl(ex,i,l)\equiv i\#l\in lblmap(ex)\\
ens(ex,i,ns)\equiv i\#ns\in ensmap(ex)\\
alts(ex,i,as)\equiv i\#as\in altsmap(ex)\end{gather*}


For notational convenience we will often write these as functions,
e.g. $ens(ex,i)=ns$ rather than $ens(ex,i,ns)$, but this should
be understood as an abbreviation since not every joint execution will
contain every event.

We must also define the \emph{precedes} and \emph{conflicts} relations
in terms of enablers and alternatives. These will be written as binary
infix operators $\prec_{ex}$ and $\oplus_{ex}$ respectively. Since
they are transitive closures they require a second-order axiomatisation.
First, the precedence relation is defined as a simple transitive closure
over enablers:\begin{multline*}
\forall P,ex,i,j:\left[\left(i\in ens(ex,j)\,\rightarrow P(i,j)\right)\wedge\left(\forall k:P(i,k)\wedge k\in ens(ex,j)\rightarrow P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\prec_{ex}j\right)\end{multline*}


Then we can define the conflict relation by specifying that $i\oplus_{ex}j$
if they are alternatives to each other, or they have conflicting predecessors:\begin{multline*}
\forall P,ex,i,j:\,\left[\left(i\in alts(ex,j)\,\rightarrow P(i,j)\right)\right.\\
\left.\wedge\,\left(\forall i',j':\, P(i',j')\wedge i'\preceq_{ex}i\wedge j'\preceq_{ex}j\,\rightarrow\, P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\oplus_{ex}j\right)\end{multline*}


Next we need axioms defining our terminology of \emph{branches} and
\emph{leaves}. A branch is a set of unordered non-conflicting outcome
events:\begin{multline*}
Branch(ex,br)\,\equiv\,\forall i,j\in br:\, IsOutcome(lbl(ex,i))\wedge IsOutcome(lbl(ex,j))\\
\wedge\,\neg(i\oplus_{ex}j)\,\wedge\, i\not\prec_{ex}j\,\wedge\, j\not\prec_{ex}\, j\end{multline*}


A \emph{leaf} is defined as a special case of a branch, so that everything
either precedes or conflicts with something in the leaf:\begin{multline*}
Leaf(ex,lf)\,\equiv\, Branch(ex,lf)\\
\wedge\forall i\in events(ex):\, i\in lf\,\equiv\,\neg(\exists i'\in lf:\,\, i\oplus_{ex}i'\,\vee\, i\prec_{ex}i')\end{multline*}


Finally, we say a joint execution is \emph{proper} if it respects
the basic structural intuitions we discussed in the previous section.
Every event must be proper according to its type, and events cannot
be enabled by higher-numbered events:\begin{gather*}
Proper(ex)\,\equiv\,\forall i\in events(ex):\, ProperAct(ex,i)\vee ProperOut(ex,i)\\
\wedge\forall i,j:\,\left(i\in events(ex)\wedge j\in ens(ex,i)\,\rightarrow\, j<i\right)\end{gather*}


Note that this does not result in a loss of expressivity, since we
we want event $i$ to preceed event $j$, then $j$ cannot also preceed
$i$ and we simply give $j$ the higher event number. This restriction
will play an important role in Section \ref{sec:JointExec:Reasonable}.

An action event is proper if it has no alternatives, enables at least
one outcome event, and is enabled by a branch. Restricting the enablers
to be a branch ensures that they do not contain any redundant or conflicting
information.\begin{gather*}
ProperAct(ex,i)\,\equiv\, IsAction(lbl(ex,i))\\
\wedge Branch(ex,ens(ex,i))\wedge alts(ex,i)=\{\}\wedge\exists j:\, ens(ex,j)=\{i\}\end{gather*}


An outcome event is proper if it is enabled by a unique action event,
and has as its alternatives the set of all other events enabled by
that action.\begin{gather*}
ProperOut(ex,i)\,\equiv\, IsOutcome(lbl(ex,i))\\
\wedge\exists j:\, ens(ex,i)=\{j\}\wedge IsAction(lbl(ex,j))\\
\wedge\forall k:\,\left(k\in alts(ex,i)\,\equiv\, ens(ex,k)=\{j\}\right)\end{gather*}


These definitions enforce the basic structure of a joint execution
according to the intuitions discussed in the previous section, but
do not constrain it to be something that could actually be performed
in the world -- for example, outcomes can be enabled by actions that
will never actually produce that outcome. Like situation terms, we
focus first on getting the appropriate structure, and then specify
additional conditions that joint executions must satisfy in order
to be legal in the real world.


\subsection{Performing Events}

We introduce a predicate $Perform$ that axiomatises how events from
a joint execution can be performed. Since we explicitly consider concurrent
actions, this predicate selects a \emph{set }of action events to be
performed. \begin{gather*}
Perform(ex,es_{a},es_{o},ex')\equiv\,\,\,\,\, es_{a}\neq\{\}\wedge es_{o}\neq\{\}\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\, IsAction(lbl(ex,i))\wedge ens(ex,i)=\{\}\right)\\
\wedge\,\forall i:\,\left(i\in es_{o}\,\rightarrow\exists j:\, ens(ex,i)=\{j\}\wedge j\in es_{a}\right)\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\,\exists j:\, j\in es_{o}\wedge ens(ex,j)=\{i\}\right)\\
\wedge\,\forall i,j:\,\left(i\in es_{o}\wedge j\in es_{o}\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall i:\,\left(i\in events(ex')\,\equiv\, i\not\in es_{a}\wedge i\not\in es_{o}\wedge\neg\exists j:\,(j\in es_{o}\wedge i\oplus_{je}j)\wedge\right)\\
\wedge\,\forall i,lb:\,\left(i\#lb\in lblmap(ex')\equiv\, lbl(ex,i)=lb\wedge i\in events(ex')\right)\\
\wedge\,\forall i,as:\,\left(i\#as\in altsmap(ex')\equiv alts(ex,i)=as\wedge i\in events(ex')\right)\\
\wedge\,\forall i,ns:\,\left(i\#ns\in ensmap(ex')\equiv(ens(ex,i)-es_{o})=ns\wedge i\in events(ex')\right)\end{gather*}


The first four lines of this definition select $es_{a}$ and $es_{o}$
as sets of action and outcome events respectively. The events in $es_{a}$
are any subset of the action events in the joint execution that have
no enablers, and are therefore possible to perform. The set $es_{o}$
then contains one outcome event enabled by each event in $es_{a}$.

The remaining four lines specify how the events remaining in the joint
execution are updated -- events that conflict with the performed events
are removed, and the performed events are removed from the enablers
lists. 

As an example, consider again the simple joint execution shown in
Figure \ref{fig:example-je}. The possible values of $es_{a}\#es_{o}$
generated by $Perform$ for this joint execution are:\begin{gather*}
\{A1\}\#\{O1\}\\
\{A1\}\#\{O2\}\\
\{A2\}\#\{O3\}\\
\{A1,A2\}\#\{O1,O3\}\\
\{A1,A2\}\#\{O2,O3\}\end{gather*}


This predicate is clearly quite non-deterministic, permitting any
subset of the enabled events to be performed. The different choices
made by $Perform$ correspond to different potential orderings of
events when performing the joint execution.


\subsection{Histories}

Every branch identifies a family of potential partial runs of the
execution, which are given by the branch's \emph{histories}. The predicate
$History$ constructs a branch history by recursively performing events
that do not conflict with the branch, until all events in the branch
have been performed. This predicate depends on $Perform$ to identify
an enabled set of action events $es_{a}$ and outcome events $es_{o}$,
the labels of which are translated into action and outcome terms $c$
and $y$ respectively. \begin{gather*}
History(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


Note that the action term $c$ is constructed as the union of the
individual actions attached to each event in $es_{a}$, and the corresponding
outcome term $y$ is the agent-wise union of the outcomes attached
to each event in $es_{o}$. Such pairs $c\#y$ are repeatedly selected
until every event in the branch has been performed.

Clearly, if there are many events that can happen in either order,
there are many potential histories for a given branch; in fact there
may be exponentially-many histories in general. In Section \ref{sec:JointExec:Reasonable}
we show how to avoid reasoning about each history individually, which
is crucial if these structures are to be of practical use. Instead,
we reason about only the \emph{canonical} \emph{history, }the unique
history obtained by perform events in the strict order determined
by the $<$ relation:\begin{gather*}
CHistory(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\exists i:\, es_{a}=\{i\}\wedge\forall j\in events(ex):\, i<j\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


For convenience, we also define a predicate $Sit$ that gives the
situation terms corresponding to the branch histories:\[
Sit(ex,br,s)\,\equiv\,\exists h:\, History(ex,br,h)\wedge Sit(h,s)\]



\subsection{The Agent-Local Perspective}

Since we intend for joint executions to be performed reactively by
a team of agents in an asynchronous environment, we must also formalise
the relationship between a joint execution and each agent's local
view. First, we define the $View$ function over a history in the
obvious way:\begin{gather*}
View(agt,\epsilon)=\epsilon\\
y[agt]=\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=View(agt,h)\\
y[agt]\neq\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=y[agt]\cdot View(agt,h)\end{gather*}


We will say that an action event $i$ is \emph{enabled by a view}
if there is a history of its enablers that corresponds to that view:
\[
EnabledByView(ex,i,agt,v)\equiv\exists h:\, History(ex,ens(ex,i),h)\wedge View(agt,h)=v\]


Since an agent's view does not have complete information, $EnabledByView$
identifies events that \emph{might} be enabled given the agent's local
information. Since agents can only be expected to act based on their
local information, we will need to further restrict the structure
of joint executions so that this information is sufficient for performing
the joint execution.


\subsection{Feasible Joint Executions}

We are now in a position to restrict joint executions so that they
are \emph{feasible}, meaning that the agents would actually be able
to cooperatively perform them in the world. This is accomplished using
two structural restrictions.

The first restriction corresponds to the idea of \emph{knowing when}
to perform an action. If an action event $i$ is enabled by an outcome
event $j$, then $j$ must not be hidden from the agent performing
$i$. Otherwise, it has no way of enforcing the required ordering
between the two events. Let $actor(ex,i)$ be the agent responsible
for performing an action event $i$, then we have the following requirment:\begin{multline*}
KnowsWhen(ex)\,\isdef\,\\
\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\,\wedge j\in ens(ex,i)\\
\rightarrow\, lbl(ex,i)[actor(ex,i)]\neq\{\}\end{multline*}


Figure \ref{fig:not-knows-when} shows an example of a joint execution
that does not meet this requirement. This plan calls for $Jim$ to
place an egg in the bowl, and then for $Joe$ to mix the bowl's contents.
However, since $Joe$ cannot observe the occurrence of $Jim$'s action,
he cannot enforce the ordering between these two events and the plan
cannot be executed.

%
\begin{figure}[!b]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/unfeas_je2}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhen$ restriction}


\label{fig:not-knows-when} 
\end{figure}


%
\begin{figure}[!b]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35]{listings/jointexec/unfeas_je}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhat$ restriction}


\label{fig:not-knows-what} 
\end{figure}


The second restriction corresponds to the idea of \emph{knowing what}
action to perform. For any given view $v$, there may be multiple
events enabled by that view, and the agent has no means of knowing
precisely which event is actually enabled. To ensure it always knows
what to do, we require that all such events call for the same action
to be performed:\begin{multline*}
KnowsWhat(ex)\,\isdef\,\\
\forall agt,v,i,j:\,\, EnabledByView(ex,i,agt,v)\wedge EnabledByView(ex,j,agt,v)\\
\rightarrow lbl(ex,u)=lbl(ex,j)\end{multline*}
 While the agent may not know precisely which \emph{event} is enabled,
its local information is enough to determine the specific \emph{action}
that it is to perform. Figure \ref{fig:not-knows-what} shows an example
of a joint execution that does not meet this requirement. This plan
calls for $Jim$ to check for the availability of eggs, then for $Joe$
to acquire an appropriate ingredient depending on whether they are
available. But since $Joe$ cannot distinguish between outcome events
$O1$ and $O2$, he doesn't know what action to perform and the plan
cannot be executed.

TODO: KnowsWhat isn't quite right yet

We say a joint execution is \emph{feasible} if it meets both these
restrictions:\[
Feasible(ex)\,\isdef\, KnowsWhat(ex)\wedge KnowsWhen(ex)\]


The important property of feasible joint executions is that an agent's
local view is always sufficient to determine the next action it should
perform.

\begin{thm}
Let $ex$ be a feasible joint execution, then:\[
\Dt\cup\Dt_{je}\,\models\, TODO:\, what?\]

\end{thm}

\subsection{Legal Joint Executions}

So far, we have not restricted joint executions to correspond to any
sort of \emph{legal} run of execution. A joint execution may have
action events enabling outcome events that they would never produce
under the given theory of action. It may call for actions to be performed
in situations where they are not legal, or allow actions to be performed
concurrently that could be in conflict.

To avoid such undesirable cases, we identify \emph{legal} joint executions
as ones that are constrained enough to be performed in the real word.
We will say that a particular leaf of a joint execution is legal if
every history of that leaf corresponds to a legal situation:\[
Legal(ex,lf)\,\isdef\,\forall h:\, History(ex,lf,h)\,\rightarrow\,\exists s:\, Legal(s)\wedge History(s)=h\]


This ensures that the leaf is constrained enough to prevent precondition
interaction between independent action events, that its outcome events
are correct for their corresponding actions, etc. However, the agents
will generally not have enough information to determine whether a
particular leaf is legal, since this would imply that they already
know what sensing results will occur. We call an entire joint execution
legal if it contains a legal leaf:\[
Legal(ex)\,\isdef\,\exists lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\]


This definition does not require that we establish \emph{which} leaf
is legal, only that we are able to prove that \emph{some} leaf must
be legal. Since the leaves of a joint execution represent all its
possible terminating configurations, this requirement means that a
legal joint execution can legally be performed to completion in the
world.

The definition is also \emph{permissive}, in that there may be leaves
of the joint execution that are provably never be legal. Since the
outcomes along these leaves will not occur in reality, the agents
will never follow them at execution time. This permissiveness will
therefore not affect an agent's ability to carry out the plan in practice.


\subsection{Summary}

This section has formally defined a \emph{joint execution}, a partially-ordered
branching action structure that we claim is particularly well suited
for representing the actions to be performed by a team of agents in
service of a shared task. The partially-ordered nature of joint executions
allows them to explicitly account for inter-agent syncrhonisation
of actions in the face of partial observability, while their branching
nature allows them to account for incomplete information that must
be augmented with runtime sensing results.

In asynchronous domains, where raw situation terms cannot feasibly
be executed in the world, joint executions are an ideal alternative
as a plan representation structure for use by the Golog execution
planning process. In the next section we identify precisely what such
a planning process must search for.


\section{Planning with Joint Executions\label{sec:JointExec:Planning}}

With the above definitions and axioms in place, we are now in a position
to plan the cooperative execution of a shared Golog program using
joint executions rather than raw situation terms. For the moment we
focus on \emph{offline} execution planning, in the style of the original
Golog and ConGolog. Recall that the semantics of execution planning
in Golog involve finding a situation term $s$ satisfying:\[
\Dt\cup\Dt_{golog}\,\models\,\exists s:\,\Do(\delta,S_{0},s)\]


Before extending this query to search for a joint execution, notice
an important consequence of our definitions: if two events can occur
in either order, then it is also possible for them to occur concurrently.
Since the standard Golog/ConGolog semantics do not permit true concurrency,
they would require all events to be ordered and we would gain no benefit
from using joint executions. We must therefore adopt the concurrency
semantics of MIndiGolog from Chapter \ref{ch:mindigolog}, which permit
true concurrency of actions.

The execution planning problem then reduces to the task of finding
a \emph{legal}, \emph{feasible} joint execution such that for every
leaf, if that leaf is legal, then it constitutes a legal execution
of the program:\begin{multline*}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\end{multline*}


This query neatly captures dual soundness and completeness requirements.
For soundness, it requires that for every leaf of the joint execution,
\emph{if} that leaf is legal then it will be a legal execution of
the program $\delta$. For completeness, it requires that there must
in fact be \emph{some} leaf that is legal, so the joint execution
can actually be performed in the world. The joint execution must contain
enough branching to account for any incomplete knowledge the agents
have about the state of the world.

%
\begin{algorithm}[t]
\caption{Offline Execution Algorithm using Joint Executions}


\label{alg:je_offline_exec} \begin{algorithmic}

\STATE

\STATE $v\,\Leftarrow\,\epsilon$

\STATE Find a joint execution $ex$ such that:\begin{multline*}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\end{multline*}


\WHILE{$ex$ contains action events to be performed by me}

\STATE Find an action $a$ such that\[
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists i:\, EnabledByView(ex,i,agt,v)\wedge lbl(ex,i)=a\]


\IF {there is such an action}

\STATE Execute action $a$

\ENDIF

\STATE Wait for a new observation $o$

\STATE $v\,\Leftarrow\, o\cdot v$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


Algorithm \ref{alg:je_offline_exec} presents a simple modification
of the Golog offline planning algorithm that can be used by each agent
to plan the execution of a shared program $\delta$ and then perform
it in the world. A restricted version of this algorithm is used by
our implementation that will be described in Section \ref{sec:JointExec:Implementation}.

If we turn out attention to \emph{online} execution of a Golog program,
things are not so straightforward. While it is simple enough to extend
a joint execution one action at a time in the style of IndiGolog execution
from Algorithm \ref{alg:indigolog_exec}, it is difficult to coordinate
such a procedure between multiple agents.

Recall the ReadyLog execution algorithm from Algorithm \ref{alg:readylog_exec},
which our MIndiGolog implementation uses to coordinate online execution
of a shared program. This algorithm depends crucially on each agent
producing the same {}``next step'' at every iteration, a restriction
that is difficult to maintain when each agent may have a different
perspective on the state of the world.

For example, suppose that $Jim$ can use his local sensing information
to deduce that the current execution can be extended by a single action
and a single outcome event; he has enough local information to eliminate
any branching from the plan. However, he must allow for the possibility
that $Joe$ does not have this information, and may therefore produce
try to extend the current exectution with several branches. Furthermore,
$Joe$ must also plan according to what he thinks $Jim$ might consider
possible, which $Jim$ must take into account in turn. So planning
the {}``next step'' must take into account all the potential differences
between the agent's local information.

The difficulty here is the well-known correspondance between coordination
and common knowledge. In order to extend the ReadyLog execution algorithm
to the case of incomplete information, the agents must extend their
joint execution with something that is \emph{commonly known} to be
a valid next step. Unfortunately the situation calculus does not offer
any tools for reasoning about common knowledge, not even in synchronous
domains. In Chapter \ref{ch:cknowledge} we will explore the foundations
of such a formalism, but the technology required to incorporate common-knowledge
reasoning into our planning loop simply does not exist at this stage.
Our joint-execution based MIndiGolog planner is therefore currently
limited to offline execution planning.


\section{Reasonable Joint Executions\label{sec:JointExec:Reasonable}}

While joint executions can clearly provide a powerful formal account
of execution planning for asynchronous multi-agent domains, in their
current form they are not suitable for an effective implementation.
The difficulty arises from the definition of $History(ex,br,h)$,
which due to the partial ordering on events can generate an exponentially-large
number of possible histories. To verify that a joint execution is
legal, the planner needs to examine each of these histories individually.

To overcome this difficulty and produce an effective implementation,
we identify a restricted class of joint executions in which all possible
histories of a branch are provably equivalent. Such executions can
be reasoned about using the canonical ordering over events, rather
than having to enumerate each possible distinct history.


\subsection{Independent Actions}

To construct families of situation terms that are all equivalent,
we need a way to identify \emph{independent actions.} Intuitively,
we want independent actions to be able to be performed in either order,
or even concurrently, without affecting what holds in the resulting
situation, or the preconditions or outcomes of each action. This section
formally identifies sufficient conditions to ensure that actions are
independent.

For simplicity, we identify actions that are independent regardless
of the situation they are performed in. Let us assume that the theory
of action $\Dt$ is equipped with a rigid predicate $indep(a,a')$
identifying actions that are independent. We identify sets of mutually-independent
actions with this simple definition:\[
mIndep(c)\isdef\forall a,a':\, a\in c\wedge a'\in c\,\rightarrow\, indep(a,a')\]
We then restrict the theory of action to satisfy the following conditions:

\begin{defnL}
[{Independent~Actions}] A theory of action $\Dt$ correctly
specifies independent actions when it contains a rigid predicate $indep(a,a')$
and entails the following, where $\mathcal{F}$ is a meta-variable
ranging over fluents:\begin{gather*}
\Dt\,\models\, indep(a,a')\equiv indep(a',a)\\
\Dt\,\models\, Legal(\{a\},s)\equiv Legal(\{a\},do(\{a'\},s))\\
\Dt\,\models\, Out(\{a\},s)=Out(\{a\},do(\{a'\},s))\\
\Dt\,\models\,\mathcal{F}(do(\{a\},do(\{a'\},s)))\equiv\mathcal{F}(do(\{a'\},do(\{a\},s)))\\
\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(Legal(c,s)\equiv\,\forall a\in c:\, Legal(\{a\},s)\right)\\
\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(o\in Out(c,s)[agt]\equiv\exists a\in c:\, o\in Out(\{a\},s)[agt]\right)\\
\Dt\,\models\, mIndep(c)\,\rightarrow\,\forall a\in c:\left(\,\mathcal{F}(do(c,s))\equiv\mathcal{F}(do(\{a\},do(c-\{a\},s)))\right)\end{gather*}

\end{defnL}
The restriction simple ensures that indepedence is symmetrical. The
next three restrictions ensure that independent actions do not interfere
with each other's preconditions, outcomes or effects. The final three
restrictions ensure that there is no interference between preconditions,
outcomes or effects when independent actions are performed concurrently.


\subsection{Reasonability}

We now define a \emph{reasonabl}e joint execution as one in which
every pair of action events is either ordered, in conflict, or independent:

\begin{defnL}
[{Reasonable~Joint~Execution}] A joint execution is reasonable
if it satisfies the following restriction:\begin{multline*}
\Dt\,\models\,\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\wedge IsAction(lbl(ex,j))\\
\rightarrow\, i\prec_{ex}j\,\vee\, j\prec_{ex}i\,\vee\, i\oplus_{ex}j\,\vee\, indep(lbl(ex,i),lbl(ex,j))\end{multline*}

\end{defnL}
We call such executions reasonable because a planner can reason about
then effectively, using the unique canonical history of each leaf
rather than enumerating each individual history.

\begin{thm}
Let $ex$ be a reasonable joint execution, then:\begin{multline*}
\Dt\cup\Dt_{je}\,\models\,\forall lf:\, Leaf(ex,lf)\,\rightarrow\,\\
\left[Legal(ex,lf)\,\equiv\,\exists h:\, CHistory(ex,lf,h)\,\wedge\, Legal(h)\right]\end{multline*}

\end{thm}
\begin{proof}
By definition, a leaf is legal if every possible history of that leaf
is legal, so the \emph{if }direction is trivial. For the \emph{only-if
}direction, assume that the canonical history of the leaf if legal.
Since the histories of a leaf can differ only by the order of execution
of unordered action events, and all unordered action events in a reasonable
execution are independent, every history of the leaf differs from
the canonical history only in the order of execution of independent
events.

By the definition of independent events, performing them in a different
order does not affect their legality, nor does performing them concurrently.
Since the canonical history is legal, all histories will be legal
and we can conclude that the leaf itself is legal.

This result is key to our implementation of a MIndiGolog execution
planner based on joint executions - by restricting its search to reasonable
executions, it can verify the legality of each leaf by querying the
legality of the canonical leaf history, which can be done using standard
regression techniques.
\end{proof}

\section{Implementation\label{sec:JointExec:Implementation}}

We have modified our MIndiGolog execution planner from Chapter \ref{ch:mindigolog}
to perform offline execution planning and generate a joint execution
rather than a raw situation term. As already mentioned, Figure \ref{fig:JE:MakeSalad1}
shows the output of our system when run on the $MakeSalad$ program
that was used in that chapter Since all actions in this execution
have a single outcome, the outcome events have been suppressed to
keep the presentation clear.

In the cooking agents domain, actions are independent if they deal
with different objects. As seen in Figure \ref{fig:JE:MakeSalad1},
the use of a partial order structure facilitates independent execution
between the agents, with each processing a different ingredient and
only synchronising on the availability of the required resources.
This execution provides the maximum potential for concurrency given
the resource constraints of the domain, and is clearly a significant
improvement over totally ordered sequences of actions as produced
by the earlier MIndiGolog planner.

However, the simple $MakeSalad$ program does not demonstrate a key
feature of joint executions: branching. Consider instead the program
$MakeSalad2$ shown in Figure \ref{fig:MIndiGolog:MakeSalad2}. In
this case the agents are unsure whether there are any eggs available,
so the sensing action $checkFor$ is required. If there are eggs then
they should make an egg salad, otherwise they should make the standard
vegetable salad. Note that since lettuce appears in both dishes, they
are permitted to begin processing theat ingredient before checking
for the eggs.

%
\begin{figure}
\begin{centering}
\framebox{%
\parbox[t][1\totalheight]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, MakeSalad2(dest)\\
\left[\pi(agt,ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\left.ChopEggOrVeg(dest)\right]\,;\\
\pi(agt,\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
endTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right])\,\,\mathbf{end}\\
\\\\\mathbf{proc}\, ChopEggOrVeg(dest)\\
\pi(agt,\, checkFor(agt,Egg))\,;\\
\mathbf{if}\\
\exists e:\, IsType(e,Egg)\wedge\neg Used(e)\\
\mathbf{then}\\
\left[\pi(agt,ChopTypeInto(agt,Egg,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Cheese,dest))\right]\\
\mathbf{else}\\
\left[\pi(agt,ChopTypeInto(agt,Carrot,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\mathbf{endif}\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for making Egg or Veg Salad\label{fig:MIndiGolog:MakeSalad2}}

\end{figure}


The joint execution found by our implementation for $MakeSalad2$
is shown in Figure \ref{fig:JE:MakeSalad2-Exec}. The event nodes
in this diagram are colour-coded into three groups: white nodes can
occur independently of the sensing results from $checkFor$; light-grey
nodes can only occur if $checkFor$ returns false; dark-grey nodes
can only occur if $checkFor$ returns true. 

We see from this joint execution that $Joe$ can indeed proceed to
prepare the lettuce without needing to know whether eggs are available.
$Jim$ is assigned to check for the eggs, and acquires either an egg
or a tomato depending on the outcome of his sensing action. Importantly,
$Jon$ has to wait until $Jim$ acquires his ingredient before he
knows whether to process the cheese, or the carrot. This is due to
him being unable to directly observe the outcome of the $checkFor$
action.

By basing branching and syncrhonisation directly on the observations
made by each agent, joint executions allow us to capture this kind
of rich branching and partial-order structure while ensuring that
the agents can still execute the plan based solely on their local
information.

In the following sections, we briefly highlight some key aspects of
our implementation. More details are available in Appendix \ref{ch:code}.

%
\begin{figure}[H]
\framebox{%
\begin{minipage}[t][1\totalheight]{1\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25]{listings/jointexec/salad2_plan}}}
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad2$ program}


\label{fig:JE:MakeSalad2-Exec} 
\end{figure}





\subsection{Program Steps}

The $Trans$ predicate of MIndiGolog is modified to generate \emph{steps}
instead of constructing a new situation term. These are records that
describe not only the next action to perform, but also meta-data about
that action's role in the larger program. Step records have the following
attributes.

\begin{itemize}
\item action: the action performed in that step, or $nil$ if it is an internal
program transition 
\item test: an additional fluent formula that must hold immediately before
performing the step 
\item thread: a sequence of 'l' and 'r' characters indicating the concurrent
thread in which the step is performed 
\item outcome: the outcome of performing the action. 
\end{itemize}
These steps contain the necessary information for the planner to determine
whether two actions can be performed independently. A sequence of
steps corresponds to a history term in the obvious way, but simply
taking the action and outcome components.

The procedure implementing $Trans$ takes a program and a run as input,
returning a new program and new step of execution. As an example consider
the code in figure \ref{fig:trans-code}, implementing the test operator
and the concurrency operator from equation \ref{eqn:trans_conc_orig}.

\programinput{listings/jointexec/ConGolog.oz}

Note that whenever the procedure descends through the left side of
a concurrency operator it pushes an 'l' onto the step's {}``thread''
attribute, and each descent through the right side pushes an 'r'.
Two steps can be said to come from different threads as long as neither
{}``thread'' attribute is a prefix of the other.

We say that two steps are \emph{ordered} if any of the following holds:
their action terms are not independent; ones thread is a prefix of
the other; ones action falsifies the test condition associated with
the other. When building a joint execution, ordered steps are forced
to be executed in the order they were generated by the planner, while
unordered steps may be performed independently.


\subsection{Planning Procedure}

The code for planning a joint execution from a given ConGolog program
is shown in figure \ref{fig:planning-code}. The main procedure is
$MakePlan$, a recursive procedure that operates on a list of branches-in-progress
of the form $(D,R,B)$. Here $B$ is a branch in the joint execution
under construction, $D$ is the program remaining to be executed on
that branch, and $R$ is the run of program steps performed on that
branch so far.

\programinput{listings/jointexec/Planner.oz}

Each iteration of the planning loop proceeds as follows. The procedure
$FindOpenBranch$ updates each branch to account for events that were
added since it was last processed (some may have been added automatically
to satisfy restriction (R5)), then searches the list to find a branch
for which $Final(D,R)$ does not hold. If all branches are final,
planning can terminate. Otherwise, the procedure $FindTrans1$ is
called to find a new step of execution for that branch. The action
is inserted into the joint execution, which returns a list of new
branches, one for each possible outcome of the action. Each of these
outcomes is added to the list of branches, and the loop is started
again.

Of particular interest is the procedure $FindTrans1$, which uses
the encapsulated search functionality of Mozart to yield possible
next steps according to an estimate of their potential for concurrency.
The procedure $LP.yieldOrdered$ yields the solutions of the given
search context, sorted using the procedure $CompareSteps$. This procedure
(not shown) gives preference to steps that can be performed concurrently
with as many existing actions as possible.


\section{Discussion\label{sec:JointExec:Discussion}}

In this section we have defined a \emph{joint execution} as a prime
event structure with some additional restrictions. We contend that
such structures are highly suitable for planning the actions to be
performed by a team in service of some shared task, such as executing
a shared Golog program.

On one hand, joint executions are restricted enough to be practical
for such use. Prime event structures are purely reactive (equivalent
to a kind of finite automaton) and can be executed by the agents without
further deliberation. They are restricted to ensure that whenever
an agent is required to perform an action, it is able to determine
this using only its local information. Each branch of execution can
be easily converted into a situation term for the purposes of reasoning,
and can be extended one action at a time.

Joint executions are also significantly more flexible than previous
approaches. They allow independent actions to be performed without
synchronisation, in any order. The agents need never know precisely
what actions have been executed, only those that enable them to perform
their next action. Synchronisation is automatically achieved when
required by explicitly reasoning about what actions each agent can
observe, rather than requiring that all actions be public.

To demonstrate the utility of these structures, we have implemented
an interpreter for multi-agent ConGolog programs that produces joint
executions as its output. In the next section, we highlight the key
aspects of our implementation and give an example of the output it
produces.

An alternate approach to the problem of partial observability is the
language TeamGolog developed in \citep{farinelli07team_golog}, where
agents explicitly synchronise through communication and a shared state.
By contrast, our approach constructs synchronisation implicitly by
reasoning about the actions that can be observed by each agent. This
has the advantage of requiring no changes to the form or semantics
of the agents' control program, but the disadvantage that joint execution
construction may fail if too many actions are unobservable. It would
be interesting to combine these approaches by automatically incorporating
explicit communication when implicit synchronisation is not possible.

There is, of course, an extensive body of work on partial-order planning
in the context of goal-based planning. Unsurprisingly, the joint execution
structure we develop here has deep similarities to the structures
used in conditional partial-order planners such as \citep{peot92conditional_nonlinear}.
It is, however, intentionally specific to the situation calculus.
We make no use of many concepts common in partial-order goal-based
planning (causal links, threats, conflicts, etc) because we do not
deal explicitly with goals, but with steps generated by an underlying
transition semantics. Our approach can be considered roughly equivalent
to \emph{deordering} of a totally-ordered plan as described in \citep{backstrom99reordering},
except performed during plan construction rather than as a post-processing
step.

loops: \citep{levesque96what_is_planning,levesque05planning_with_loops}

can't represent actions that {*}need{*} to be performed concurrently
- but should be a trivial addition.

don't use explicit mental attitudes, mutual beliefs etc. JE's more
akin to recpies in SharedPlans. Assume agents all have the common
goal of executing the given shared program. But it could be used as
part of larger system.

In this section we have defined a \emph{joint execution} as a prime
event structure with some additional restrictions. We contend that
such structures are highly suitable for planning the actions to be
performed by a team in service of some shared task, such as executing
a shared Golog program.

On one hand, joint executions are restricted enough to be practical
for such use. Prime event structures are purely reactive (equivalent
to a kind of finite automaton) and can be executed by the agents without
further deliberation. They are restricted to ensure that whenever
an agent is required to perform an action, it is able to determine
this using only its local information. Each branch of execution can
be easily converted into a situation term for the purposes of reasoning,
and can be extended one action at a time.

Joint executions are also significantly more flexible than previous
approaches. They allow independent actions to be performed without
synchronisation, in any order. The agents need never know precisely
what actions have been executed, only those that enable them to perform
their next action. Synchronisation is automatically achieved when
required by explicitly reasoning about what actions each agent can
observe, rather than requiring that all actions be public.

To demonstrate the utility of these structures, we have implemented
an interpreter for multi-agent ConGolog programs that produces joint
executions as its output. In the next section, we highlight the key
aspects of our implementation and give an example of the output it
produces.


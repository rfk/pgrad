
While knowledge can be difficult to obtain if agents cannot observe
many actions, our approach offers two ways to overcome this problem:

(1) increasing the ability of agents to observe actions performed
by others will increase the number of fluents that can be known
(2) "change actions" (section 3.3) can model agents knowing that the
value of a fluent has changed while not directly observing the action
causing the change.

The ability to explicitly make such tradeoffs is a powerful feature of
our approach.

We're also confident that our technique for determining agent's mental
states from explicit observation histories will apply to systems
of belief, which often use extensions of techniques for handling knowledge.


p2) We should explicitly state that we are working with standard sitcalc
theories of action, as used by Reiter, Levesque et.al, and clarify that we
must assume significant background knowledge (possibility of concurrent
actions, foundational axioms, s < s' notation, etc) due to space constraints.

p4) Some issues with parentheses and several typos affect the meaning of
our axioms and we welcome your comprehensive list. Of particular
importance is the carelessly ommitted s<=s" conjunct in Unobs and
correct precedence between exists/implies:

  exists o. Observations(agt,c,s)=o and (o\={} -> X)

These are easily remedied.

p5) We will clarify that P_D always produces a regressible formula. Eq10
simply explains the meaning of P_D, a seperate paper details how to
calculate it.


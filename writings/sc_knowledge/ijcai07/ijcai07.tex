%% LyX 1.4.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[letterpaper]{article}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand{\noun}[1]{\textsc{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.



\makeatletter



\usepackage{ijcai07}


\usepackage{times}


\usepackage{helvet}


\usepackage{courier}


\usepackage{amsthm}




\newcommand{\isdef}{\hbox{$\stackrel{\mbox{\tiny def}}{=}$}}


\newtheorem{theorem}{Theorem}

\makeatother

\makeatother
\begin{document}


\title{Knowledge via Observations in the Multi-Agent Situation Calculus }


\author{Ryan Kelly and Adrian Pearce\\
 Department of Computer Science and Software Engineering\\
 NICTA Victoria Laboratory\\
 The University of Melbourne\\
 Victoria, 3010, Australia\\
 \{rfk,adrian\}@csse.unimelb.edu.au}

\maketitle
\begin{abstract}
We develop a new semantics for knowledge in the situation calculus
by reifying the observations that each agent makes as the world evolves.
It is shown to be strictly more general than previous approaches,
and can easily model agents who passively monitor the value of fluents
in their environment. We develop a technique for effective reasoning
in this formalism using an extended regression operator that accommodates
limited quantification over situations, and show how it allows agents
to reason based on their internal history of observations, rather
than requiring a full history of the world. This makes the situation
calculus more suitable for implementation in real-world multi-agent
systems.
\end{abstract}

\section{Introduction}

The situation calculus is one of the most popular formalisms for reasoning
about dynamic worlds. Many extensions have been proposed to introduce
concepts such as knowledge and concurrent actions, which can be combined
to provide a rich formalism for modeling multi-agent domains.

A common assumption when working in the situation calculus is that
agents are fully aware of the actions that have been performed in
the world. Indeed, the notion of 'situation' is formalized as a history
of all actions that have occurred. In the rare cases that this is
not assumed, the opposing extreme is posited - that agents are completely
ignorant of actions performed by others.

Both of these assumptions are unrealistic in many domains, and can
limit the applicability of the situation calculus. To overcome this,
we reify the notion of \emph{observations} and axiomatize the conditions
under which an agent will observe the occurrence of an action. By
ensuring that agents consider possible any situation compatible with
what they have observed, we develop an improved account of knowledge
that spans the two extremes. This formulation can be naturally extended
to model agents who monitor the values of fluents in their environment,
rather than directly observing actions.

Our semantics depend on universal quantification over situation terms,
which requires induction using second-order logic and hence is difficult
to handle in automated reasoning systems. Using an extension of the
regression operator that can handle limited quantification over situations,
we show how to reason within our framework using purely first-order
logic. The result is a powerful new account of multi-agent knowledge
that still permits an effective reasoning procedure.

Reasoning in the situation calculus traditionally takes a {}``Gods-eye
view'' approach, where queries are posed relative to the current
situation. This works well for modeling and simulation where a full
world history is always available. However, it makes it difficult
for agents to use the situation calculus to reason about their own
world, as they may not have access to the full world history. Our
regression technique can be applied to the sequence of observations
of a single agent, rather than to a full situation term, facilitating
reasoning from an {}``internal view'' more appropriate for implementation
in real systems.

The paper is organized as follows: section \ref{sec:ma-sitcalc} gives
a brief introduction to the situation calculus with knowledge and
concurrent actions, and highlights some of the limitations of current
approaches; section \ref{sec:New-Semantics} introduces our improved
semantics of knowledge and shows how to reason effectively with them;
and section \ref{sec:Conclusions} concludes with a summary of our
results.


\section{The Multi-Agent Situation Calculus\label{sec:ma-sitcalc}}

We work in a version of the the situation calculus as described in
\cite{pirri99contributions_sitcalc}, enriched with concurrent actions
\cite{reiter96sc_nat_conc} to better represent the dynamics of a
multi-agent system. We use the approach of \cite{shapiro01casl_feat_inter}
for representing multiple agents, and begin from the standard account
of knowledge given by \cite{scherl03sc_knowledge}. A brief overview
is presented below.

The situation calculus is a many-sorted language of first-order logic
augmented with a second-order induction axiom. Its has the following
sorts: \noun{Agent} terms represent the agents operating in the world;
\noun{Action} terms are functions denoting individual instantaneous
events that can cause the state of the world to change, with the initiating
agent indicated by their first argument; \noun{Concurrent} terms are
sets of actions that occur simultaneously; \noun{Situation} terms
are histories of the concurrent actions that have occurred in the
world, with the initial situation represented by $S_{0}$ and successive
situations built using the function $do\,:\, Concurrent\times Situation\rightarrow Situation$;
\noun{Result} terms represent sensing results returned by actions;
\noun{Object} terms represent any other object in the domain. We also
distinguish \noun{Fluents} as predicates or functions representing
properties of the world that may change from one situation to another,
and so take a situation term as their final argument.

A set of situation calculus statements $\mathcal{D}$ that describe
a dynamic world is referred to as a \emph{theory of action}. Queries
about the behavior of the world are posed as logical entailment queries
relative to the theory of action.


\subsubsection{Action Precondition Axioms}

There is a distinguished fluent predicate $Poss(a,s)$ that indicates
when it is possible to perform an action in a given situation. For
example, it is only possible for an agent to drop an object if they
are actually holding it%
\footnote{We follow the convention that lower-case names indicate variables,
with free variables being implicitly universally quantified %
}:
\begin{equation*}
Poss(drop(agt,obj),s)\equiv Holding(agt,obj,s)
\end{equation*}
For concurrent actions, an arbitrary combination of actions $\{ a_{1},a_{2}\}$
is not guaranteed to be possible. This is known as the precondition
interaction problem \cite{reiter96sc_nat_conc}. A simple solution
is to explicitly state which actions cannot be performed concurrently
using a predicate $Conflicts$:
\begin{multline*}
Poss(c,s)\equiv\\
\forall a\left[a\in c\rightarrow Poss(a,s)\right]\wedge\neg Conflicts(c,s)
\end{multline*}
This paper requires no particular commitment toward a solution to
this problem.


\subsubsection{Successor State Axioms}

The truth of a fluent is completely specified by defining its truth
in the initial situation, and collecting the effects of various actions
into \emph{successor state axioms}. Such axioms provide a monotonic
solution to the infamous frame problem, and are a principle attraction
of the situation calculus. They have the following general form, asserting
the truth of a fluent $F$ in the successor situation $do(c,s)$ based
on the current situation $s$ and the actions $c$ that were performed:
\begin{equation*}
F(\overrightarrow{x},do(c,s))\equiv\Phi(\overrightarrow{x},c,s)
\end{equation*}



\subsubsection{Uniform Formulae}

The \emph{uniform formulae} are those that refer only to a single
situation term and do not mention the $Poss$ predicate, and can thus
be thought of as formulae about the state of the world at a given
instant. Throughout this paper we use the meta-variable $\phi$ to
refer to an arbitrary uniform formula. It is often useful to determine
the truth of a uniform formula at an alternate situation term, and
we use $\phi[s]$ to represent the uniform formula $\phi$ with all
occurrences of its unique situation term replaced by the situation
$s$. Where no confusion can arise, we suppress the situation terms
in uniform formulae to simplify the presentation.


\subsubsection{Knowledge and Sensing}

The semantics of knowledge \cite{scherl03sc_knowledge} are based
on the popular {}``possible worlds'' model. A knowledge fluent $K(agt,s',s)$
is used to indicate that {}``in situation $s$, the agent $agt$
considers the alternate situation $s'$ to be possible''. The operator
$\mathbf{Knows}$ is then introduced as a macro, stating that an agent
knows something if it is true in all situations considered possible:
\begin{equation}
\mathbf{Knows}(agt,\phi,s)\isdef\forall s'\, K(agt,s',s)\rightarrow\phi[s']\label{eqn:knows_def}
\end{equation}
To allow actions to return sensing information the sensing result
function $SR(a,s)$ is introduced, giving the result returned by the
action $a$ when executed in a situation $s$. This is defined by
axioms of the form:
\begin{equation*}
SR(a(\overrightarrow{x}),s)=r\equiv\psi_{a}(\overrightarrow{x},r,t,s)
\end{equation*}
For actions that don't return sensing information, the value of $SR$
is set to some arbitrary constant such as $"OK"$. Combining the multi-agent
semantics of \cite{shapiro01casl_feat_inter} with the handling of
concurrent actions in \cite{scherl03conc_knowledge}, the common form
of successor state axiom for the knowledge fluent is:
\begin{multline}
K(agt,s'',do(c,s))\equiv\\
\exists s'\,\, s''=do(c,s')\,\wedge K(agt,s',s)\wedge Poss(c,s')\\
\wedge\,\forall a \in c \left[agent(a)=agt\rightarrow SR(a,s)=SR(a,s')\right]\label{eqn:k_ssa_standard}
\end{multline}
This states that $s''$ is considered a possible alternative to $do(c,s)$
when $s''$ is the result of doing those same actions $c$ in a situation
$s'$ that is a possible alternative to $s$. The situation $s''$
must furthermore be possible, and the sensing results must be consistent
for all actions in $c$ that were carried out by the agent. 

It is also necessary to permit alternate possible worlds to the initial
situation $S_{0}$. The predicate $Init$ identifies initial situations,
and only other initial situations may be $K$-related to an initial
situation. We also talk of situations being \emph{rooted at} some
initial situation:
\begin{equation*}
\begin{split}
& Init(s)\equiv\neg\exists c',s'\, s=do(c',s')\\
& Init(s)\rightarrow Root(s)=s\\
& Root(do(c,s))=Root(s)\\
& Init(s)\rightarrow\left(K(s',s)\rightarrow Init(s')\right)
\end{split}
\end{equation*}
While powerful, this formulation has an important limitation: each
agent must be aware of \emph{all} actions that have occurred. Note
that this awareness is passive - the agents perform no explicit sensing
actions to determine what has occurred. Responsibility for generating
such {}``awareness'' must thus be abdicated to a lower-level component
of the agent's software, such as a visual processing system that identifies
change in the environment.

While suitable for some domains, there are clearly many realistic
multi-agent domains that do not meet this limitation. An alternate
formulation from \cite{Lesperance99sitcalc_approach} can model these:
\begin{multline}
K(agt,s'',do(c,s))\equiv\\
\exists s',s^{*},c'\,.\, s''=do(c',s^{*})\,\wedge K(s',s)\wedge Poss(c',s^{*})\\
\wedge\,\mathbf{ExoOnly}(agt,s',s^{*})\\
\wedge\,\forall a\left[agent(a)=agt\rightarrow a\in c'\equiv a\in c\right]\\
\wedge\,\forall a \in c \left[agent(a)=agt\rightarrow SR(a,s)=SR(a,s')\right]\label{eqn:k_ssa_exo}
\end{multline}
Where the macro $\mathbf{ExoOnly}$ indicates that two situations
are connected only by actions performed by other agents:
\begin{multline*}
\mathbf{ExoOnly}(agt,s,s'')\,\,\isdef\,\, s\leq s''\wedge\\
\forall s',c,a\left[s<do(c,s')\leq s''\wedge a\in c\rightarrow agent(a)\neq agt\right]
\end{multline*}
Here agents consider possible any situation compatible with the actions
that they themselves have performed. There may have been an arbitrary
sequence of situations between $s'$ and $s''$ which the agent knew
nothing about, because they consisted entirely of exogenous (from
$agt$'s point of view) actions. But this approach is also limiting,
in that agents can \emph{never} be aware of the actions performed
by others. Full generality requires a middle ground, with agents being
aware of \emph{some} of the actions performed by others.

Furthermore, suppose that $agt$ has just performed action $a_{1}$,
so the world is in some situation $do(a_{1},s)$. Another agent then
performs the action $a_{2}$, leaving the world in situation $do(a_{2},do(a_{1},s))$.
Since it cannot observe the occurrence of $a_{2}$, $agt$ would be
aware of no change in the world and its state of knowledge should
therefore remain unchanged. Unfortunately this is not the case: $K(agt,s',do(a_{2},do(a_{1},s)))\not\equiv K(agt,s',do(a_{1},s))$
under this formulation. To faithfully represent this aspect of the
knowledge of real-world agents, the successor state axiom for $K$
must permit any \emph{future} of $do(a_{1},s)$ that can be brought
about by exogenous actions, rather than any \emph{past} as done above.


\subsubsection{Belief}

We note at this point that we are interested in a logic of \emph{knowledge}
- everything known by an agent must actually be true in the world.
There has also been significant work on \emph{belief} in the situation
calculus. \cite{shapiro04sc_belief_exog} show how agents may hypothesize
the occurrence of exogenous actions when they discover that their
beliefs are wrong, neatly avoiding the issue of being aware of actions
performed by others. This approach cannot be applied when dealing
with knowledge. However, we believe that the concrete notion of observations
we develop below will also be useful for belief-based systems.


\subsubsection{Regression}

One of the attractions of the situation calculus is the existence
of effective reasoning procedures for certain types of query. The
principle tool is the regression meta-operator \cite{pirri99contributions_sitcalc}
which transforms a formula $\phi$ uniform in $do(c,s)$ into a formula
$\mathcal{R}_{\mathcal{D}}(\phi)$ uniform in $s$, such that the
two are equivalent relative to the theory of action $\mathcal{D}$.
By repeatedly applying the regression operator, $\phi$ can be transformed
into an equivalent formula uniform in the initial situation%
\footnote{One can also define a regression operator that reduces to $S_{0}$
in a single pass, rather than requiring repeated application. The
two approaches are essentially equivalent, but the repeated-application
version is simpler to extend for our purposes.%
}:
\begin{equation*}
\mathcal{D}\models\phi[do(c_{n},do(c_{n-1},\dots,do(c_{1},S_{0}))]\equiv\mathcal{R}_{\mathcal{D}}^{*}(\phi)[S_{0}]
\end{equation*}
Many of the axioms from $\mathcal{D}$ are not required for reasoning
about the initial situation, and so can be discarded when reasoning
about $\mathcal{R}_{\mathcal{D}}^{*}(\phi)[S_{0}]$. This is often
(but not necessarily always) more efficient than directly reasoning
about $\phi$.

In \cite{scherl03sc_knowledge}, the regression operator is extended
to handle to the standard account of knowledge in equation (\ref{eqn:k_ssa_standard})
by reducing reasoning about formulae containing the $\mathbf{Knows}$
macro to modal reasoning over the $K$ relation in the initial situation.
Regressing such formulae relies on the fact that agents are aware
of all actions - formulae containing quantification over situations,
such as the modified dynamics of knowledge in equation (\ref{eqn:k_ssa_exo}),
cannot be regressed. Indeed, \cite{Lesperance99sitcalc_approach}
offer no procedure for reasoning in their formalism other than using
second-order induction.

By using an extension of the regression idea that can handle limited
forms of quantification over situations, we provide a purely first-order
reasoning procedure for our improved account of knowledge.


\section{New Semantics of Knowledge\label{sec:New-Semantics}}


\subsubsection{Observations}

Existing situation calculus accounts of knowledge all employ an assumption
about when an agent is aware of an action occurring - either {}``agents
are always aware of actions'' or {}``agents are only aware of actions
that they perform''. We replace such assumptions with a question:
{}``when will an agent be aware of the occurrence of an action?''.

A new fluent is introduced, akin to $Poss$ but describing when actions
will be observed by agents: $CanObs(agt,a,s)$ indicates that agent
$agt$ would be aware of action $a$ being performed in situation
$s$. As before, we assume that in an implemented system this {}``awareness''
is generated by some other component of the agent's software. The
important point is that if $CanObs(agt,a,s)$ is true and action $a$
occurs, then $agt$ will be made aware of it. The axiomatisation of
this predicate is the responsibility of the domain modeler.

There is a related assumption implicit in the handling of sensing
actions: only the agent performing a sensing action is aware of its
result. Such a restriction is common but certainly not universal.
Consider an agent waiting for a train who activates a speaker to determine
when it will arrive. The result of this sensing action would be available
to any other agent within earshot. We add an analogous predicate $CanSense(agt,a,s)$
to indicate when the sensing information resulting from an action
is available to an agent.

To allow comparison of what is observed by an agent in different situations,
we introduce a new sort \noun{Observations} consisting of sets of
action/result pairs. The function $Observations(agt,c,s)$ is defined
to return precisely the set of $<action,result>$ pairs that $agt$
would be aware of if the actions $c$ were performed in situation
$s$ . The special result term {}``?'' indicates that the result
of an action was not available:
\begin{multline}
Observations(agt,c,s)=o\equiv\\
\forall a,r\,\left[<a,r>\in o\equiv a\in c\wedge CanObs(agt,a,s)\right.\\
\wedge\,\left(CanSense(agt,a,s)\wedge r=SR(a,s)\right.\\
\left.\vee\,\left.\neg CanSense(agt,a,s)\wedge r="?"\right)\right]\label{eqn:observations_orig}
\end{multline}
Like their counterpart $Poss$, $CanObs$ and $CanSense$ may suffer
from interaction problems when concurrent actions are considered.
While we are confident an approach similar to that used for precondition
interaction can be applied, this remains an open problem.

With a concrete notion of observations in place, the concept of an
\emph{observation history} follows naturally - it is a sequence of
all the observations made by an agent as the world has evolved. We
introduce the sort \noun{History} consisting of sequences of observations,
with $\epsilon$ being the empty sequence, and the fluent $ObsHist$
giving the history associated with a particular situation:
\begin{multline}
Init(s)\rightarrow ObsHist(agt,h,s)\equiv h=\epsilon\\
\shoveleft{ObsHist(agt,h,do(c,s))\equiv}\\
\,\,\,\, Observations(agt,c',s')=\{\}\rightarrow ObsHist(agt,h,s')\\
\shoveleft{\,\,\,\,\wedge\,\exists o\,.\, Observations(agt,c',s')=o\wedge o\neq\{\}\rightarrow}\\
\exists h'\,\, h=o\cdot h'\wedge ObsHist(agt,s',h')\label{eqn:obshist_defn}
\end{multline}


\subsubsection{Successor State Axiom for $K$}

In their classic article, \cite{halpern90knowledge_distrib} assert
that \emph{{}``an agent's knowledge at a given time must depend only
on its local history: the information that it started out with combined
with the events it has observed since then''}. Given an explicit
account of the observations made by each agent, the required semantics
of the $K$ relation are clear: $K(agt,s'',s)$ must hold whenever
situations $s''$ and $s$ would result in the same sequence of observations
being made by the agent. We first introduce the predicates $Legal(c,s)$
and $Legal(s)$, which single out situations that can actually be
brought about in the world:
\begin{equation}
\begin{split}
& Legal(c,s)\equiv Poss(c,s)\\
& Init(s)\rightarrow Legal(s)\\
& Legal(do(c,s))\equiv Legal(c,s)\wedge Legal(s)
\end{split}
\end{equation}
We further introduce the abbreviation $\mathbf{Unobs}(agt,s,s')$,
which is true when $agt$ would not be aware of any of the actions
leading from $s$ to $s'$:
\begin{multline}
\mathbf{Unobs}(agt,s,s''))\,\isdef\,\neg\exists c',s'\,.\, s<do(c',s')\leq s''\\
\wedge\, Observations(agt,c',s')\neq\{\}\label{eqn:unobs_defn}
\end{multline}
If the agent considers possible a situation $s$ then it must also
consider possible any legal situation $s'$ such that $\mathbf{Unobs}(s,s')$.
Also note that $\mathbf{Unobs}(s,s)$ is always true. The following
successor state axiom then captures the desired semantics of knowledge:
\begin{multline}
K(agt,s'',do(c,s))\equiv\\
Observations(agt,c,s)=\{\}\wedge K(agt,s'',s)\\
\shoveleft{\vee\,\,\exists o\, Observations(agt,c,s)=o\,\wedge}\\
o\neq\{\}\wedge Legal(s'')\,\wedge\\
\exists c',s'\, Observations(agt,c',s')=o\,\wedge\\
K(agt,s',s)\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\label{eqn:new_k_ssa}
\end{multline}
If $c$ was totally unobservable, the agent's state of knowledge does
not change. Otherwise, it considers possible any legal successor to
a possible situation that can be brought about by actions $c'$ resulting
in the same set of observations $o$. It also considers possible any
unobservable future of such a situation.

It remains to specify $K$ in the initial situation. Since situations
where $\mathbf{Unobs}(agt,s,S_{0})$ should be $K$-related to $S_{0}$,
we introduce another relation $K_{0}$ to specify each agent's knowledge
in the initial situation:
\begin{multline}
K_{0}(s',s)\rightarrow Init(s')\wedge Init(s)\\
\shoveleft{Init(s)\rightarrow K(agt,s'',s)\equiv}\\
\,\,\,\,Legal(s)\wedge\exists s'\,\left[K_{0}(agt,s',s)\wedge\mathbf{Unobs}(agt,s',s)\right]\label{eqn:new_k_s0}
\end{multline}
From these definitions, it is straightforward to show that knowledge
is completely determined by an agent's observations: two legal situations
are $K$-related iff they have identical observation histories, and
are rooted at $K_{0}$-related situations.
\begin{theorem}
For any theory of action $\mathcal{D}$ containing our new semantics
of knowledge, any agent $agt$ and any legal situations $s$ and $s'$:
\begin{multline*}
\mathcal{D}\models K(agt,s',s)\equiv K_{0}(Root(s'),Root(s))\\
\wedge\exists h\, ObsHist(agt,h,s)\wedge ObsHist(agt,h,s')
\end{multline*}
\end{theorem}
This new formulation overcomes the limitations highlighted previously.
By appropriately axiomatizing $CanObs$ and $CanSense$ it is possible
to model both total awareness of actions and total ignorance. It also
enables previously unaccounted-for circumstances, such as only being
aware of the actions of all agents within one's field of view, or
all agents on one's own team. At the same time, it ensures that an
agent's state of knowledge does not change if it is not aware of any
actions occurring. It is thus a true generalization and improvement
over previous approaches.

It is straightforward to verify that important properties of the $K$
relation discussed in \cite{scherl03sc_knowledge} are maintained
by our new formulation, including memory, default persistence of ignorance,
knowledge producing effects, and preservation of transitive, symmetric,
reflexive and euclidean relations.


\subsubsection{Observing Fluent Change}

In many domains it may be infeasible for an agent to be aware that
a particular action has occurred, but it may be aware that a particular
fluent has changed. For example, suppose that an agent monitors the
state of a light bulb in its environment, such that it notices it
changing from dark to light. While it knows that \emph{some} action
must have occurred, it is not sure precisely which action took place.

This can be modeled by introducing a special class of actions called
\emph{change actions} that inform agents that some property of the
world has changed. They never appear in situation terms directly,
but are included in the list of observations made by an agent by modifying
the $Observations$ predicate as follows:
\begin{multline*}
Observations(agt,c,s)=o\equiv\\
\shoveleft{\,\,\,\,\forall a,r\,\left[<a,r>\in o\equiv\right.}\\
\left[a\in c\,\vee\, ChangeAction(a)\wedge SR(a,s)\neq SR(a,do(c,s))\right]\\
\wedge CanObs(agt,a,s)\\
\wedge\,\left(CanSense(agt,a,s)\wedge SR(a,s)=r\right.\\
\left.\vee\,\left.\neg CanSense(agt,a,s)\wedge r="?"\right)\right]
\end{multline*}
 According to this definition, change actions appear in the list of
observations only when the corresponding sensing result changes in
the successor situation. By defining an appropriate $SR$ function,
and making agents aware of these actions using $CanObs$ and $CanSense$,
our formalism can neatly handle this form of environmental awareness.


\subsubsection{Regression}

The appearance of $\mathbf{Unobs}$ in equation (\ref{eqn:new_k_ssa})
means that our new successor state axiom universally quantifies over
situations, and so is not regressable using standard techniques. To
permit an effective reasoning procedure, we appeal to the \emph{persistence
condition} meta-operator. In recent unpublished work {[}citation omitted]
we develop a new meta-operator $\mathcal{P}_{\mathcal{D}}(\phi,\alpha)$,
taking a uniform formula $\phi$ and some action conditions $\alpha(c,s)$
, such that:
\begin{multline}
\mathcal{D}\models\mathcal{P}_{\mathcal{D}}(\phi,\alpha)[s]\,\,\equiv\,\,\forall s''\, s\leq s''\wedge\\
\neg\exists c',s'\, s<do(c',s')\leq s''\wedge\neg\alpha(c',s')\,\rightarrow\,\phi[s'']\label{eqn:P_defn}
\end{multline}
The truth of $\mathcal{P}_{\mathcal{D}}(\phi,\alpha)$ in a situation
$s$ guarantees that, as long as all subsequent actions satisfy $\alpha$,
the formula $\phi$ will remain true in all situations in the future
of $s$. It thus represents the conditions under which $\phi$ will
\emph{persist} with respect to the given class of actions. The procedure
for determining $\mathcal{P}_{\mathcal{D}}$ replaces second-order
induction with iterated first-order reasoning, and always produces
a uniform formula. It also requires that there be only finitely many
types of action, an assumption met by most realistic multi-agent domains.

By singling out unobservable actions, the persistence condition can
be used to augment existing techniques for regressing formulae about
knowledge. Define the macro $\mathbf{UA}$ to identify legal, unobservable
sets of actions:
\begin{multline*}
\mathbf{UA}(agt,c,s)\isdef\\
Legal(c,s)\wedge Observations(agt,c,s)=\{\}
\end{multline*}
Assuming that the $K$ fluent appears only in the context of a $\mathbf{Knows}$
macro, we propose the following to replace the regression of $\mathbf{Knows}$
given by \cite{scherl03sc_knowledge}:
\begin{multline}
\mathcal{R}_{\mathcal{D}}(\mathbf{Knows}(agt,\phi,do(c,s)))=\\
\left[Observations(agt,c,s)=\{\}\rightarrow\mathbf{Knows}(agt,\phi,s)\right]\\
\wedge\left[\exists o\,\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\mathbf{Knows}(agt,\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\left.\mathcal{R}_{\mathcal{D}}(\mathcal{P}_{\mathcal{D}}(\phi,\mathbf{UA}(agt))[do(c',s')]),s)\right]\label{eqn:R_do_c_s}
\end{multline}
As required, this reduces reasoning about knowledge in $do(c,s)$
to reasoning about knowledge in $s$. It is also intuitively appealing:
to know that $\phi$ holds, the agent must know that in all situations
that agree with its observations, $\phi$ cannot become false without
it noticing that an action has occurred. We must also specify the
regression of $\mathbf{Knows}$ in the initial situation, as equation
(\ref{eqn:new_k_s0}) also quantifies over situations:
\begin{multline}
\mathcal{R}_{\mathcal{D}}(\mathbf{Knows}(agt,\phi,S_{0}))=\\
\forall s\, K_{0}(agt,s)\rightarrow\mathcal{P}_{\mathcal{D}}(\phi,\mathbf{UA}(agt))[s]\label{eqn:R_s0}
\end{multline}
 This is then standard first-order modal reasoning over the $K_{0}$
relation. We sketch below the highlights of a proof that our modified
regression operator preserves equivalence.

Regression of the additional predicates we have introduced ($CanObs$,
$Observations$, etc) is identical to that of the $Poss$ predicate
and requires no special treatment here, except to mention that the
restriction to a finite number of actions allows regression of such
formulae even when their arguments are variables.

\begin{theorem}

Given a theory of action $\mathcal{D}$ with regression and persistence
operators defined relative to it, a uniform formula $\phi$ and a
ground situation term $s$, it is always the case that:
\begin{equation*}
\mathcal{D}\models\phi[s]\equiv\mathcal{R}_{\mathcal{D}}^{*}(\phi)[S_{0}]
\end{equation*}


\end{theorem}

\begin{proof}

It suffices to show that $\mathcal{R}_{\mathcal{D}}$ preserves equivalence
for $\mathbf{Knows}$, as that it all we have modified from the definitions
in \cite{scherl03sc_knowledge}. Combining and rearranging equations
(\ref{eqn:knows_def}) and (\ref{eqn:new_k_ssa}), the definition
of $\mathbf{Knows}$ can be written in the form:
\begin{multline*}
\mathbf{Knows}(agt,\phi,do(c,s))\equiv\\
\left[Observations(agt,c,s)=\{\}\rightarrow\forall s''K(agt,s'',s)\rightarrow\phi[s'']\right]\\
\wedge\left[\exists o\,\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\forall s'\, K(agt,s',s)\rightarrow\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\left.\forall s''\, Legal(s'')\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\,\rightarrow\,\phi[s'']\right]
\end{multline*}
Note that both of these conjuncts contain sub-formulae matching the
form of the $\mathbf{Knows}$ macro. It can thus be substituted back
in to give:
\begin{multline*}
\mathbf{Knows}(agt,\phi,do(c,s))\equiv\\
\left[Observations(agt,c,s)=\{\}\rightarrow\mathbf{Knows}(agt,\phi,s)\right]\\
\wedge\left[\exists o\,\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\left.\mathbf{Knows}(agt,\mathbf{PK}(\phi,o)),s)\right]
\end{multline*}
Where we have defined the abbreviation $\mathbf{PK}(\phi,o,s')$ as:
\begin{multline*}
\mathbf{PK}(\phi,o,s')\isdef\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\forall s''\, Legal(s'')\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\,\rightarrow\,\phi[s'']
\end{multline*}
For $\mathbf{PK}(\phi,o,s')$ to legitimately appear in the $\mathbf{Knows}$
macro it must be uniform in the situation variable $s'$. Noting that
equation (\ref{eqn:unobs_defn}) matches the form of equation (\ref{eqn:P_defn}),
and regressing to make the expression uniform, we develop
the following equivalence, which is as required:
\begin{multline*}
\mathbf{PK}(\phi,o,s')\equiv\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\mathcal{R}_{\mathcal{D}}(\mathcal{P}_{\mathcal{D}}(\phi,Legal()\wedge Observations(agt)=\{\})[do(c',s')])
\end{multline*}
For the initial situation, a straightforward transformation of equations
(\ref{eqn:knows_def}) and (\ref{eqn:new_k_s0}) gives:
\begin{multline*}
\mathbf{Knows}(\phi,S_{0})\equiv\forall s\, K_{0}(agt,s)\rightarrow\\
\{\forall s'\, Legal(s')\wedge\mathbf{Unobs}(s,s')\rightarrow\phi[s']\}
\end{multline*}
Applying the persistence condition operator, this can easily be re-written
in the required form:
\begin{multline*}
\mathbf{Knows}(\phi,S_{0})\equiv\forall s\, K_{0}(agt,s)\rightarrow\\
\mathcal{P}_{\mathcal{D}}(\phi,Legal()\wedge Observations(agt)=\{\})[s]
\end{multline*}


\end{proof}

We can thus reduce reasoning about knowledge to modal reasoning in
the initial situation, as in previous work. Our extension of the regression
operator provides a mechanical procedure for reasoning in our improved
account of knowledge, without requiring second-order logic.


\subsubsection{Regressing over Observations}

While the above reasoning method is suitable for modeling and simulation
purposes, it would be unreasonable in general for a situated agent
to ask {}``do I know $\phi$ in the current situation?'' using the
situation calculus query $\mathcal{D}\models\mathbf{Knows}(agt,\phi,s)$,
as it cannot be expected to be aware of the full current situation
$s$. However, it will be aware of its current observation history
$h$. Let us therefore define knowledge with respect to a history
as follows:
\begin{multline*}
\mathbf{Knows}(agt,\phi,h)\isdef\\
\forall s\, ObsHist(agt,h,s)\wedge Root(s)=S_{0}\rightarrow\mathbf{Knows}(agt,\phi,s)
\end{multline*}
The following is then a straightforward consequence of our semantics of
knowledge:
\begin{theorem}

Given a theory of action $\mathcal{D}$ including our semantics for
knowledge, a situation term $s$ rooted at $S_{0}$, and an observation
history $h$ such that $ObsHist(agt,h,s)$:\
\begin{equation*}
\mathcal{D}\models\mathbf{Knows}(agt,\phi,s)\equiv\mathbf{Knows}(agt,\phi,h)\end{equation*}


\end{theorem}
Extending the definitions developed in equations (\ref{eqn:R_do_c_s}) and
(\ref{eqn:R_s0}) to handle regressing formulae
of this form is actually simpler than regressing over situations,
as there are no empty observations in a history:
\begin{multline*}
\mathcal{R}_{\mathcal{D}}(\mathbf{Knows}(agt,\phi,o\cdot h))=\\
\mathbf{Knows}(agt,\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\mathcal{R}_{\mathcal{D}}(\mathcal{P}_{\mathcal{D}}(\phi,\mathbf{UA}(agt))[do(c',s')]),h)
\end{multline*}
\begin{multline*}
\mathcal{R}_{\mathcal{D}}(\mathbf{Knows}(agt,\phi,\epsilon))=\\
\forall s\, K_{0}(agt,s)\rightarrow\mathcal{P}_{\mathcal{D}}(\phi,\mathbf{UA}(agt))[s]
\end{multline*}
Using this, agents can reason about their own knowledge using only
their local information. Our work thus makes it possible to include
a situation calculus model in the implementation of a real-world multi-agent
system, even when agents have only partial awareness of actions.


\section{Conclusions\label{sec:Conclusions}}

In this paper we have significantly increased the scope of the situation
calculus for modeling knowledge in multi-agent domains. By explicitly
reifying the observations made by each agent as the world evolves,
we have generalized the dynamics of knowledge update. We have shown
that this can accommodate the important case where agents are aware
that a property of their environment has changed, but do not know
the precise actions responsible. Despite requiring universal quantification
over future situations, we have shown that the regression operator
can be adapted to our new formalism. This technique can also be used
for reasoning from the internal perspective of a single agent.

With our new semantics of knowledge, the situation calculus is well
positioned for representing, reasoning about, and implementing more
realistic multi-agent systems.

\bibliographystyle{named} \bibliographystyle{named}
\bibliography{/storage/uni/pgrad/library/references}


\end{document}

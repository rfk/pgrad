\documentclass[letterpaper]{article}
\usepackage{amsmath}

\makeatletter

\newcommand{\noun}[1]{\textsc{#1}}

\usepackage{ijcai07}

\usepackage{times}

\usepackage{helvet}

\usepackage{courier}

\usepackage{amsthm}



\newcommand{\isdef}{\hbox{$\stackrel{\mbox{\tiny def}}{=}$}}


\newtheorem{theorem}{Theorem}

\makeatother
\begin{document}


\title{Multi-Agent Knowledge in the Situation Calculus with\\
 Partial Awareness of Actions}


\author{Ryan Kelly and Adrian Pearce\\
 Department of Computer Science and Software Engineering\\
NICTA Victoria Laboratory\\
 The University of Melbourne\\
 Victoria, 3010, Australia\\
 \{rfk,adrian\}@csse.unimelb.edu.au}

\maketitle
\begin{abstract}
We develop significant improvements to the existing accounts of knowledge
in the situation calculus. Situation calculus models of multi-agent
domains typically make one of two assumptions: that all agents are
aware of all actions that have been performed, or that each agent
is completely ignorant of actions performed by others. By reifying
the observations made by each agent, we develop an enhanced account
of knowledge that spans these two extremes. Our approach can naturally
model agents who monitor the value of fluents in their environment,
and provides a more modular approach to communication actions. We
show how to reason effectively in this formalism using an extended
regression operator that accommodates limited quantification over
situations. 
\end{abstract}

\section{Introduction}

The situation calculus is one of the most popular formalisms for reasoning
about dynamic worlds. Since its inception, many extensions have been
proposed to enrich it with concepts such as knowledge and concurrent
actions. These extensions can be combined to provide a rich formalism
for modeling multi-agent domains.

An almost universal assumption when working in the situation calculus
is that agents are fully aware of the actions that have been performed
in the world. Indeed, the notion of 'situation' is formalized as a
history of all actions that have occurred. In the rare cases that
this is not assumed, the opposing extreme is posited - that agents
are completely ignorant of actions performed by others.

Both of these assumptions are unrealistic in many domains, and can
limit the applicability of the situation calculus. To overcome this,
we reify the notion of \emph{observations} and axiomatize the conditions
under which an agent will observe the occurrence of an action. By
ensuring that agents consider possible any situation compatible with
what they have observed, we develop an improved account of knowledge
that spans the two extremes. We then show that this formulation can
be naturally extended to model agents who monitor the values of fluents
in their environment, rather than directly observing actions. It also
allows communication actions to be added or modified without altering
the fundamental axioms of knowledge.

Our new semantics of knowledge depend on universal quantification
over situation terms, traditionally a roadblock for automated reasoning.
Despite this, we show that an extension of the regression operator
permits reasoning within our formulation. The final result is a powerful
new account of multi-agent knowledge that still permits a suitably
efficient reasoning procedure.

The paper is organized as follows: section \ref{sec:ma-sitcalc} gives
a brief introduction to the situation calculus with knowledge and
concurrent actions, and highlights some of the limitations of current
approaches; section \ref{sec:New-Semantics} introduces our improved
semantics of knowledge and shows how to reason effectively with them;
and section \ref{sec:Conclusions} concludes with a summary of our
results.


\section{The Multi-Agent Situation Calculus\label{sec:ma-sitcalc}}

We work in a version of the the situation calculus as described in
\cite{pirri99contributions_sitcalc}, enriched with concurrent actions
\cite{reiter96sc_nat_conc} to more realistically represent the dynamics
of a multi-agent system. We use the approach of \cite{shapiro01casl_feat_inter}
for representing multiple agents, and begin from the standard account
of knowledge given by \cite{scherl03sc_knowledge,scherl03conc_knowledge}.
A brief overview is presented below.

The situation calculus is a many-sorted language of first-order logic,
augmented with a second-order induction axiom. Its has the following
sorts: \noun{Agent} terms (variables $agt_{y}^{x}$) represent the
agents operating in the world; \noun{Action} terms (variables $a_{y}^{x}$)
are functions denoting individual instantaneous events that can cause
the state of the world to change, with the initiating agent indicated
by their first argument; \noun{Concurrent} terms (variables $c_{y}^{x}$)
are sets of actions that occur simultaneously; \noun{Situation} terms
(variables $s_{y}^{x}$) are histories of the concurrent actions that
have occurred in the world, with the initial situation represented
by $S_{0}$ and successive situations built up using the function
$do\,:\, Concurrent\times Situation\rightarrow Situation$; \noun{Result}
terms (variables $r_{y}^{x}$) represent sensing results returned
by actions, and are written inside double-quotes; \noun{Object} terms
(variables $obj_{y}^{x}$) represent any other object in the domain.
We also distinguish \noun{Fluents} as predicates or functions representing
properties of the world that may change from one situation to another.
Fluents take a situation term as their final argument.

A collection of situation calculus statements that describe the behavior
of a dynamic world is referred to as a \emph{theory of action} and
is typically represented by $\Sigma$. Queries about the behavior
or evolution of the world are posed as logical entailment queries
relative to the theory of action.


\subsubsection{Action Precondition Axioms}

There is a distinguished fluent predicate $Poss(a,s)$ that indicates
when it is possible to perform an action in a given situation. For
example, it is only possible for an agent to drop an object if they
are actually holding it:
\footnote{We follow the convention that lower-case names indicate variables,
with free variables being implicitly universally quantified %
}
\begin{equation*}
Poss(drop(agt,obj),s)\equiv Holding(agt,obj,s)
\end{equation*}
For concurrent actions, an arbitrary combination of actions $\{ a_{1},a_{2}\}$
is not guaranteed to be possible. While the actions $moveTo(Chair)$
and $moveTo(Table)$ may individually be possible, performing them
concurrently clearly is not. This is known as the precondition interaction
problem \cite{reiter96sc_nat_conc}. A simple solution is to explicitly
state which actions cannot be performed together using a predicate
$Conflicts$:
\begin{multline*}
Poss(c,s)\equiv\\
\forall a\left[a\in c\rightarrow Poss(a,s)\right]\wedge\neg Conflicts(c,s)
\end{multline*}
For this paper, we make no particular commitment toward a solution
to this problem.


\subsubsection{Successor State Axioms}

The truth of the various fluents is specified by defining what is
true of the initial situation, and collecting the effects of various
actions into \emph{successor state axioms}. Such axioms provide a
monotonic solution to the infamous frame problem \cite{reiter91frameprob}
and are a principle attraction of the situation calculus. They have
the general form: \begin{multline*}
F(\overrightarrow{x},do(c,s))\equiv\\
\Gamma^{+}(\overrightarrow{x},c,s)\,\vee\, F(\overrightarrow{x},s)\wedge\neg\Gamma^{-}(\overrightarrow{x},c,s)\end{multline*}


Here $F$ is a fluent with non-situation arguments $\overrightarrow{x}$,
$\Gamma^{+}$ is a formula giving the conditions under which $F$
will become true, and $\Gamma^{-}$ a formula giving the conditions
under which $f$ will become false. In words, these axioms state that
{}``$F$ is true after doing actions $c$ if $c$ causes $F$ to
become true, or $F$ is currently true and $c$ doesn't cause $F$
to become false''.


\subsubsection{Uniform Formulae}

An important class of formulae in the situation calculus are the \emph{uniform
formulae} - those that refer to a single situation term, so representing
a property of a situation. Throughout this paper, we will use the
meta-variable $\phi$ to refer to an arbitrary uniform formula. Where
no confusion can arise, we suppress the situation terms in uniform
formulae to simplify the presentation. It is also standard practice
to pass uniform formulae as arguments to other functions or predicates
- this technically requires an encoding of formulae as terms, as discussed
in \cite{shapiro01casl_feat_inter}. We omit such details for notational
simplicity.

It is often useful to determine the truth of a uniform formula at
a given situation term. The formula $\phi[s]$ represents the uniform
formula $\phi$ with all occurrences of its unique situation term
replaced by the situation $s$.


\subsubsection{Communication}

Inter-agent communication is typically modeled using special communication
actions. Representative of this approach are the $informWhether(agt_{1},agt_{2},\phi)$
and $informRef(agt_{1},agt_{2},\theta)$ actions of \cite{shapiro01casl_feat_inter},
whereby $agt_{1}$ informs $agt_{2}$ about the truth of a formula
or the referent of a function respectively. We shorten these to $infWhether$
and $infRef$ in our presentation. Such actions are intricately connected
with knowledge, and existing accounts directly include them in the
dynamics of knowledge change.


\subsubsection{Knowledge and Sensing}

The semantics of knowledge in the situation calculus \cite{scherl03sc_knowledge}
are based on the popular {}``possible worlds'' model. A knowledge
fluent $K(agt,s',s)$ is used to indicate that {}``in situation $s$,
the agent $agt$ considers the alternate situation $s'$ to be possible''.
A knowledge operator $\mathbf{Knows}$ is then introduced as a macro:
\begin{equation}
\mathbf{Knows}(agt,\phi,s)\isdef\forall s'\, K(agt,s',s)\rightarrow\phi[s']\label{eqn:knows_def}\end{equation}


Thus an agent knows something if it is true in all situations that
the agent considers possible. This can be specialized with further
macros, such as an agent knowing whether or not some formula holds:
\begin{multline*}
\mathbf{KWhether}(agt,\phi,s)\isdef\\
\mathbf{Knows}(agt,\phi,s)\vee\mathbf{Knows}(agt,\neg\phi,s)\end{multline*}


To allow actions to return sensing information, the sensing result
function $SR(a,s)$ is introduced to give the result returned by the
action $a$ when executed in a situation $s$. This is defined by
axioms of the form: \begin{equation*}
SR(a(\overrightarrow{x}),s)=r\equiv\phi_{a}(\overrightarrow{x},r,t,s)\end{equation*}


For actions that don't return sensing information, the value of $SR$
is set to some arbitrary constant such as $"OK"$. As an example,
consider the action $sense_{F}$ which senses whether fluent $F$
is true or false. Its sensing result axiom would be given by: \begin{multline*}
SR(sense_{F},s)=r\equiv\\
(r="YES"\wedge F(s))\vee(r="NO"\wedge\neg F(s))\end{multline*}


Combining the multi-agent semantics of \cite{shapiro01casl_feat_inter}
with the handling of concurrent actions in \cite{scherl03conc_knowledge},
the common form of successor state axiom for the knowledge fluent
can be written as:\begin{multline}
K(agt,s'',do(c,s))\equiv\\
\exists s'\,.\, s''=do(c,s')\,\wedge K(agt,s',s)\wedge Poss(c,s')\\
\wedge\,\forall a\left[a\in c\wedge agent(a)=agt\rightarrow SR(a,s)=SR(a,s')\right]\\
\wedge\,\forall agt_{2},\phi\left[infWhether(agt_{2},agt,\phi)\in c\rightarrow\phi[s']\equiv\phi[s]\right]\\
\wedge\,\forall agt_{2},\theta\left[infRef(agt_{2},agt,\theta)\in c\rightarrow\theta[s']=\theta[s]\right]\label{eqn:k_ssa_standard}\end{multline}

In words, this states that $s''$ is considered a possible alternative
to $do(c,s)$ when $s''$ is the result of doing those same actions
$c$ in a situation $s'$ that is a possible alternative to $s$.
The situation $s''$ must furthermore be possible, the sensing results
must be consistent for all actions in $c$ that were carried out by
the agent, and the situation must be consistent with what it has been
informed by others.

Alternate possible worlds to the initial situation are identified
by truth of the predicate $K_{0}(agt,s)$. This allows the $K$ fluent
to be fully specified, by asserting that:\begin{equation}
K(agt,s,S_{0})\equiv K_{0}(agt,s)\end{equation}


While quite powerful, this formulation suffers from a severe limitation:
each agent must be aware of \emph{all} actions that have occurred.
Responsibility for generating such {}``awareness'' is abdicated
to a separate component of the agent's software. Many realistic multi-agent
domains clearly do not satsify this assumption. An alternate formulation
from \cite{Lesperance99sitcalc_approach} gives the opposite extreme:\begin{multline}
K(agt,s'',do(c,s))\equiv\\
\exists s',s^{*},c'\,.\, s''=do(c',s^{*})\,\wedge K(s',s)\wedge Poss(c',s^{*})\\
\wedge\,\mathbf{ExoOnly}(agt,s',s^{*})\\
\wedge\,\forall a\left[agent(a)=agt\rightarrow a\in c'\equiv a\in c\right]\\
\wedge\,\forall a\left[a\in c\wedge agent(a)=agt\rightarrow SR(a,s)=SR(a,s')\right]\\
\wedge\,\forall agt_{2},\phi\left[infWhether(agt_{2},agt,\phi)\in c\rightarrow\phi[s']\equiv\phi[s]\right]\\
\wedge\,\forall agt_{2},\theta\left[infRef(agt_{2},agt,\theta)\in c\rightarrow\theta[s']=\theta[s]\right]\label{eqn:k_ssa_exo}\end{multline}

Where the macro $\mathbf{ExoOnly}$ indicates that two situations
are connected only by actions performed by other agents:\begin{multline*}
\mathbf{ExoOnly}(agt,s,s'')\,\isdef\, s\leq s''\wedge\\
\forall s',c,a\left[s<do(c,s')\leq s''\wedge a\in c\rightarrow agent(a)\neq agt\right]\end{multline*}


With this approach, agents consider possible any situation compatible
with the actions that they themselves have performed. There may have
been an arbitrary sequence of situations between $s'$ and $s''$
which the agent knew nothing about, because they consisted entirely
of exogenous (from $agt$'s point of view) actions. But this approach
is also limiting, in that agents can \emph{never} be aware of the
actions performed by others. Full generality requires a middle ground,
with agents being aware of \emph{some} of the actions performed by
others.

Furthermore, suppose that $agt$ has just performed action $a_{1}$,
so the world is in some situation $do(a_{1},s)$. Another agent then
performs the action $a_{2}$, leaving the world in situation $do(a_{2},do(a_{1},s))$.
Since it cannot observe $a_{2}$ occurring, $agt$ would not be aware
that the state of the world has changed. Its set of possible situations
should therefore remain unchanged. Unfortunately, $K(agt,s',do(a_{2},do(a_{1},s)))\not\equiv K(agt,s',do(a_{1},s))$
under this formulation. To faithfully represent this aspect of the
knowledge of real-world agents, the successor state axiom for $K$
must permit any arbitrary future of $do(a_{1},s)$ that can be brought
about by exogenous actions, rather than any arbitrary past as done
above.

We overcome these limitations with the development of an improved
successor state axiom for $K$.


\subsubsection{Regression}

One of the attractions of the situation calculus is the existence
of efficient reasoning procedures for certain types of query. The
principle tool is the regression meta-operator \cite{reiter91frameprob}
which transforms a formula $\phi$ uniform in $do(c,s)$ into a formula
$\mathcal{R}_{\Sigma}(\phi)$ uniform in $s$, such that the two are
equivalent relative to the theory of action $\Sigma$. By repeatedly
applying the regression operator, $\phi$ can be transformed into
an equivalent formula uniform in the initial situation:\begin{equation*}
\Sigma\models\phi[do(c_{1},do(c_{2},\dots,do(c_{n},S_{0}))]\equiv\mathcal{R}_{\Sigma}^{*}(\phi)[S_{0}]\end{equation*}

Many of the axioms from $\Sigma$ are not required for reasoning about
the initial situation, and so can be discarded when reasoning about
$\mathcal{R}_{\Sigma}^{*}(\phi)[S_{0}]$. This is frequently more
efficient than directly reasoning about $\phi$.

In \cite{scherl03sc_knowledge}, the regression operator is extended
to handle to the standard account of knowledge (equation \ref{eqn:k_ssa_standard})
by reducing reasoning about formulae containing the $\mathbf{Knows}$
macro to \emph{modal} reasoning over the $K_{0}$ relation. Regressing
such formulae relies on the fact that agents are aware of all actions
- formulae containing quantification over situations, such as the
modified successor state axiom for knowledge in equation \ref{eqn:k_ssa_exo},
cannot be handled by the regression operator. Indeed, \cite{Lesperance99sitcalc_approach}
offer no procedure for reasoning in their formalism other than using
second-order induction.

By using an extension of the regression idea that can handle limited
forms of quantification over situations, we provide a purely first-order
reasoning procedure for our improved account of knowledge.


\section{New Semantics of Knowledge\label{sec:New-Semantics}}


\subsubsection{Awareness of Actions}

Existing accounts of knowledge in the situation calculus all employ
an assumption about when an agent is aware of the occurrence of an
action - either {}``agents are always aware of actions'' or {}``agents
are only aware of actions that they themselves perform''. We replace
such assumptions with a question: {}``when will an agent be aware
of the occurrence of an action?''. By providing a way to answer this
question within the theory of action, a more general account of knowledge
can be developed.

A new fluent is introduced, akin to $Poss$ but describing when actions
will be observed by agents: $CanObs(agt,a,s)$ indicates that agent
$agt$ would be aware of action $a$ being performed in situation
$s$. As before, we assume that in an implemented system this {}``awareness''
is generated by some other component of the agent's software. The
important point is that if $CanObs(agt,a,s)$ is true and action $a$
occurs, then $agt$ will be made aware of it. Likewise, if $agt$
is not aware that action $a$ occurred, then it did not occur. The
axiomatisation of this predicate, like that of $Poss$, is the responsibility
of the domain modeler.

There is a related assumption implicit in the handling of sensing
actions: that only the agent performing a sensing action is aware
of its result. Such a restriction is common in the real world, but
certainly not universal. Consider an agent waiting for a train who
activates a speaker to acquire information about when it will arrive.
The result of this sensing action would be available to any other
agent within earshot. We add an analogous predicate $CanSense(agt,a,s)$
to indicate when the sensing information resulting from an action
is available to an agent.

Since we will often want to compare what is observed by an agent in
different situations, we introduce a new sort \noun{Observations}
consisting of sets of action/result pairs. We then define the function
$Observations(agt,c,s)$ which returns precisely the set of $<action,result>$
pairs that $agt$ would be aware of if the concurrent actions $c$
were performed in situation $s$ . The special result term {}``?''
indicates that the result of an action was not available:\begin{multline}
Observations(agt,c,s)=o\equiv\\
\forall a,r\,\left[<a,r>\in o\equiv a\in c\wedge CanObs(agt,a,s)\right.\\
\wedge\,\left(CanSense(agt,a,s)\wedge r=SR(a,s)\right.\\
\left.\vee\,\left.\neg CanSense(agt,a,s)\wedge r="?"\right)\right]\label{eqn:observations_orig}\end{multline}
Like their counterpart $Poss$, $CanObs$ and $CanSense$ may suffer
from interaction problems when concurrent actions are considered -
for example, one agent moving in front of another may mean the second
agent's actions are no longer observable. While we are confident an
approach similar to that used for precondition interaction can be
applied, this remains an open problem.


\subsubsection{Successor State Axiom for $K$}

Given an explicit account of the observations made by each agent,
the required semantics of the $K$ relation are clear: $K(agt,s'',s)$
must hold whenever situations $s''$ and $s$ would result in the
same sequence of observations being made by the agent. We first introduce
the abbreviation $\mathbf{Unobs}(agt,s,s')$, which is true when $agt$
would not be aware of any of the actions leading from $s$ to $s'$:
\begin{multline}
\mathbf{Unobs}(agt,s,s''))\,\isdef\,\neg\exists c',s'\,.\, s<do(c',s')\leq s''\\
\wedge\, Observations(agt,c',s')\neq\{\}\label{eqn:unobs_defn}\end{multline}

If the agent considers possible a situation $s$ then it must also
consider possible any situation $s'$ such that $\mathbf{Unobs}(s,s')$,
as it would be completely unaware of the world changing from $s$
to $s'$. Also note that $\mathbf{Unobs}(s,s)$ is always true. Let
us further introduce the predicate $Legal(s)$, which states that
a situation can legally be brought about in the world. For this basic
situation calculus, it suffices to constrain all actions to be possible:
\begin{equation}
\begin{split}
& Legal(S_{0})\equiv True\\
& Legal(do(c,s))\equiv Poss(c,s)\wedge Legal(s)\end{split}
\end{equation}

The following successor state axiom for knowledge then captures the
desired semantics: \begin{multline}
K(agt,s'',do(c,s))\equiv\\
Observations(agt,c,s)=\{\}\wedge K(agt,s'',s)\\
\shoveleft{\vee\,\,\exists o\, Observations(agt,c,s)=o\,\wedge}\\
o\neq\{\}\wedge Legal(s'')\,\wedge\\
\exists c',s'\, Observations(agt,c',s')=o\,\wedge\\
K(agt,s',s)\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\label{eqn:new_k_ssa}\end{multline}


If $c$ was totally unobservable, the agent's state of knowledge does
not change. Otherwise, it considers possible any legal successor to
a possible situation that can be brought about by actions $c'$ resulting
in the same set of observations $o$. It also considers possible any
unobservable future of such a situation.

It remains to specify the truth of the $K$ fluent in the initial
situation. Assuming that alternate initial situations are identified
by the truth of $K_{0}(agt,s)$ as in previous works, then the following
captures the intended semantics:\begin{multline}
K(agt,s,S_{0})\equiv\\
Legal(s)\wedge\exists s'\,\left[K_{0}(agt,s')\wedge\mathbf{Unobs}(agt,s',s)\right]\label{eqn:new_k_s0}\end{multline}
This new formulation overcomes the limitations highlighted in previous
sections. By appropriately axiomatizing $CanObs$ and $CanSense$
it is possible to model both total awareness of actions and total
ignorance. It also enables previously unaccounted-for circumstances,
such as only being aware of the actions of all agents within one's
field of view, or all agents on one's own team. At the same time,
it ensures that an agent's state of knowledge does not change if it
is not aware of any actions occurring. It is thus a true generalization
and improvement over previous approaches.

It is straightforward to verify that important properties of the $K$
relation discussed in \cite{scherl03sc_knowledge} are maintained
by our new formulation, including memory, default persistence of ignorance,
knowledge producing effects, and preservation of transitive, symmetric,
reflexive and euclidean relations. We omit proofs for space reasons.


\subsubsection{Awareness of Fluent Change}

In many domains it may be infeasible for an agent to be aware that
a particular action has occurred, instead only being aware that a
particular fluent has changed. For example, suppose that an agent
monitors the state of a light bulb in its environment, such that it
notices it changing from dark to light. While it knows that \emph{some}
action must have occurred, it is not aware of precisely which action
took place.

To model this, we introduce a special class of actions called \emph{change
actions}, whose sole purpose is to inform agents that some property
of the world has changed. They can never be executed and so never
appear in situation terms directly. Instead they are included in the
list of observations made by an agent, by modifying the $Observations$
predicate like so:\begin{multline}
Observations(agt,c,s)=o\equiv\\
\forall a,r\,\left[<a,r>\in o\equiv\right.\\
\left[a\in c\,\vee\, changeAction(a)\wedge SR(a,s)\neq SR(a,do(c,s))\right]\\
\wedge CanObs(agt,a,s)\\
\wedge\,\left(CanSense(agt,a,s)\wedge SR(a,s)=r\right.\\
\left.\vee\,\left.\neg CanSense(agt,a,s)\wedge r="?"\right)\right]\end{multline}
According to this definition, change actions appear in the list of
observations only when the corresponding sensing result changes in
the successor situation. By defining an appropriate $SR$ function,
and making agents aware of such actions using $CanObs$ and $CanSense$,
our formalism can neatly handle this form of environmental awareness.


\subsubsection{Communication as Sensing}

The traditional inclusion of communication actions directly in the
successor state axiom for $K$ complicates the semantics of knowledge
and makes it cumbersome to introduce new communication actions. Our
formulation provides a ready alternative - encode communication actions
are sensing actions where both sender and recipient are aware of the
outcome. Consider formulating the action $infWhether$ in this framework:\begin{multline*}
Poss(infWhether(agt_{1},agt_{2},\phi),s)\equiv\\
\shoveright{\mathbf{KWhether}(agt_{1},\phi,s)}\\
\shoveleft{SR(infWhether(agt_{2},agt_{3},\phi),s)=r\equiv}\\
\shoveright{(r="YES"\wedge\phi[s])\,\vee\,(r="NO"\wedge\neg\phi[s])}\\
\shoveleft{CanObs(agt_{1},infWhether(agt_{2},agt_{3},\phi),s)\equiv}\\
\shoveright{agt_{1}=agt_{2}\,\vee\, agt_{1}=agt_{3}}\\
\shoveleft{CanSense(agt_{1},infWhether(agt_{2},agt_{3},\phi),s)\equiv}\\
agt_{1}=agt_{2}\,\vee\, agt_{1}=agt_{3}\end{multline*}


It is straightforward to show that the intended semantics of this
communication are now enforced by the general successor state axiom
for $K$. Only sender and recipient will be aware that the communication
has occurred, and their state of knowledge will be updated to take
into account the communicated truth/falsity of $\phi$ in accordance
with $SR$. This significantly improves the modularity of communication
actions in the situation calculus.


\subsubsection{Regression}

The appearance of $\mathbf{Unobs}$ in equation \ref{eqn:new_k_ssa}
means that our new successor state axiom is not regressable using
standard techniques. To permit an effective reasoning procedure, we
appeal to the \emph{persistence condition} meta-operator. In recent
unpublished work {[}citation omitted] we introduce a new meta-operator
$\mathcal{P}_{\Sigma}(\phi,\alpha)$, taking a uniform formula $\phi$
and some action conditions $\alpha(c,s)$ , such that: \begin{multline}
\Sigma\models\mathcal{P}_{\Sigma}(\phi,\alpha)[s]\equiv\forall s''\, s\leq s''\wedge\\
\neg\exists c',s'\, s<do(c',s')\leq s''\wedge\neg\alpha(c',s')\rightarrow\phi[s'']\label{eqn:P_defn}\end{multline}


The truth of $\mathcal{P}_{\Sigma}(\phi,\alpha)$ in a situation $s$
guarantees that, as long as all actions satisfy $\alpha$, the formula
$\phi$ will remain true in all situations in the future of $s$.
It thus represents the conditions under which $\phi$ will \emph{persist}
with respect to a given class of actions. The procedure for determining
$\mathcal{P}_{\Sigma}$ replaces second-order induction with iterated
first-order reasoning, and always produces a uniform formula.

By having $\alpha$ single out unobservable actions, the persistence
condition can be used to augment existing techniques for regressing
formulae about knowledge. Assuming that the $K$ fluent appears only
in the context of a $\mathbf{Knows}$ macro, we propose the following
to replace the regression of $\mathbf{Knows}$ given by \cite{scherl03sc_knowledge}:\begin{multline*}
\mathbf{UA}(agt,c,s)\isdef\\
Legal(do(c,s))\wedge Observations(agt,c,s)=\{\}\end{multline*}
\begin{multline}
\mathcal{R}_{\Sigma}(\mathbf{Knows}(agt,\phi,do(c,s)))=\\
\left[Observations(agt,c,s)=\{\}\rightarrow\mathbf{Knows}(agt,\phi,s)\right]\\
\wedge\left[\exists o\,.\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\mathbf{Knows}(agt,\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\left.\mathcal{R}_{\Sigma}(\mathcal{P}_{\Sigma}(\phi,\mathbf{UA}(agt))[do(c',s')]),s)\right]\end{multline}


As required, this reduces reasoning about knowledge in $do(c,s)$
to reasoning about knowledge in $s$. It is also intuitively appealing:
to know that $\phi$ holds, the agent must know that in all situations
that agree with its observations, $\phi$ cannot become false without
it noticing that an action has occurred. We must also specify the
regression of $\mathbf{Knows}$ in the initial situation, as equation
\ref{eqn:new_k_s0} also quantifies over situations:\begin{multline}
\mathcal{R}_{\Sigma}(\mathbf{Knows}(agt,\phi,S_{0}))=\\
\forall s\, K_{0}(agt,s)\rightarrow\mathcal{P}_{\Sigma}(\phi,\mathbf{UA}(agt))[s]\end{multline}
This is standard modal reasoning over the $K_{0}$ relation. It remains
of course to prove that the regression operator works as required,
and we sketch the highlights of such a proof below:

\begin{theorem}

Given a theory of action $\Sigma$ with regression and persistence
operators defined relative to it, and a ground situation term $s$,
it is always the case that:
\begin{equation}
\Sigma\models\phi[s]\equiv\mathcal{R}_{\Sigma}^{*}(\phi)[S_{0}]
\end{equation}

\end{theorem}

\begin{proof}

It suffices to show that $\mathcal{R}_{\Sigma}$ preserves equivalence
for $\mathbf{Knows}$, as that it all we have modified. Employing
the successor state axiom from equation \ref{eqn:new_k_ssa}, the
definition of the $\mathbf{Knows}$ operator from equation \ref{eqn:knows_def}
can be re-written in the equivalent form: \begin{multline*}
\mathbf{Knows}(agt,\phi,do(c,s))\equiv\\
\forall s''\left[Observations(agt,c,s)=\{\}\wedge K(agt,s'',s)\right.\\
\vee\,\,\exists o\, Observations(agt,c,s)=o\wedge\\
o\neq\{\}\wedge Legal(s'')\wedge\\
\exists c',s'\, Observations(agt,c',s')=o\\
\left.\wedge K(agt,s',s)\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\right]\,\rightarrow\,\phi[s'']\end{multline*}


Through a series of equivalence-preserving transformations, this can
be re-written as: \begin{multline*}
\mathbf{Knows}(agt,\phi,do(c,s))\equiv\\
\left[Observations(agt,c,s)=\{\}\rightarrow\forall s''\, K(agt,s'',s)\rightarrow\phi[s'']\right]\\
\wedge\left[\exists o\,.\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\forall s'\, K(agt,s',s)\rightarrow\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\left.\forall s''\, Legal(s'')\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\,\rightarrow\,\phi[s'']\right]\end{multline*}


Note that both of these conjuncts now contain sub-formulae matching
the form of the $\mathbf{Knows}$ macro. It can thus be substituted
back in to give: \begin{multline*}
\mathbf{Knows}(agt,\phi,do(c,s))\equiv\\
\left[Observations(agt,c,s)=\{\}\rightarrow\mathbf{Knows}(agt,\phi,s)\right]\\
\wedge\left[\exists o\,.\, Observations(agt,c,s)=o\wedge o\neq\{\}\rightarrow\right.\\
\left.\mathbf{Knows}(agt,\mathbf{PK}(\phi,o)),s)\right]\end{multline*}


Where we have defined the abbreviation $\mathbf{PK}(\phi,o,s')$ as:
\begin{multline*}
\mathbf{PK}(\phi,o,s')\isdef\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\forall s''\, Legal(s'')\wedge\mathbf{Unobs}(agt,do(c',s'),s'')\,\rightarrow\,\phi[s'']\end{multline*}


For $\mathbf{PK}(\phi,o,s')$ to legitimately appear in the $\mathbf{Knows}$
macro it must be uniform in the situation variable $s'$. Noting that
equation \ref{eqn:unobs_defn} matches the form of equation \ref{eqn:P_defn},
and regressing to make the expression uniform in $s'$, we develop
the following equivalence, which is as required: \begin{multline*}
\mathbf{PK}(\phi,o,s')\equiv\forall c'\, Observations(agt,c',s')=o\rightarrow\\
\mathcal{R}_{\Sigma}(\mathcal{P}_{\Sigma}(\phi,Legal()\wedge Observations(agt)=\{\})[do(c',s')])\end{multline*}


For the initial situation, a straightforward transformation of equations
\ref{eqn:knows_def} and \ref{eqn:new_k_s0} gives: \begin{multline*}
\mathbf{Knows}(\phi,S_{0})\equiv\\
\forall s\, K_{0}(agt,s)\rightarrow\{\forall s'\, Legal(s')\wedge\mathbf{Unobs}(s,s')\rightarrow\phi[s']\}\end{multline*}
 Applying the persistence condition operator, this can easily be re-written
in the required form: \begin{multline*}
\mathbf{Knows}(\phi,S_{0})\equiv \forall s\, K_{0}(agt,s) \rightarrow\\
\mathcal{P}(\phi,Legal()\wedge Observations(agt)=\{\})[s]\end{multline*}


\end{proof}

We can thus reduce reasoning about knowledge to modal reasoning in
the initial situation, as in previous work. Our extension of the regression
operator thus provides a mechanical procedure for reasoning in our
improved account of knowledge, without requiring second-order induction. 


\section{Conclusions\label{sec:Conclusions}}

In this paper we have significantly increased the scope of the situation
calculus for modeling knowledge in multi-agent domains. By explicitly
reifying the observations made by each agent as the world evolves,
we have generalized the dynamics of knowledge update to allow partial
awareness of actions. We have shown that this can accommodate the
important case where agents are aware that a property of their environment
has changed, but do not know the precise actions responsible. A pleasing
offshoot of this generalization is that communication actions, previously
tied intimately to the dynamics of knowledge, can now be added or
modified with the same ease as regular actions. Despite requiring
universal quantification over future situations, we have shown that
the regression operator - the standard tool for efficient reasoning
in the situation calculus - can be adapted to our new formalism.

With our improved semantics of knowledge, the situation calculus is
well positioned for representing and reasoning about much more realistic
multi-agent domains.

\bibliographystyle{named}
\bibliography{/storage/uni/pgrad/library/references}


\end{document}

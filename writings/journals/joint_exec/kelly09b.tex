%% LyX 1.6.5 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[jair,twoside,11pt,theapa,letterpaper]{article}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand{\noun}[1]{\textsc{#1}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}

\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
 \usepackage{amsmath}
 \usepackage{amsfonts}
 \usepackage{amsthm}
 \usepackage{theapa}
 \usepackage{jair}

 % LyX will insert natbib citation commands.
 % Emulate them with the corresponding commands from theapa.
 %
 %  Author (Year)
 \newcommand{\citet}[1]{\citeA{#1}}
 %
 %  (Author, Year)
 \newcommand{\citep}[1]{\cite{#1}}
 %
 %  Author
 % \citeauthor is the same in natbib and theapa
 %
 %  Year
 \renewcommand{\citeyear}[1]{\citeyearR{#1}}
 %
 %  Author Year
 \newcommand{\citealt}[1]{\citeauthor{#1} \citeyearR{#1}}
 %
 %  Author, Year
 \newcommand{\citealp}[1]{\citeR{#1}}
 %
 %  (Year)
 \newcommand{\citeyearpar}[1]{(\citeyear{#1})}
 \newtheorem{defn}{Definition}
 \newtheorem{defnL}[defn]{Definition}
 \newtheorem{thm}{Theorem}
 \newenvironment{proofsketch}{\begin{proof}[Proof Sketch]}{\end{proof}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.

\usepackage{verbatim}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{color}
\usepackage{tikz}

\jairheading{0}{0000}{0-0}{0/0}{0/0}
\ShortHeadings{Common Knowledge, Hidden Actions, and the Frame Problem}{R. F. Kelly \& A. R. Pearce}
\firstpageno{1}

 \renewenvironment{proofsketch}{\begin{proof}[Proof Sketch]}{ For the complete proof, see Appendix \ref{sec:Complete-Proofs}. \end{proof}}

% Shortcut for formatting program snippets
\newcommand{\programinput}[1]{
  \begin{center}
  \framebox[0.85\textwidth]{
    \begin{minipage}[1\totalheight]{0.75\textwidth}{
      \footnotesize
      \verbatiminput{#1}
    }\end{minipage}
  }
  \end{center}
}

\makeatother

\begin{document}

\title{Cooperative Execution Planning in the Asynchronous Situation Calculus}


\author{\name Ryan F. Kelly \email rfk@csse.unimelb.edu.au\\
\name Adrian R. Pearce \email adrian@csse.unimelb.edu.au\\
\addr Department of Computer Science and Software Engineering\\
The University of Melbourne\\
Victoria, 3010, Australia}
\maketitle
\begin{abstract}
We investigate cooperative task execution in the situation calculus.
It is a great paper, everyone should read it.
\end{abstract}
\global\long\def\isdef{\stackrel{\mbox{\tiny def}}{=}}
\global\long\def\Dt{\mathcal{D}}
\global\long\def\Reg{\mathcal{R}}
\global\long\def\vars#1{\bar{#1}}
\global\long\def\Do{\mathbf{Do}}
\global\long\def\Lsit{\mathcal{L}_{sitcalc}}



\section{Introduction}

The situation calculus, along with the programming language Golog
that is built upon it, has proven a powerful formalism for reasoning
about dynamic worlds and specifying the behaviour of autonomous agents.
It combines a rich language for expressing domain features with techniques
for effective reasoning and a straightforward implementation using
logic programming. But while powerful, applications of the situation
calculus in multi-agent domains have typically suffered a serious
limitation.

When multi-agent domains are considered, for example as in \citep{shapiro02casl,Ferrein2005readylog,Lesperance01epi_feas_casl,delgrande01sitcalc_cleudo},
they are almost invariably assumed to be \emph{syncrhonous}; each
agent is able to determine precisely how many actions have been performed
in the world. This assumption allows the agents to reason about their
world using standard techniques developed in a single-agent setting,
such as regression \citep{reiter91frameprob}. With the notable exception
of \citep{farinelli07team_golog}, there has been little work on using
the situation calculus in rich \emph{asyncrhonous} multi-agent domains.

To address this shortcoming, we study a challenging multi-agent problem
within the framework of the situation calculus: how to enable a team
of agents to cooperatively plan and perform the joint execution of
a shared task. We extend the reasoning and planning machinery of the
situation calculus to provide a powerful approach to cooperative task
execution, even in the face of asyncrhonicity. Our approach is developed
in two phases.

First, we extend the standard semantics of Golog to incorporate true
concurrency of actions, in order to better represent the dynamics
of a multi-agent team. This new language -- dubbed \emph{MIndiGolog}
for {}``Multi-Agent IndiGolog'' -- provides a powerful mechanism
for specifying the shared tasks to be performed by a team of agents.
We develop an implementation of MIndiGolog based on the cooperative
execution algorithm of ReadyLog \citep{Ferrein2005readylog}, using
the powerful distributed logic programming capabilities of the Mozart
platform \citep{vanroy99mozart} to transparently share the planning
workload.

This first implementation, like previous work, is limited to syncrhonous
domains by the reasoning and planning machinery of the situation calculus.
The difficulty here is that the fundamental unit of reasoning, and
the output of the Golog execution planning process, is the \emph{situation}:
a complete, ordered history of all actions that are to be performed.
Working with totally-ordered sequences of actions is far from ideal
in a multi-agent setting. On one hand, each agent may have only partial
information about the actions performed so far, so they may be unable
to construct a situation term in order to reason about the current
state of the world. On the other, cooperatively executing a totally-ordered
sequence of actions requires constrant synchronisation between the
agents, which may be undersirable or even impossible in some domains.

To support richer multi-agent domains in which synchronicity cannot
be quaranteed, we develop a partially-ordered representation of the
actions to be performed by the team. Dubbed \emph{joint executions},
these structures provide a much more flexible plan representation
formalism for multi-agent domains. Unlike raw situation terms joint
executions permit branching based on results obtained at run-time;
allow independent actions to be performed without synchronsation;
and ensure that when synchronisation of actions is required, it is
actually achievable based on the local information available to each
agent.

We identify a restricted class of joint executions that can be reasoned
about using standard regression techniques, and extend our MIndiGolog
interpreter to generate joint executions instead of raw situation
terms. The end result is a powerful new approach to cooperative task
execution in the situation calculus that is suitable for use in a
much wider variety of multi-agent domains.


\subsection{Motivating Example: The Cooking Agents}

To make things more concrete, consider the following example domain
which will be used throughout the paper:
\begin{quotation}
Cathy is hosting a dinner party. A brilliant engineer but a mediocre
cook, she has built a team of robotic chefs to help her prepare the
meal, and must now program them to carry out their duties. She needs
a powerful formalism with which the agents can plan their actions,
and a programming language flexible enough to specify the major steps
in each recipe while leaving the precise details of execution for
the agents to plan amongst themselves. Moreover, she wants to specify
the tasks to be performed as a single shared program, and have the
agents automatically distribute the work amongst themselves in such
a way that they can operate independently where possible and synchronise
their actions only when necessary.
\end{quotation}
The situation calculus offers a compelling approach for this example
domain: each recipe can be represented as a Golog program, and the
agents can cooperate to plan and perform the concurrent execution
of these shared programs. However, existing Golog implementations
generate raw situation terms as the output of their planning process.
Such fully-ordered sequences of actions require constant synchronisation
if the agents are to execute them cooperatively.

If the domain is synchronous, the agents will be able to carry out
such a plan without difficulty. But in asyncrhonous domains, the plan
must only call for an action to be performed if the relevant agent
can determine, based solely on its local information, that is should
do so.


\subsection{Overview of Paper}

The paper proceeds as follows...TODO


\section{Background}


\subsection{The Multi-Agent Situation Calculus\label{sec:The-Multi-Agent-Situation}}

Our work utilises the situation calculus \citep{pirri99contributions_sitcalc}
with multiple agents \citep{shapiro98specifying_ma_systems} and concurrent
actions \citep{reiter96sc_nat_conc}. A brief overview is presented
below. Readers familiar with the situation calculus should note our
generalisation of the $Poss$ fluent to action description predicates,
and our use of the single-step variant of the regression operator.


\subsubsection{Notation\label{sub:Notation}}

The language $\Lsit$ of the situation calculus is a many-sorted language
of first-order logic with equality, augmented with a second-order
induction axiom. Its has the following sorts: \noun{Agent} terms represent
the agents operating in the world; \emph{\noun{Action}} terms are
functions denoting individual instantaneous events that can cause
the state of the world to change, with the initiating agent indicated
by their first argument; \noun{Concurrent} terms are sets of actions
that occur simultaneously; \noun{Situation} terms are histories of
the actions that have occurred in the world, with the initial situation
represented by $S_{0}$ and successive situations built using the
function $do\,:\, Concurrent\times Situation\rightarrow Situation$;
\noun{Object} terms represent any other object in the domain. \emph{Fluents}
are predicates or functions that represent properties of the world
that may change between situations; they take a situation term as
their final argument.

For concreteness, let us present some formulae from the example domain
that will be used throughout the paper. In the {}``cooking agents''
domain a group of robotic chefs inhabit a kitchen containing various
ingredients and utensils, and they must cooperate to prepare a meal.
Some example statements from this domain include {}``Joe does not
have the knife initially'', {}``Jim has the knife after he acquires
it'' and {}``It is only possible to acquire an object if nobody
else has it''. Formally:\begin{gather*}
\neg HasObject(Joe,Knife1,S_{0})\\
HasObject(Jim,Knife1,do(\{acquire(Jim,Knife1)\},S_{0}))\\
Poss(acquire(agt,obj),s)\equiv\neg\exists agt_{2}:\, HasObject(agt_{2},obj,s)\end{gather*}


In multi-agent domains it is customary to introduce a distinct sort
\noun{Agent} to explicitly represent the agents operating in the world,
and we will do so here. As seen in the example formulae above, the
first argument of each action term gives the performing agent, which
can be accessed by the function $actor(a)$.

Complex properties of the state of the world are represented using
\emph{uniform formulae}. These are basically logical combinations
of fluents referring to a common situation term.
\begin{defnL}
[{{[}{Uniform~Terms}{]}}] Let $\sigma$ be a fixed situation term,
$r$ an arbitrary rigid function symbol, $f$ an arbitrary fluent
function symbol, and $x$ a variable that is not of sort \noun{Situation}.
Then the terms uniform in $\sigma$ are the smallest set of syntactically-valid
terms satisfying:\[
\tau\,::=x\,|\, r(\vars{\tau})\,|\, f(\vars{\tau},\sigma)\]

\begin{defnL}
[{{[}{Uniform~Formulae}{]}}] Let $\sigma$ be a fixed situation
term, $R$ an arbitrary rigid predicate, $F$ an arbitrary primitive
fluent predicate, $\tau$ an arbitrary term uniform in $\sigma$,
and $x$ an arbitrary variable that is not of sort \noun{Situation}.
Then the formulae uniform in $\sigma$ are the smallest set of syntactically-valid
formulae satisfying:\[
\phi::=F(\vars{\tau},\sigma)\,|\, R(\vars{\tau})\,|\,\tau_{1}=\tau_{2}\,|\,\phi_{1}\wedge\phi_{2}\,|\,\neg\phi\,|\,\exists x:\phi\]

\end{defnL}
\end{defnL}
We will call a formula \emph{uniform} if it is uniform in some situation.
The important aspect of this definition is that the formula refers
to no situation other than $\sigma$, which appears as the final argument
of all fluents in the formula. In particular, uniform formulae cannot
quantify over situations or compare situation terms, and cannot contain
non-primitive fluents.

The meta-variable $\phi$ is used throughout to refer to an arbitrary
uniform formula. Since they represent some aspect of the state of
the world, it is frequently useful to evaluate uniform formulae at
several different situation terms. The notation $\phi[s']$ represents
a uniform formula with the particular situation $s'$ inserted into
all its fluents. We may also completely suppress the situation term
to simplify the presentation, using $\phi^{-1}$ to represent a uniform
formula with the situation argument removed from all its fluents.
For example, given: \[
\phi=HasObject(Jim,Knife1,s)\wedge HasObject(Joe,Bowl2,s)\]
 Then we have:\begin{gather*}
\phi[s']\,=\, HasObject(Jim,Knife1,s')\wedge HasObject(Joe,Bowl2,s')\\
\phi^{-1}\,=\, HasObject(Jim,Knife1)\wedge HasObject(Joe,Bowl2)\end{gather*}


Note that these are strictly meta-level operations, corresponding
to possibly quite complex sentences from the underlying logic. They
are \emph{not} terms or operators from the logic itself.


\subsubsection{Axioms\label{sec:Background:SC:Axioms}}

The dynamics of a particular domain are captured by a set of sentences
from $\Lsit$ called a \emph{basic action theory}. Queries about the
behaviour of the world are posed as logical entailment queries relative
to this theory.
\begin{defnL}
[{{[}{Basic~Action~Theory}{]}}] A basic action theory, denoted
$\Dt$, is a set of situation calculus sentences (of the specific
syntactic form outlined below) describing a particular dynamic world.
It consists of the following disjoint sets: the foundational axioms
of the situation calculus ($\Sigma$); action description axioms defining
preconditions etc for each action ($\Dt_{ad}$); successor state axioms
describing how primitive fluents change between situations ($\Dt_{ssa}$);
axioms describing the value of primitive fluents in the initial situation
($\Dt_{S_{0}}$); and axioms describing the static background facts
of the domain ($\Dt_{bg}$):\[
\Dt=\Sigma\cup\Dt_{ad}\cup\Dt_{ssa}\cup\Dt_{S_{0}}\cup\Dt_{bg}\]

\end{defnL}
These axioms must satisfy some simple consistency criteria to constitute
a valid domain description; see \citep{pirri99contributions_sitcalc}
for the details. This definition is slightly broader than the standard
definitions found in the literature \citep{levesque98sc_foundations,pirri99contributions_sitcalc,reiter01kia}
and is designed to accommodate a variety of extensions to the situation
calculus in a uniform manner. We assume an arbitrary, but fixed, basic
action theory $\Dt$.


\paragraph{Background Axioms}

The set $\Dt_{bg}$ characterises the static aspects of the domain,
and contains all axioms defining rigid predicates or functions. In
particular, it must contain a set of unique names axioms asserting
that action terms with different types or arguments are in fact different,
e.g.:\begin{gather*}
acquire(agt,obj)\neq release(agt,obj)\\
acquire(agt_{1},obj_{1})=acquire(agt_{2},obj_{2})\,\rightarrow\, agt_{1}=agt_{2}\,\wedge\, obj_{1}=obj_{2}\end{gather*}


It also contains domain closure axioms for the sorts \noun{Action,
Agent} and \noun{Object}, and defines the function $actor(a)$ to
give the agent performing an action. The background axioms are a generalisation
of the set $\Dt_{una}$ commonly found in the literature, which contains
only the unique names axioms.


\paragraph{Successor State Axioms}

The set $\Dt_{ssa}$ contains one \emph{successor state axiom} for
each primitive fluent in the domain. These axioms provide an elegant
monotonic solution to the frame problem for that fluent \citep{reiter91frameprob}
which has been instrumental to the popularity and utility of the situation
calculus. They have the following general form:\[
F(\vars x,do(a,s))\,\equiv\,\Phi_{F}(\vars x,a,s)\]
 Here $\Phi_{F}$ is uniform in $s$. While we will make no assumptions
about the internal structure of $\Phi_{F}$, it typically takes the
form shown below, which may help elucidate the purpose of these axioms:
\[
F(\vars x,do(a,s))\equiv\Phi_{F}^{+}(\vars x,a,s)\,\,\vee\,\, F(\vars x,s)\wedge\neg\Phi_{F}^{-}(\vars x,a,s)\]


Here $\Phi_{F}^{+}$ and $\Phi_{F}^{-}$ are formulae uniform in $s$,
representing the positive and negative effect axioms for that fluent.
This may be read as {}``$F$ is true after performing $a$ if $a$
made it true, or it was previously true and $a$ did not make it false''.
For example, the dynamics of the $HasObject$ fluent may be specified
using:\begin{multline*}
HasObject(agt,obj,do(a,s))\,\equiv\, a=acquire(agt,obj)\\
\vee\,\, HasObject(agt,obj,s)\wedge a\neq release(agt,obj)\end{multline*}


For functional fluents, $\Dt_{ssa}$ contains a similar axiom to specify
the value $v$ of the fluent after an action has occurred:\[
f(\vars x,do(a,s))=v\,\equiv\,\Phi_{f}(v,\vars x,a,s)\]



\paragraph{Action Description Predicates}

The set $\Dt_{ad}$ generalises the standard \emph{action precondition
axioms} \citep{pirri99contributions_sitcalc} to define fluents that
describe various aspects of the performance of an action, which we
call \emph{action description predicates}. These are the only non-primitive
fluents permitted in a basic action theory. The predicate $Poss(a,s)$
is the canonical example, indicating whether it is possible to perform
an action in a given situation. The set $\Dt_{ad}$ contains a single
axiom of the following form, defining the complete set of preconditions
for the action variable $a$, where $\Pi_{Poss}$ is a formula uniform
in $s$:\[
Poss(a,s)\,\equiv\,\Pi_{Poss}(a,s)\]


Note that this is a slight departure from the standard approach of
\citep{pirri99contributions_sitcalc}, in which the preconditions
for each action type are enumerated individually. The more restrictive
approach presented here embodies a domain-closure assumption on the
\noun{Action} sort. If there are finitely many action types then $\Pi_{Poss}$
is simply the completion of the precondition axioms for each action
type. The single-axiom form is necessary when quantifying over {}``all
possible actions'' and has been widely used in the literature \citep{vassos08progression_future_queries,savelli06sc_quantum_levels}.

In principle, any number of predicates and functions can be defined
in this way; a common example is the sensing-result function $SR(a,s)$
which we will describe in Chapter \ref{ch:observations}. The general
notion of an action description predicate allows us to treat all of
them in a uniform manner. We will use the meta-variable $\alpha$
to represent an arbitrary action description predicate, and allow
the action and situation arguments to be suppressed in a similar way
to situation-suppressed uniform formulae.

In preparation for the coming material on extensions to the situation
calculus in Section \ref{sec:Background:Extensions}, let us introduce
an action description predicate $Legal$ that identifies actions that
can be legally executed in the real world. In the basic situation
calculus, it is simply equivalent to $Poss$:\begin{gather*}
Legal(a,s)\,\equiv\, Poss(a,s)\end{gather*}


As shown by the above, it is often useful to define new action description
predicates in terms of simpler existing ones, rather than directly
in terms of the primitive fluents of the domain. As long as these
definitions are well-founded they can be expanded down to primitive
fluents when constructing the basic action theory.


\paragraph{Foundational Axioms}

The foundational axioms $\Sigma$ ensure that situations form a branching-time
account of the world state. There is a distinguished situation $S_{0}$
called the \emph{initial situation}. Situations in general form a
tree structure with the initial situation at the root and $do(a,s)$
constructing the successor situation resulting when the action $a$
is performed in situation $s$. All situations thus produced are distinct:\[
do(a_{1},s_{1})=do(a_{2},s_{2})\,\rightarrow\, a_{1}=a_{2}\,\wedge\, s_{1}=s_{2}\]


We abbreviate the performance of several successive actions by writing:\[
do([a_{1},\dots,a_{n}],s)\,\isdef\, do(a_{n},do(\dots,do(a_{1},s)))\]


There is also a second-order induction axiom asserting that all situations
must be constructed in this way, which is needed to prove statements
that universally quantify over situations \citep{Reiter93proving}:\[
\forall P:\,\left[P(S_{0})\wedge\forall s,a:\,\left(P(s)\rightarrow P(do(a,s))\right)\right]\,\rightarrow\,\forall s:\, P(s)\]


The relation $s\sqsubset s'$ indicates that $s'$ is in the future
of $s$ and is defined as follows:\begin{gather*}
\neg(s\sqsubset S_{0})\\
s\sqsubset do(a,s')\equiv s\sqsubseteq s'\end{gather*}


Here $s\sqsubseteq s'$ is the standard abbreviation for $s\sqsubset s'\vee s=s'$.
This notion of {}``in the future of'' can be extended to consider
only those futures in which all actions satisfy a particular action
description predicate. We define as a macro the relation $<_{\alpha}$
for an arbitrary action description predicate $\alpha$, with the
following definition:\[
s<_{\alpha}s'\,\isdef\, s\sqsubset s'\wedge\forall a,s'':\,\left(s\sqsubset do(a,s'')\sqsubseteq s'\rightarrow\alpha[a,s'']\right)\]


It is straightforward to demonstrate that this macro satisfies the
following properties, which are analogous to the definition of $\sqsubset$:\begin{gather*}
\neg\left(s<_{\alpha}S_{0}\right)\\
s<_{\alpha}do(a,s')\equiv s\leq_{\alpha}s'\wedge\alpha[a,s']\end{gather*}


The \emph{legal situations} are those in which every action was legal
to perform in the preceding situation. These are of fundamental importance,
as they are the only situations that could be reached in the real
world:\[
Legal(s)\isdef S_{0}\leq_{Legal}s\]



\paragraph{Initial State Axioms}

The set $\Dt_{S_{0}}$ describes the actual state of the world before
any actions are performed. It is a collection of sentences uniform
in $S_{0}$ stating what holds in the initial situation. In many domains
the initial state can be completely specified, so $\Dt_{S_{0}}$ is
often in a closed form suitable for efficient automated reasoning.

Note that, unlike \citep{levesque98sc_foundations,pirri99contributions_sitcalc,reiter01kia},
we include static facts about the domain in $\Dt_{bg}$ rather than
$\Dt_{S_{0}}$. This is entirely a cosmetic change to allow us to
talk about these static facts separately from the initial database.


\subsubsection{Reasoning and Regression}

One of the attractions of the situation calculus is the existence
of effective reasoning procedures for certain types of query. These
are generally based on syntactic manipulation of a query into a form
that is more amenable to reasoning -- for example, because it can
be proven without using some of the axioms from $\Dt$.

In the general case, answering a query about a basic action theory
$\Dt$ is a theorem-proving task in second-order logic (denoted SOL)
due to the induction axiom included in the foundational axioms. This
is clearly problematic for effective automated reasoning, but fortunately
there exist particular syntactic forms for which some of the axioms
in $\mathcal{D}$ are not required \citep{pirri99contributions_sitcalc}.
In particular, queries about the initial situation can be answered
using only first-order logic (FOL) and a limited set of axioms:\[
\mathcal{D}\models_{SOL}\phi[S_{0}]\,\,\,\,\,\mathit{\mathrm{iff}}\,\,\,\,\,\Dt_{S_{0}}\cup\Dt_{bg}\models_{FOL}\phi[S_{0}]\]


Since the axioms $\Dt_{S_{0}}\cup\Dt_{bg}$ often satisfy the closed-world
assumption, provers such as Prolog can be employed to handle this
type of query quite effectively. Effective reasoning depends on transforming
queries into more easily-handled forms such as this. \\


The principle tool for effective reasoning in the situation calculus
is the regression meta-operator $\Reg_{\Dt}$ \citep{pirri99contributions_sitcalc},
a syntactic manipulation that can transform a formula uniform in $do(c,s)$
into an equivalent formula that is uniform in $s$:\[
\Dt\,\models\,\phi[do(c,s)]\equiv\Reg_{\Dt}(\phi[do(c,s)])[s]\]


Since $\Dt$ is fixed, we drop the subscript and simply write $\Reg$
for regression. Its operation is defined by a set of \emph{regression
rules} such as those shown below:\begin{align*}
\Reg(\phi_{1}\wedge\phi_{2})\isdef & \,\,\,\Reg(\phi_{1})\wedge\Reg(\phi_{2})\\
\Reg(Poss(a,s))\isdef & \,\,\, a=A{}_{1}(\vars x_{1})\wedge\Reg(\Phi_{Poss}^{A_{1}}(\vars x_{1},s))\,\vee\,\dots\,\vee\, a=A_{n}(\vars x_{n})\wedge\Reg(\Phi_{Poss}^{A_{n}}(\vars x_{n},s))\\
\Reg(F(\vars x,do(c,s)))\isdef & \,\,\,\Phi_{F}^{+}(\vars x,c,s)\,\,\vee\,\, F(\vars x,s)\wedge\neg\Phi_{F}^{-}(\vars x,c,s)\end{align*}


Each application of the regression operator replaces action description
predicates with their definitions from $\Dt_{ad}$ and primitive fluents
with their successor state axioms from $\Dt_{ssa}$, {}``unwinding''
a single action from each situation term in the query.

Repeated applications of this operator, denoted by $\Reg^{*}$, can
transform a query about some future situation into a query about the
initial situation only, which is much easier to answer. The axioms
$\Dt_{ad}$ and $\Dt_{ssa}$ are essentially {}``compiled into''
the query. The trade-off is that the length of the regressed query
may be exponential in the length of $\phi$. While an efficiency gain
is not guaranteed, regression has proven a very effective technique
in practice \citep{levesque97golog,pirri99contributions_sitcalc}.

When dealing with situation-suppressed uniform formulae, we will use
a two-argument operator $\Reg(\phi,c)$ to indicate the regression
of $\phi$ over the action $c$. It should be read as a shorthand
for $\Reg(\phi[do(c,s)])^{-1}$ using the situation-suppression operator
from Section \ref{sub:Notation}.


\subsection{Golog}

Golog is a declarative agent programming language that is the standard
approach to specifying complex behaviours in the situation calculus
\citep{levesque97golog}. Testimony to its success are its wide range
of applications and many extensions to provide additional functionality
\citep{giacomo00congolog,giacomo99indigolog,Ferrein2005readylog}.
For simplicity, we use the general name {}``Golog'' to refer to
the standard family of languages based on this technique, including
ConGolog \citep{giacomo00congolog} and IndiGolog \citep{giacomo99indigolog}.


\subsubsection{Notation}

To program an agent using Golog one specifies a situation calculus
theory of action, and a program consisting of actions from the theory
connected by programming constructs such as if-then-else, while loops,
and nondeterministic choice. Table \ref{tbl:Background:Golog-Operators}
lists the standard operators available in various incarnations of
the language.

%
\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Operator  & Meaning\tabularnewline
\hline
\hline 
$Nil$  & The empty program\tabularnewline
\hline 
$a$  & Execute action $a$ in the world\tabularnewline
\hline 
$\phi?$  & Proceed if condition $\phi$ is true\tabularnewline
\hline 
$\delta_{1};\delta_{2}$  & Execute $\delta_{1}$followed by $\delta_{2}$\tabularnewline
\hline 
$\delta_{1}|\delta_{2}$  & Execute either $\delta_{1}$ or $\delta_{2}$\tabularnewline
\hline 
$\pi(x,\delta(x))$  & Nondet. select arguments for $\delta$\tabularnewline
\hline 
$\delta*$  & Execute $\delta$ zero or more times\tabularnewline
\hline 
$\mathbf{if}\,\phi\,\mathbf{then}\,\delta_{1}\,\mathbf{else}\,\delta_{2}$  & Exec. $\delta_{1}$ if $\phi$ holds, $\delta_{2}$ otherwise\tabularnewline
\hline 
$\mathbf{while\,}\phi\mathbf{\, do}\,\delta$  & Execute $\delta$ while $\phi$ holds\tabularnewline
\hline 
$\mathbf{proc}P(\overrightarrow{x})\delta(\overrightarrow{x})\mathbf{end}$  & Procedure definition\tabularnewline
\hline 
$\delta_{1}||\delta_{2}$  & Concurrent execution\tabularnewline
\hline 
$\delta_{1}\ll\delta_{2}$  & Prioritised concurrency\tabularnewline
\hline 
$\delta^{||}$  & Concurrent iteration\tabularnewline
\hline 
$\Sigma(\delta)$  & Plan execution offline\tabularnewline
\hline
\end{tabular}
\par\end{centering}

\caption{Operators used in Golog and its descendants \label{tbl:Background:Golog-Operators} }

\end{table}


Readers familiar with dynamic logic will recognise some of these operators,
but others are unique to first-order formalisms such as Golog. Many
Golog operators are nondeterministic and may be executed in several
different ways. It is the task of the agent to plan a deterministic
instantiation of the program, a sequence of actions that can legally
be performed in the world. Such a sequence is called a \emph{legal
execution} of the program.

To get a feel for how these operators can be used, consider some example
programs. Figure \ref{fig:Background:Golog:Washing-Dishes} shows
a simple program for Jim to wash the dishes. It makes use of the nondeterministic
{}``pick'' operator to select and clean a dish that needs washing,
and does so in a loop until no dirty dishes remain. The legal executions
of this program are sequences of $clean(Jim,d)$ actions, one for
each dirty dish in the domain, performed in any order.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t]{0.85\columnwidth}%
\begin{flalign*} \mathbf{while}\,\exists d:\, Dirty(d)\,\mathbf{do}\\
 \pi(d,\, clean(Jim,d))\\
 \mathbf{end}\end{flalign*} %
\end{minipage}} 
\par\end{centering}

\caption{A Golog program for washing the dishes\label{fig:Background:Golog:Washing-Dishes}}

\end{figure}


Figure \ref{fig:Background:Golog:MakeSalad} shows a program that
we will return to in subsequent chapters, giving instructions for
how to prepare a simple salad. The procedure $ChopTypeInto$ (not
shown) directs the specified agent to acquire an ingredient of the
specified type, chop it, and place it into the indicated bowl. The
procedure $MakeSalad$ nondeterministically selects an agent to do
this for a lettuce, a carrot, and a tomato. Note the nondeterminism
in this program: the agent assigned to handling each ingredient is
not specified ($\pi$ construct), nor is the order in which they should
be processed ($||$ construct). There is thus considerable scope for
cooperation between agents to effectively carry out this task.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t]{0.85\columnwidth}%
\begin{gather*}
\mathbf{proc}\, MakeSalad(dest)\\
\left[\pi(agt,ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\pi(agt,ChopTypeInto(agt,Carrot,dest))\,||\\
\left.\pi(agt,ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\pi(agt,\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
endTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right])\,\,\mathbf{end}\end{gather*}
 %
\end{minipage}} 
\par\end{centering}

\caption{A Golog program for making a salad\label{fig:Background:Golog:MakeSalad}}

\end{figure}



\subsubsection{Semantics}

The original semantics of Golog were defined using macro-expansion
\citep{levesque97golog}. The macro $\Do(\delta,s,s')$ was defined
to be true if program $\delta$ could be successfully executed in
situation $s$, leaving the world in situation $s'$. However, these
semantics could not support the concurrent execution of two programs
and were modified with the introduction of ConGolog \citep{giacomo00congolog}
to use two predicates $Trans(\delta,s,\delta',s')$ and $Final(\delta,s)$
which are capable of representing single steps of execution of the
program.

The predicate $Trans(\delta,s,\delta',s')$ holds when executing a
step of program $\delta$ can cause the world to move from situation
$s$ to situation $s'$, after which $\delta'$ remains to be executed.
It thus characterises single steps of computation. The predicate $Final(\delta,s)$
holds when program $\delta$ may legally terminate its execution in
situation $s$. We base our work on the semantics of IndiGolog \citep{giacomo99indigolog},
which builds on ConGolog \citep{giacomo00congolog} and is the most
feature-full of the standard Golog variants. The full semantics are
available in the references, but we present some illustrative examples
below.

The transition rule for a program consisting of a single action is
straightforward -- it transitions by performing the action, provided
it is possible in the current situation. Such a program may not terminate
its execution since the action remains to be performed:\begin{alignat*}{1}
Trans(a,s,\delta',s')\,\equiv\, & \, Poss(a,s)\wedge\delta'=Nil\wedge s'=do(a,s)\\
Final(a,s)\,\equiv\, & \,\bot\end{alignat*}


The transition rule for a test operator proceeds only if the test
is true, leaving the situation unchanged, and likewise cannot terminate
execution until the test has been satisfied:\begin{alignat*}{1}
Trans(?\phi,s,\delta',s')\,\equiv\, & \,\phi[s]\wedge\delta'=Nil\wedge s'=s\\
Final(?\phi,s)\,\equiv\, & \,\bot\end{alignat*}


Now consider a simple nondeterministic operator, the {}``choice''
construct that executes one of two alternate programs:\begin{alignat*}{1}
Trans(\delta_{1}|\delta_{2},s,\delta',s')\,\equiv\, & \, Trans(\delta_{1},s,\delta',s')\,\vee\, Trans(\delta_{2},s,\delta',s')\\
Final(\delta_{1}|\delta_{2},s)\,\equiv\, & \, Final(\delta_{1},s)\,\vee\, Final(\delta_{2},s)\end{alignat*}


It is possible for this operator to transition in two different ways
- by executing a step of execution from the first program, or a step
of execution from the second program. Slightly more complicated, but
of fundamental important in the next chapter, is the semantics of
the concurrency operator:\begin{alignat*}{1}
Trans(\delta_{1}||\delta_{2},s,\delta',s')\,\equiv\, & \,\exists\gamma:\, Trans(\delta_{1},s,\gamma,s')\,\wedge\,\delta'=(\gamma||\delta_{2})\\
 & \,\vee\,\exists\gamma:\, Trans(\delta_{2},s,\gamma,s')\,\wedge\,\delta'=(\delta_{1}||\gamma)\\
Final(\delta_{1}||\delta_{2},s)\,\equiv\, & \, Final(\delta_{1},s)\,\wedge\, Final(\delta_{2},s)\end{alignat*}


This rule specifies the concurrent-execution operator as an \emph{interleaving}
of computation steps. It states that it is possible to single-step
the concurrent execution of $\delta_{1}$ and $\delta_{2}$ by performing
either a step from $\delta_{1}$ or a step from $\delta_{2}$, with
the remainder $\gamma$ left to execute concurrently with the other
program

Clearly there are two notions of concurrency to be considered in the
situation calculus: the possibility of performing several actions
at the same instant (\emph{true concurrency}), and the possibility
of interleaving the execution of several programs (\emph{interleaved
concurrency}). \citet{pinto99tcongolog} have modified ConGolog to
incorporate sets of concurrent actions in an attempt to integrate
these two forms of concurrency. However, their semantics may call
for actions to be performed that are not possible and can also produce
unintuitive program behaviour in some cases. A key aspect of our work
in Chapter \ref{ch:mindigolog} is a robust integration of these two
notions of concurrency.\\


We have omitted many details here that are not relevant to this thesis,
such as the second-order axioms necessary to handle recursive procedure
definitions. We will denote by $\Dt_{golog}$ the standard axioms
defining $Trans$ and $Final$ \citep{giacomo00congolog,giacomo99indigolog}.


\subsubsection{Execution Planning\label{sec:Background:Golog-Exec-Planning}}

Planning an execution of a Golog program $\delta$ can be reduced
to a theorem proving task as shown in equation (\ref{eqn:Background:golog_execution}).
Here $Trans^{*}$ indicates the standard second-order definition for
the reflexive transitive closure of $Trans$.\begin{equation}
\Dt\cup\Dt_{golog}\models\exists s,\delta':\,\left[Trans^{*}(\delta,S_{0},\delta',s)\wedge Final(\delta',s)\right]\label{eqn:Background:golog_execution}\end{equation}


A constructive proof of this query would produce an instantiation
of $s$, a situation term giving a sequence of actions constituting
a legal execution of the program. These actions are then executed
one-by-one in the world. Since the program remaining after termination
is often not important, the macro $\Do$ is re-defined in terms of
$Trans$ and $Final$ to specify only the resulting situation:\[
\Do(\delta,s,s')\isdef\exists\delta':\, Trans^{*}(\delta,s,\delta',s')\wedge Final(\delta',s')\]


In the original Golog and in ConGolog this forms the entirety of the
execution planning process, as these variants require a full legal
execution to be planned before any actions are performed in the world.
This is referred to as \emph{offline execution}. The Golog execution
algorithm is presented in Algorithm \ref{alg:golog_exec}.

%
\begin{algorithm}[t]
\caption{The Golog/ConGolog Execution Algorithm for program $\delta$}


\label{alg:golog_exec} \begin{algorithmic} \STATE Find a situation
$s$ such that:\[
\Dt\cup\Dt_{golog}\models\exists s:\,\Do(\delta,S_{0},s)\]
 \FOR{each action in the resulting situation term} \STATE execute
that action \ENDFOR \end{algorithmic} 
\end{algorithm}


By contrast, IndiGolog allows agents to proceed without planning a
full terminating execution of their program, instead searching for
a legal next step $a$ in the current situation $\sigma$ such that:\[
\Dt\cup\Dt_{golog}\,\models\,\exists a,\delta':\, Trans^{*}(\delta,\sigma,\delta',do(a,\sigma))\]


This next step is then performed immediately, and the process repeats
until a terminating configuration is reached. This is referred to
as \emph{online execution}. The IndiGolog execution algorithm is presented
in Algorithm \ref{alg:indigolog_exec}.

%
\begin{algorithm}[t]
\caption{The IndiGolog Execution Algorithm for program $\delta$}


\label{alg:indigolog_exec} \begin{algorithmic} \STATE $\sigma\ \Leftarrow\ S_{0}$
\WHILE{$\Dt\cup\Dt_{golog}\not\models Final(\delta,\sigma)$} \STATE
Find an action $a$ and program $\delta'$ such that: \[
\Dt\cup\Dt_{golog}\models Trans^{*}(\delta,\sigma,\delta',do(a,\sigma))\]
 \STATE Execute the action $a$ \STATE $\sigma\ \Leftarrow\ do(a,\sigma)$
\STATE $\delta\ \Leftarrow\ \delta'$ \ENDWHILE \end{algorithmic} 
\end{algorithm}


In order to incorporate planning into this execution algorithm, IndiGolog
introduces an explicit {}``search'' operator $\Sigma(\delta)$,
which can only make a transition if the program is guaranteed to eventually
terminate successfully:\[
Trans(\Sigma(\delta),s,\delta',s')\equiv\exists s'',\delta'':\, Trans(\delta,s,\delta'',s')\wedge\mathbf{Do}(\delta'',s',s'')\wedge\delta'=\Sigma(\delta'')\]


This approach gives the programmer powerful control over the amount
of non-determinism in the program, and the amount of planning required
to find a legal execution. It also allows the programmer to avoid
planning over sensing actions, which can cause an exponential blowup
in planning complexity. Sensing actions are simply performed outside
the scope of a search operator.


\subsubsection{Multi-Agent Domains}

There are two basic approaches to the use of Golog in a multi-agent
setting. The first, and most common, is to assign each agent its own
individual Golog program. The behaviour of the overall system is then
defined as the concurrent execution of the individual agent's programs:\[
\delta=\delta_{agt1}\,||\,\delta_{agt2}\,||\,\dots\,||\,\delta_{agtN}\]


This is the approach followed by TeamGolog \citep{farinelli07team_golog}
and the Cognitive Agents Specification Language \citep{shapiro02casl},
along with earlier work in a similar vein \citep{lesperance99modeling}.
In such a setting, the agents do not necessarily cooperate or coordinate
their actions, and it is assumed that any legal execution of the combined
agent programs is a possible evolution of the entire system.

The second approach, and the one we follow here, is to have all agents
cooperate to plan and perform the joint execution of a single, shared
program. This program would typically be the concurrent execution
of several shared tasks:\[
\delta=\delta_{task1}\,||\,\delta_{task2}\,||\,\dots\,||\,\delta_{taskN}\]


This is the approach taken by the Golog variant {}``ReadyLog'' developed
by \citet{Ferrein2005readylog} to control the behaviour of a RoboCup
soccer team.

The one-program-per-agent approach can be considered a special case
of the shared-task approach, one which does not require coordination
or cooperation between team members. So while we focus exclusively
on the cooperative execution of a shared task in this and subsequent
chapters, the techniques we develop are likely to have application
in the case of multiple individual control programs as well.

While \citeauthor{Ferrein2005readylog} focus on decision-theoretic
planning rather than the rich domain extensions we consider below,
the execution algorithm they have developed for ReadyLog provides
an excellent introduction to the cooperative execution of Golog programs.
It is presented in Algorithm \ref{alg:readylog_exec}.

The aim of the ReadyLog execution algorithm is to allow agents to
coordinate their actions without the need for explicit communication.
Each agent is given their own individual copy of the shared program,
and they each independently execute the IndiGolog planning process
to determine the next step of execution. When an agent finds a next
step where the action is to be performed by the agent itself, it executes
the action immediately. When the next action is to be performed by
another agent, it waits for its teammate to execute the action before
proceeding to the next step.

%
\begin{algorithm}[t]
\caption{The ReadyLog Execution Algorithm for program $\delta$}


\label{alg:readylog_exec} \begin{algorithmic}

\STATE $\sigma\ \Leftarrow\ S_{0}$

\WHILE{$\Dt\cup\Dt_{golog}\not\models Final(\delta,s)$}

\STATE Find an action $a$ and program $\delta'$ such that:\[
\Dt\cup\Dt_{golog}\models Trans^{*}(\delta,\sigma,\delta',do(a,\sigma))\]


\IF{the action is to be performed by me}

\STATE Execute the action $a$

\ELSE

\STATE Wait for the action to be executed

\ENDIF

\STATE $\sigma\ \Leftarrow\ do(a,\sigma)$

\STATE $\delta\ \Leftarrow\ \delta'$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


Coordination arises in this setting by ensuring that the agents use
identical theorem provers (in the case of \citep{Ferrein2005readylog},
identical Prolog interpreters) to determine each program step, which
will generate candidate solutions in the same order for each agent.
So although each agent plans the program execution steps independently,
they are guaranteed to plan the \emph{same} execution steps and their
actions will therefore be coordinated without needing to communicate.

TODO: note that similar approach as been used for HTN (and find the
ref)

However, the semantics of ReadyLog remain largely single-agent and
do not address concerns such as the possibility of performing actions
concurrently, sharing the computational workload of planning, or predicting
the behaviour of team members and the environment in the face of many
concurrently-executing tasks.


\subsubsection{Extensions}

There have been a wide range of Golog extensions developed which we
will not consider in this paper. Among them have been extensions to
include decision-theoretic \citep{boutilier00dtgolog} and game-theoretic
aspects \citep{finzi03gtgolog,finzi05pogtgolog}, additional control
operators such as partially-ordered sequences of actions \citep{son00htn_golog}
and hierarchical task networks \citep{Gabaldon02htn_in_golog,Son04golog+htn+time},
synchronisation between the individual programs of a team of agents
\citep{farinelli07team_golog}, and accounting for continuous change
and event triggering \citep{grosskreutz00ccgolog}.

While we will not consider these Gologs in any detail, we do note
that each has been a relatively straightforward matter of extending
the underlying situation calculus theory and/or the semantics of the
Golog operators, and as a result there has been rich cross-pollination
between these different works. We therefore hope that our work may
in turn be combined with some of these extensions to provide an even
richer formalism.


\subsection{Mozart/Oz\label{sec:Background:Mozart/Oz}}

One of the main advantages of the situation calculus and Golog are
their straightforward implementation as a logic program. As the dominant
implementation of the logic programming paradigm, Prolog is typically
used for such implementations. In this thesis we use Mozart, a multi-paradigm
programming system with some unique features that are particularly
suited to our work.

The Mozart system \citep{vanroy99mozart} is an implementation of
the Oz programming language \citep{vanRoyHaridi04ctm} with strong
support for logic programming and distributed computing. While a full
explanation of its features is well outside the scope of this thesis,
we provide a short introduction to the subset of its features we will
be using -- in particular, doing Prolog-style logic programming in
Oz. Familiarity with logic programming in the style of Prolog is assumed.

Terms, variables and unification in Oz work similarly to Prolog, although
arguments in compound terms are separated by whitespace rather than
a comma. Predicates are implemented as ordinary procedures, so all
clauses for a predicate must be contained in a single procedure. Figure
\ref{fig:Background:Naive-List-Reverse} shows an Oz implementation
of a classic Prolog example predicate, naive list reverse.

Some things to note about this example include:
\begin{itemize}
\item The syntax for procedure definition is $\mathbf{proc}\,\{Name\, Arg\,\dots\,\}\,\, Body\,\,\mathbf{end}$ 
\item The syntax for procedure calls is $\{Name\, Arg\,\dots\,\}$ 
\item The $\mathbf{case}$ statement is used to pattern-match the contents
of a variable 
\item Local variables must be explicitly introduced using the keyword $\mathbf{in}$ 
\item Mozart separates functionality into modules, such as $List$ 
\end{itemize}
%
\begin{figure}[t]
\programinput{listings/oz-examples/Reverse.oz}

\caption{Naive List Reverse implemented in Mozart/Oz\label{fig:Background:Naive-List-Reverse}}

\end{figure}


Procedures in Oz are deterministic by default, and there is no default
search strategy for exploring different alternatives. Instead, Oz
provides independent facilities for creating choicepoints and for
exploring procedures that contain choicepoints. The result is a much
more flexible, although sometimes syntactically more cumbersome, approach
to logic programming \citep{lpinoz99}.

The creation of choice points is explicit in Oz, and performed using
the $\mathbf{choice}$ keyword. To demonstrate, consider another classic
Prolog example: the nondeterministic list member predicate shown in
Figure \ref{fig:Background:Nondet-Member}. In the case of the empty
list, $Member$ simply fails. For a non-empty list, $Member$ explicitly
creates a \emph{choice point} with two options -- either bind $E$
to the head of the list, or bind $E$ to a member of the tail of the
list.

%
\begin{figure}[t]
\programinput{listings/oz-examples/Member.oz}

\caption{Nondeterministic List Member implemented in Mozart/Oz\label{fig:Background:Nondet-Member}}

\end{figure}


It is at this point that the use of Mozart for logic programming differs
most from Prolog. If the $Member$ procedure is invoked directly,
it will suspend its execution when the $\mathbf{choice}$ statement
is reached. To resolve the nondeterminism, one must execute the procedure
inside an explicit \emph{search} \emph{object}. These objects are
responsible for exploring the various choicepoints until a non-failing
computation is achieved. They operate by executing the procedure in
a separate \emph{computation space} through which the state of the
underlying computation can be managed \citep{schulte00constraint_services}.

As a demonstration, Figure \ref{fig:Background:All-Pairs} uses the
$Member$ procedure to define a procedure $Pairs$, which nondeterministically
selects a pair of elements from a pair of lists. The procedure $AllPairs$
then uses the builtin $Search.base.all$ object to find all solutions
from this procedure, returning a list of all possible pairs from the
two lists. By encapsulating the calls to nondeterministic procedures
inside a search object, $AllPairs$ will not expose any choicepoints
to code that calls it.

%
\begin{figure}[t]
\programinput{listings/oz-examples/Pairs.oz}

\caption{Finding all pairs in Mozart/Oz\label{fig:Background:All-Pairs}}

\end{figure}


Also of note in Figure \ref{fig:Background:All-Pairs} is the use
of a \emph{closure} over the procedure $Pair$ to create the one-argument
procedure $FindP$. Search objects work with a one-argument procedure,
which is expected to bind its argument to a result. The dollar symbol
is used to translate a statement (in this case the $\mathbf{proc}$
definition) into an expression. The value that would be bound to the
dollar symbol by the statement becomes the return value of the expression,
so $FindP=proc\,\{\$\, P\}$ is equivalent to $proc\,\{FindP\, P\}$.

The power of this decoupled approach to nondeterminism and search
becomes apparent when defining new search strategies, which can then
be used to evaluate any procedure. For example, it is straightforward
to implement breadth-first or iterative-deepening strategies to replace
the standard depth-first traversal of the $Search.base$ object \citep{schulte00constraint_services}.

Coupled with Mozart's strong support for distributed computing, these
programmable search strategies offer a unique opportunity -- it becomes
possible to implement a parallel search object which can automatically
distribute work between several networked machines. Moreover, this
parallel search can be applied without modification to any nondeterministic
procedure. Mozart comes with a built-in $ParallelSearch$ object,
which is described in detail in \citep{schulte00oz_parallel} and
which is our main motivation for the use of Oz in this thesis.

To demonstrate the power of the approach, consider Figure \ref{fig:Background:Parallel-All-Pairs},
which describes a parallel-search version of the $AllPairs$ procedure.
In this instance we define $FindP$ as a \emph{functor}, an Oz abstraction
for code that is portable between machines. This functor imports the
module $MyList$ containing the procedures we defined earlier, and
exports a one-argument procedure $Script$ which will be executed
by the parallel search object. The parallel search object $Seacher$
launches one instance of Mozart on the machine {}``mango'' and two
instances on the machine {}``rambutan'', then is asked to enumerate
all solutions for $FindP$.

%
\begin{figure}[!t]
\programinput{listings/oz-examples/PPairs.oz}

\caption{Finding all pairs in parallel in Mozart/Oz\label{fig:Background:Parallel-All-Pairs}}

\end{figure}


In Chapter \ref{ch:mindigolog} we will use this parallel search object
to automatically share the workload of planning a Golog execution
amongst a team of cooperating agents.

As a multi-paradigm programming language with significant research
history, there is much more to Oz than we have described here. However,
these brief examples should be sufficient for a reader well-versed
in Prolog to understand the Oz code used throughout this thesis. For
more information and further examples, consult the general Oz tutorial
\citep{haridi99oz_tutorial} or the specialised tutorial on logic
programming in Oz \citep{lpinoz99}, which are both available online.


\section{MIndiGolog}

In tihs section we develop a Golog variant specifically designed for
cooperative execution in multi-agent domains. As we will demonstrate,
the existing features of the situation calculus go a long way towards
achieving this goal, but are ultimately limited to execution in synchronous
domains.

Key to our approach is a robust integration of true concurrency of
actions with the standard interleaved concurrency semantics of ConGolog/IndiGolog,
giving a flexible account of concurrent execution in multi-agent domains.
We name the resulting Golog variant {}``MIndiGolog'' for {}``Multi-Agent
IndiGolog''.

We also develop an innovative implementation of our language using
the distributed logic programming features of the Mozart platform.
Utilising the parallel search facility as described in Section \ref{sec:Background:Mozart/Oz},
the agents can transparently share the workload of planning a program
execution. The ability to utilise off-the-shelf techniques such as
parallel search highlights a significant advantage of building our
system on the situation calculus: it has a straightforward encoding
as a logic program.

Concluding the section is a discussion of the limitations of this
first incarnation of MIndiGolog, which derive from the effective reasoning
procedures of the situation calculus. Specifically, it can only operate
in fully-observable, synchronous domains. Subsequent chapters of this
thesis develop new extensions to the situation calculus that work
towards overcoming this limitation.


\subsection{Motivation\label{sec:MIndiGolog:Motivation}}

Recall the {}``cooking agents'' example domain -- several agents
inhabit a kitchen along with various ingredients and utensils, and
they must cooperate to prepare a meal. A full axiomatisation of this
domain is given in Appendix \ref{ch:cookingagents}, but the precise
details are not important here.

Specifying tasks for the cooking agents requires an interesting combination
of features. There is much procedural knowledge about recipes that
should be encoded as precisely as possible, while at the same time
there are a lot of details of precisely who performs which steps,
or precisely when they are performed, that should not be explicitly
specified by the programmer.

The Golog family of languages provide a compelling formalism for specifying
tasks in this domain, as the controlled nondeterminism they provide
can be used to elide certain details from the program while keeping
its procedural nature intact. Consider how we might specify the task
of making a simple salad, shown in Figure \ref{fig:MIndiGolog:MakeSalad}.
Using the high-level nondeterministic operators of Golog, this program
says, in essence, {}``somebody chop a lettuce, somebody chop a carrot,
and somebody chop a tomato. Then, somebody mix them together''.

%
\begin{figure}[!t]
\begin{centering}
\framebox{%
\parbox[t]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, MakeSalad(dest)\\
\left[\pi(agt,ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\pi(agt,ChopTypeInto(agt,Carrot,dest))\,||\\
\left.\pi(agt,ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\pi(agt,\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
endTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right])\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for making a salad\label{fig:MIndiGolog:MakeSalad}}

\end{figure}


%
\begin{figure}[!t]
\begin{centering}
\framebox{%
\parbox[t]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, ChopTypeInto(agt,type,dest)\\
\left[\pi(board,\, IsType(board,Board)?\,;\right.\\
\pi(obj,\, IsType(obj,type)?\,;\,\,\,\\
acquire(agt,board)\,;\\
acquire(agt,obj)\,;\\
placeIn(agt,obj,board)\,;\\
beginTask(agt,chop(board))\,;\\
endTask(agt,chop(board))\,;\\
acquire(agt,dest)\,;\\
transfer(agt,board,dest)\,;\\
release(agt,board)\,;\\
\left.\, release(agt,dest)))\right]\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for chopping an ingredient\label{fig:MIndiGolog:ChopTypeInto}}

\end{figure}


Note that the explicit concurrency operators allow the three ingredients
to be chopped independently, while the nondeterministic {}``pick''
operators allow any available agent to perform each sub-task. Expanding
on this example, the procedure $ChopTypeInto$ could be specified
as shown in Figure \ref{fig:MIndiGolog:ChopTypeInto}. Here the agent
must select and acquire an object of the specified type, as well as
an available chopping board. He then places the object on the board,
chops it, and transfers it to the destination container.

Notice that the programs do no specify which agent is to perform which
task -- in fact they make no assertions at all about the particular
agents operating in the world. A library of procedures such as this
can be combined very flexibly to specify the behaviour of the cooking
agents, and the resulting program could be given to any team of agents
for execution. For example, the agents can easily prepare several
dishes concurrently:

\framebox{%
\parbox[t]{0.85\columnwidth}{%
\[
MakeSalad()\,||\, MakePasta()\,||\, MakeCake()\]
 %
}}\\


A legal execution of these programs must select appropriate ingredients
and utensils, and ensure that are acquired in an appropriate order,
so that it can proceed to completion without the agent's actions interfering
with each other or coming into conflict over shared resources. Following
the ReadyLog execution algorithm, each agent plans to avoid such conflict
by virtue of finding a legal execution.

In short, the situation calculus and Golog provide an extremely powerful
formalism for specifying cooperative agent behaviour in domains such
as this.

However, executing these kinds of program using a standard Golog variant
is far from ideal in a multi-agent setting. To illustrate this we
have executed the $MakeSalad$ program using the standard semantics
of IndiGolog \citep{giacomo99indigolog}, augmented with an explicit
temporal component in the style of \citep{Reiter98seq_temp_golog}.
The resulting execution is shown in Figure \ref{fig:MIndiGolog:MakeSalad-in-IndiGolog}.

%
\begin{figure}
\framebox{%
\parbox[t]{0.95\columnwidth}{%
\begin{center}
{\footnotesize \verbatiminput{listings/mindigolog/output-MakeSalad-I.txt}} 
\par\end{center}%
}}

\caption{Execution of $MakeSalad$ program using IndiGolog semantics\label{fig:MIndiGolog:MakeSalad-in-IndiGolog}}

\end{figure}


In this domain there are three agents $Joe$, $Jon$ and $Jim$. While
the resulting execution is legal, it is suboptimal in several ways.
The most obvious problem is that it does not take advantage of the
concurrency inherent in a team of agents. Only a single agent acts
at any one time, while the other agents are idle. Ideally the execution
planner should exploit \emph{true concurrency} where possible, by
calling for multiple actions to be performed at each timestep.

The remainder of this chapter is dedicated to developing a robustly
multi-agent Golog semantics to overcome these issues, as well as an
implementation that can highlight the benefits of this approach.


\subsection{Semantics of MIndiGolog\label{sec:MIndiGolog:Semantics}}

To take advantage of true concurrency, we must first allow sets of
concurrent actions to appear in a MIndiGolog execution. The transition
rule for a single action then becomes:\[
Trans(a,s,\delta,s')\,\equiv\, Legal(a,s)\wedge\delta=nil\wedge s'=do(\{a\},s)\]


However, this is clearly not enough to truly exploit the potential
for concurrency in a multi-agent team. As noted by \citet{pinto99tcongolog},
the concurrency operator should be modified to accept a concurrent
transition from both programs. The concurrency semantics they propose
for their variant {}``TConGolog'' are shown below:\begin{multline*}
Trans(\delta_{1}||\delta_{2},s,\delta',s')\equiv\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\:\,\,\,\,\,\,\,\,\,\shoveright{\exists\gamma:\, Trans(\delta_{1},s,\gamma,s')\wedge\delta'=(\gamma||\delta_{2})}\\
\shoveright{\vee\exists\gamma:\, Trans(\delta_{2},s,\gamma,s')\wedge\delta'=(\delta_{1}||\gamma)}\\
\shoveright{\vee\exists c_{1},c_{2},\gamma_{1},\gamma_{2}:\, Trans(\delta_{1},s,\gamma_{1},do(c_{1},s))}\\
\wedge Trans(\delta_{2},s,\gamma_{2},do(c_{2},s))\wedge\delta'=(\gamma_{1}||\gamma_{2})\wedge s'=do(c_{1}\cup c_{2},s)\end{multline*}


The first two lines are the standard rules for the concurrency operator,
encoding the interleaving of steps from programs $\delta_{1}$ and
$\delta_{2}$. The remaining lines permit the concurrent execution
of a transition from both programs. While this modification will take
advantage of the true concurrency of actions present in multi-agent
domains, it introduces several complications that \citep{pinto99tcongolog}
does not address.

First, precondition interaction means that $c_{1}\cup c_{2}$ may
not be possible even if the individual actions are. The transition
clause must ensure that the combination of the two sets of actions
is possible. Another issue arises when two programs can legitimately
be transitioned by executing the same action. Consider the following
programs which add ingredients to a bowl:\begin{gather*}
\delta_{1}=placeIn(Jim,Flour,Bowl)\,;\, placeIn(Jim,Sugar,Bowl)\\
\delta_{2}=placeIn(Jim,Flour,Bowl)\,;\, placeIn(Jim,Egg,Bowl)\end{gather*}
 Executing $\delta_{1}||\delta_{2}$ should result in the bowl containing
two units of flour, one unit of sugar and an egg. However, an individual
transition for both programs is $c_{1}=c_{2}=\{placeIn(Jim,Flour,Bowl)\}$.
Naively executing $c_{1}\cup c_{2}$ to transition both programs would
result in only one unit of flour being added.

Alternately, consider two programs waiting for a timer to ring:\begin{gather*}
\delta_{1}=ringTimer\,;\, acquire(Jim,Bowl)\\
\delta_{2}=ringTimer\,;\, acquire(Joe,Board)\end{gather*}
 Both programs should be allowed to proceed using the same $ringTimer$
occurrence, because it is an environmental effect rather than a purposeful
agent-initiated action.

In simple cases like these, it is easy for the programmer to see the
potential for such undesirable interaction and adjust their programs
accordingly. But in more complex cases with liberal use of nondeterminism,
it may not be possible to predict what actions can potentially be
executed concurrently. To avoid unintuitive (and potentially dangerous)
behaviour, concurrent execution must not be allowed to transition
both programs using the same \emph{agent-initiated} action. Exogenous
actions can safely transition two concurrent programs.

Taking these factors into account, we develop the improved transition
rule for concurrency in equation (\ref{eqn:trans_conc_new}). The
first two lines are the original interleaved concurrency clause from
ConGolog, while the remainder characterises the above considerations
to take advantage of true concurrency.\begin{multline}
Trans(\delta_{1}||\delta_{2},s,\delta',s')\equiv\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\shoveright{\exists\gamma:\, Trans(\delta_{1},s,\gamma,s')\wedge\delta'=(\gamma||\delta_{2})}\\
\shoveright{\vee\exists\gamma:\, Trans(\delta_{2},s,\gamma,s')\wedge\delta'=(\delta_{1}||\gamma)}\\
\shoveright{\vee\exists c_{1},c_{2},\gamma_{1},\gamma_{2},t:\, Trans(\delta_{1},s,\gamma_{1},do(c_{1}\#t,s))\wedge Trans(\delta_{2},s,\gamma_{2},do(c_{2}\#t,s))}\\
\shoveright{\wedge Legal((c_{1}\cup c_{2})\#t,s)\wedge\forall a:\left[a\in c_{1}\wedge a\in c_{2}\rightarrow Natural(a)\right]}\\
\wedge\delta'=(\gamma_{1}||\gamma_{2})\wedge s'=do((c_{1}\cup c_{2})\#t,s)\label{eqn:trans_conc_new}\end{multline}


There are two other Golog operators that relate to concurrency: the
prioritised concurrency operator $\delta_{1}\ll\delta_{2}$, and the
concurrent iteration operator $\delta^{||}$. MIndiGolog leaves both
of these operators unmodified. For the concurrent iteration operator
this is clearly the right thing to do, since its standard semantics
are defined in terms of the base concurrency operator and will automatically
inherit our new ability to take advantage of true concurrency.

For the prioritised concurrency operator, we note that it is mainly
used to implement interrupt-handling by blocking the execution of
the higher-priority program until a test condition is satisfied, at
which point the lower-priority program is blocked until the interrupt
handler is complete. It makes no sense to allow concurrent execution
of both programs in this case, which would destroy these blocking
semantics.

Let us denote by $\Dt_{mgolog}$ the standard Golog axioms $\Dt_{golog}$,
modified according to equations \eqref{eqn:trans_conc_new}, \eqref{eqn:trans_prim_new}
and \eqref{eqn:trans_cond_new}. All legal executions of a MIndiGolog
program derived from such a theory of action produce legal situations.
\begin{thm}
The semantics of MIndiGolog entail: \[
\Dt\cup\Dt_{mgolog}\models\forall s',\delta,\delta':\, Trans^{*}(\delta,S_{0},\delta',s')\rightarrow Legal(s')\]
 Thus, all legal executions of a MIndiGolog program produce legal
situations. \end{thm}
\begin{proofsketch}
By induction on situation terms. For the base case, $S_{0}$ is always
legal by definition. Lemma \ref{lem:MIndiGolog:trans_legal} immediately
provides legality for the inductive case by the transitivity of $Trans^{*}$. 
\end{proofsketch}
The MIndiGolog semantics are thus a powerful but robust extension
to the standard semantics of the Golog language family. Our integration
of concurrent actions allows the language to more accurately reflect
the concurrency present in multi-agent teams while ensuring actions
are performed in a definite order if they are not legal to perform
concurrently.


\subsection{Implementation\label{sec:MIndiGolog:Implementation}}

With these new semantics in place, it is now possible to build a multi-agent
execution planning system utilising MIndiGolog to specify the tasks
to be performed. We have followed the style of \citep{giacomo99indigolog,giacomo00congolog}
to build an interpreter for our language in Oz on the Mozart programming
platform \citep{vanroy03mozart_logic}. We summarise our implementation
below; details on obtaining the full source code are available in
Appendix \ref{ch:implementation}.

Programs and actions are represented in Oz as record terms in a similar
way to Prolog data terms. For example, the program:\[
\pi(agt,\left[acquire(agt,Bowl1);acquire(agt,Lettuce1)\right])\]


is represented as follows:

\programinput{listings/mindigolog/goloz-ex-prog.oz}

Since {}``do'' is a reserved keyword in Oz, we represent situation
terms as records of the form $res(C\,\, T\,\, S)$. $Trans$ and $Final$
have a straightforward encoding as Oz procedures, using the \textbf{case}
statement to encode each individual clause using pattern matching,
and the \textbf{choice} statement to explicitly introduce choice points.
The following are a selection of the operators as they appear in our
implementation:

\programinput{listings/mindigolog/goloz-trans.oz}

\programinput{listings/mindigolog/goloz-final.oz}

The calls to $Sitcalc.holds$ etc here perform standard regression-based
theorem proving in the style of Prolog-based Golog implementations
\citep{levesque97golog,giacomo00congolog}. Of particular interest
is our implementation of the concurrency operator, reflecting the
new semantics from equation \eqref{eqn:trans_conc_new}. First, we
introduce a procedure \emph{Step} which calculates a series of transitions
to produce a single next action:

\programinput{listings/mindigolog/goloz-step.oz}

Then we can encode the semantics of concurrency using the following
case:

\programinput{listings/mindigolog/goloz-trans-conc.oz}

The first option presented by the choicepoint is the case for true
concurrency of actions, while the two other choices represent interleaved
concurrency. By putting the true-concurrency case first, a depth-first
search will try to find a concurrent step before looking for a step
from only one of the programs. Using $Step$ instead of $Trans$ allows
this search to consume empty transitions of each program, such as
test conditions, to find a valid concurrent step. This is valid since
the empty transitions consumed by $Step$ are also generated by the
interleaved concurrency cases.

These simple implementation details are enough to ensure a high degree
of concurrency in the generated executions, as we shall demonstrate
in the next section.

A procedure $Do(\delta,s,s')\equiv Trans^{*}(\delta,s,\delta',s')\wedge Final(\delta',s')$
is defined that determines a complete legal execution $Sp$ for a
given program $D$. As discussed in Section \ref{sec:Background:Golog-Exec-Planning},
this is used to define the semantics of the search operator.

\programinput{listings/mindigolog/goloz-do.oz}

Our implementation of the search operator avoids recalculating the
complete legal execution by translating it into a direct list of actions
to be performed. More sophisticated implementations can further instrument
this case to perform failure detection and re-planning \citep{Lesperance00improved_indigolog},
but we do not include these techniques in our work.

\programinput{listings/mindigolog/goloz-trans-search1.oz}

Using this implementation, a team of agents can plan and perform the
execution of a shared MIndiGolog program by following the ReadyLog
execution algorithm from Algorithm \ref{alg:readylog_exec}. First
we define procedures to detect program termination and to plan a next
program step, which use built-in search object to resolve choicepoints:

\programinput{listings/mindigolog/goloz-control.oz}

The main control loop is then implemented in the procedure $Run$
as shown below. As in ReadyLog, each agent individually executes this
control loop. When the next step contains an action that is to be
performed be the agent, they execute it at the indicated time. Otherwise,
they wait for the actions to be executed by their teammates before
proceeding to the next iteration.

\programinput{listings/mindigolog/goloz-run.oz}

%
\begin{figure}[!b]
\framebox{%
\parbox[t]{0.95\columnwidth}{%
\begin{center}
{\footnotesize \verbatiminput{listings/mindigolog/output-MakeSalad-M.txt}} 
\par\end{center}%
}}

\caption{Execution of $MakeSalad$ program using MIndiGolog semantics\label{fig:MIndiGolog:MakeSalad-in-MIndiGolog}}

\end{figure}


The effect of our new semantics can be seen in Figure \ref{fig:MIndiGolog:MakeSalad-in-MIndiGolog}.
This shows the execution generated by our implementation for the $MakeSalad$
program from Figure \ref{fig:MIndiGolog:MakeSalad}, using the new
semantics of MIndiGolog in a domain with three agents. Note the execution
of several actions at each timestep, demonstrating the integration
of true concurrency into the language. Since there are three agents
but only two chopping boards, in this execution $Jon$ must wait until
a board becomes available at time 12 before he can begin processing
his ingredient. This execution is clearly more suited to a multi-agent
domain than that produced by the standard IndiGolog semantics.


\subsection{Distributed Execution Planning\label{sec:MIndiGolog:Distributed-Planning}}

One powerful feature of Mozart is the ability to use several networked
computers to search for solutions to a logic program in parallel.
Since the task of planning a MIndiGolog execution is encoded as a
logic program, this immediately allows a team of agents to distribute
the execution planning workload.

There are non-trivial computational and communication overheads involved
in such a search, so it must be used judiciously. We argue that parts
of the program appearing outside the scope of a search operator are
intended for on-line execution, and so will tend to require little
deliberation by the agent. By contrast, program components enclosed
in a search operator are intended to require significant planning
to generate a legal execution. We therefore modify the search operator
to perform distributed execution planning, but leave the rest of the
code intact.

To coordinate the parallel search, we designate one agent to be the
\emph{team leader}, who will be responsible for managing the search
process; the choice of agent is arbitrary and is simply a coordination
device. The code below shows our implementation of the search operator
using parallel search. If the executing agent is the team leader,
it executes the procedure $ParallelDo$ and, when a plan is found,
sends the details to the other members of the team. Subordinate team
members simply wait for the plan to be received before continuing.

\programinput{listings/mindigolog/goloz-trans-search2.oz}

Note that this modification is completely transparent to the rest
of the implementation. While some details of sending messages are
not shown, the core implementation of the ParallelDo procedure is
shown below.

\programinput{listings/mindigolog/goloz-paralleldo.oz}

This code packages up the task to be performed as a \emph{functor},
a portable piece of code that can be shared across the network by
all team members. Input terms are serialised to a textual representation
since variables cannot be exported in functor definitions. It is then
a simple matter of creating a new $ParallelSearch$ object that spans
all team members, and asking it for a solution to the functor. When
this code is executed by the team leader, it will utilise the computational
resources of all team members to plan the execution of the enclosed
MIndiGolog program.

As a brief demonstration of the advantages provided by this technique,
consider the suggestively-named program {}``HardToPlan'' shown in
Figure \ref{fig:MIndiGolog:HardToPlan}. This program asks the agents
to nondeterministically select and acquire objects of a variety of
types, and then tests whether certain specific objects have been acquired.
It has been constructed so that a single bad choice in the early stages
of execution planning - for example, having $Joe$ acquire $Carrot1$
instead of $Carrot3$ - can invalidate all choices subsequently made.
Planning a legal execution of this program thus requires a significant
amount of backtracking and should benefit greatly from parallelisation.

%
\begin{figure}[!t]
\begin{centering}
\framebox{%
\parbox[t]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, HardToPlan()\\
\left[AcquireType(Joe,Carrot)\,;\right.\\
AcquireType(Jon,Sugar)\,;\\
AcquireType(Jim,Lettuce)\,;\\
AcquireType(Joe,Flour)\,;\\
AcquireType(Jon,Flour)\,;\\
HasObject(Jon,Carrot3)?\,;\\
HasObject(Joe,Flour5)?\,;\\
\left.\, HasObject(Jon,Sugar4)?\right]\,\,\mathbf{end}\\
\\\mathbf{proc}\, AcquireType(Agt,Type)\\
\pi(obj,\, IsType(obj,Type)?\,;\\
\left.\, acquire(Agt,obj)))\right]\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for which execution planning is difficult\label{fig:MIndiGolog:HardToPlan}}

\end{figure}


We used our MIndiGolog implementation to execute $\Sigma(HardToPlan)$
in two different ways: using parallel search as described above, and
having the team leader search for a legal execution on its own. The
program for team leader $Jon$ was executed on an AMD Althon 64 3000+,
while the subordinate team members $Jim$ and $Joe$ each executed
on one core an Intel Core2 Duo 1.8 GHz. Three test runs were performed
for both parallel and individual search. The times required to find
a legal execution are shown in Table \ref{tab:MIndiGolog:Execution-planning-times}
along with the speedup factor achieved by using parallel search.

%
\begin{table}[!t]
\begin{centering}
\begin{tabular}{|c|c|c|c|}
\hline 
 & \textbf{Individual Search}  & \textbf{Parallel Search}  & \textbf{Ratio Indiv/Para}\tabularnewline
\hline
\hline 
\textbf{Run 1}  & 29.30  & 13.67  & 2.14\tabularnewline
\hline 
\textbf{Run 2}  & 29.21  & 11.25  & 2.59\tabularnewline
\hline 
\textbf{Run 3}  & 29.08  & 11.61  & 2.50\tabularnewline
\hline
\hline 
\textbf{Average}  & 29.19  & 12.17  & 2.39\tabularnewline
\hline
\end{tabular}
\par\end{centering}

\caption{Execution planning times for $HardToPlan$, in seconds\label{tab:MIndiGolog:Execution-planning-times}}

\end{table}


These results shown an impressive decrease in execution planning time
with the use of parallel search - close to a factor of three speedup
using the computational resources of three agents. Of course, on programs
where execution planning is less difficult this advantage will be
reduced, but on difficult problems it can clearly provide a significant
benefit.

The ability to implement this distributed execution planning with
so little code, and in a way that is completely transparent to the
rest of the implementation, highlights one of the major advantages
of using the situation calculus and Golog -- the ability to encode
both the domain and the execution planning problem as a simple logic
program, which is then amenable to off-the-shelf techniques for distributed
logic programming.


\subsection{Discussion\label{sec:MIndiGolog:Discussion}}

Our work in this section has produced a Golog variant specifically
designed for task specification in multi-agent domains, by combining
true concurrency of actions with the interleaved concurrency semantics
of ConGolog. As we have shown by comparison to the standard IndiGolog
semantics, it defines legal executions of Golog programs that are
much more suitable for cooperative execution by a multi-agent team.

We have also demonstrated an innovative implementation of MIndiGolog
using Mozart/Oz instead of Prolog. Since the situation calculus and
Golog have a straightforward encoding as a logic program, the off-the-shelf
techniques for distributed logic programming provided by the Mozart
platform can be used to transparently share the execution planning
workload between team members.

The approach presented in this section is by no means a complete account
of cooperative execution in multi-agent domains. It pre-supposes the
existence of a fixed team of agents and their mutual commitment to
executing a pre-specified shared task. Our implementation therefore
focuses entirely on planning and performing the execution of such
a task, without explicit mental attitudes such as cooperation or commitment.
However, this technique could easily form a component of a larger
multi-agent system based on the situation calculus, such as \citep{shapiro02casl,lesperance05ecasl}.

The purpose of this section is not to propose the MIndiGolog approach
as the ultimate solution for programming cooperative behaviour. Rather,
it serves to highlight the \emph{potential} of the situation calculus
and Golog for both modelling and implementing rich multi-agent systems.
Unfortunately, this potential has traditionally been limited by some
restrictions on the reasoning and planning machinery of the situation
calculus, and our implementation of MIndiGolog has so far inherited
those limitations.

Most fundamentally, the output of our execution planning process assumes
that the domain is synchronous and that all actions are publicly observable.
This assumption is necessary to allow reasoning using standard regression
techniques, as it means the agents do not need to consider arbitrarily-long
sequences of hidden actions. It also means that simple situation terms
suffice as the output of the planning process; agents have all the
information they need to coordinate the performance of concurrent
actions, and to ensure that actions are performed in the correct order.
For example, the execution in Figure \ref{fig:MIndiGolog:MakeSalad-in-MIndiGolog}
calls for $Jim$ to release $Bowl1$ and then for $Joe$ to acquire
it in the next timestep, implicitly assuming that the two agents are
able to coordinate and synchronise these actions.

Consider, by contrast, an asynchronous domain in which some actions
are not public. If $Joe$ is not be able to observe the occurrence
of $Jim$ releasing the bowl, he would not know when to proceed with
acquiring it and execution of the plan would fail. To be sure that
the plans produced by our system can be executed in the real world,
we must assume that the agents execute their actions in lock-step
and always know the current state of execution -- in other words,
that there is some form of constant synchronisation between the agents.

Another limitation is that MIndiGolog does only \emph{linear} planning,
and has no support for sensing actions. In the single-agent case the
execution of Golog programs that include sensing actions is well understood
\citep{giacomo99indigolog,lakemeyer99golog_cats}, but there is no
straightforward way to adapt these techniques to the implicit coordination
scheme used by MIndiGolog. The difficulty arises from the execution
algorithm's crucial assumption that all agents have access to the
same information. Introducing sensing actions to MIndiGolog will require
more explicit reasoning about coordination based on the local information
available to each agent.

Existing situation calculus techniques for reasoning about the local
perspective of each agent are based on explicit notions of knowledge,
as described in Section \ref{sec:Background:Epistemic}. But even
these formalisms are limited to synchronous domains, requiring agents
to always know how many actions have occurred so that standard regression
techniques can be applied. The situation calculus currently offers
no tools to extend the MIndiGolog approach into asynchronous domains. 

We therefore need a formalisation of the local perspective of each
agent.


\section{Observations and Views}

This section develops an explicit formalisation of the local perspective
of each agent, representing it using concrete terms in the logic,
so that we can approach reasoning and planning in asynchronous domains
in a systematic way.

Existing work on multi-agent domains in the situation calculus has
left this agent-local perspective largely implicit; for example, it
is customary to introduce different kinds of sensing or communication
actions by directly modifying the axioms that define the dynamics
of knowledge. We choose instead to reify the local perspective of
each agent by explicitly talking about what it has observed, independent
of how this information will be used by the rest of the action theory.

The basic idea is as follows: each occurrence of an action results
in an agent making a set of \emph{observations}. Every situation then
corresponds to a local \emph{view} for that agent: the sequence of
all its observations, excluding cases where the set of observations
was empty. These form agent-local analogues to standard action and
situation terms, which represent the global state of the world. Allowing
the set of observations to be empty lets us model truly asynchronous
domains, in which an agent's local view is not always updated when
the state of the world is changed.

By having views as explicit terms in the logic, we are then in a position
to ensure that agents only reason and act based on their local information.
Having factored out the precise details of each agent's local view,
we can develop reasoning techniques and tools that can be applied
in a variety of different domains, rather than depending on any particular
details of how actions are perceived by each agent.

To demonstrate the appeal of this decoupling, we show how a variety
of domain dynamics can be modelled using our approach. The techniques
we subsequently develop using this foundation of observations and
views - our planning formalism using joint executions, our account
of knowledge with hidden actions, our regression rule for common knowledge
- can be used unmodified in any of these domains.


\subsection{Background\label{sec:Observations:Background}}

In many single-agent applications of the situation calculus, there
is no need to consider the local perspective of the agent -- since
the agent has complete knowledge and is the only entity acting in
the world, its local information is precisely equivalent to the global
information captured by the current situation term.

If the agent has incomplete knowledge about the state of the world,
it may need to perform \emph{sensing actions} to obtain additional
information \citep{giacomo99indigolog,scherl03sc_knowledge}. To represent
such actions, a new sort \noun{Result }is added to $\Lsit$, along
with an action description function $SR(a,s)=r$ that specifies the
result returned by each action. The agent's local perspective on the
world is then given by a \emph{history}, a sequence of $a\#r$ pairs
giving each action performed and its corresponding sensing result.

When sensing actions are used in IndiGolog \citep{giacomo99indigolog},
the agent must plan its execution using this history rather than a
raw situation term. This is accomplished without any modifications
to the underlying theory of action, by handling the history as a purely
meta-level structure and modifying the way queries are posed.

First, a pair of macros are defined to convert a history into proper
sentences of the situation calculus that capture the information it
contains. The macro $\mathbf{end}$ gives the situation term corresponding
to a history, while the macro $\mathbf{Sensed}$ produces a formula
asserting that each action produced the given sensing result. Let
$\epsilon$ be the empty history, then the definitions are:\begin{alignat*}{1}
\mathbf{end}[\epsilon] & \isdef S_{0}\\
\mathbf{end}[h\cdot(a\#r)] & \isdef do(a,\mathbf{end}[h])\\
\mathbf{Sensed}[\epsilon] & \isdef\top\\
\mathbf{Sensed}[h\cdot(a\#r)] & \isdef\mathbf{Sensed}[h]\wedge SR(a,\mathbf{end}[h])=r\end{alignat*}


Then, instead of asking whether a query holds at the current situation
$\sigma$:

\[
\Dt\,\models\,\phi[\sigma]\]


The agent asks whether the query holds given its current history $h$:\[
\Dt\,\models\mathbf{Sensed}[h]\,\rightarrow\,\phi[\mathbf{end}[h]]\]


This approach works well for a single agent, but we are aware of no
works extending this meta-level handling of histories to the multi-agent
case.\\


While the meta-level approach of \citep{giacomo99indigolog} allows
an agent to reason based on its local perspective, it is cumbersome
for reasoning \emph{about} that local perspective. To determine whether
an agent \emph{knows} that a formula holds in a given situation, we
must explicitly specify the agent's history of sensing results for
that situation, which may not be available until run-time. This meta-level
approach is not suitable for rich epistemic reasoning, where we may
want to reason offline about what the agent (or a group of agents)
will or will not know after a series actions.

This kind of reasoning requires an explicit representation of an agent's
knowledge, as described in Section \ref{sec:Background:Epistemic}.
We will review such epistemic reasoning in more detail in Chapter
\ref{ch:knowledge}, where we extend existing approaches to handle
asynchronous domains based on the formalism developed in this chapter.
For now we briefly discuss its use in axiomatising the local perspective
of each agent.

The effect of sensing results on an agent's knowledge is axiomatised
in \citep{scherl03sc_knowledge} by directly specifying it in the
successor state axiom for the knowledge fluent $K$. Agents discard
situations that do not agree with the obtained sensing result:\[
K(agt,do(a,s'),do(a,s))\,\equiv\, K(agt,s',s)\wedge Legal(a,s')\wedge SR(a,s')=SR(a,s)\]
 As a variety of richer domains have been modelled on top of this
formalism, their particular accounts of the local information available
to each agent have been specified by progressively modifying this
successor state axiom.

For example, when multiple agents are introduced, the successor state
axiom for $K$ is modified to ensure that an agent knows the results
produced by its own actions, but not by the actions of others \citep{shapiro98specifying_ma_systems}.
When communication actions are introduced, the successor state axiom
for $K$ is modified to ensure that the agent's knowledge is updated
to include the communicated information \citep{shapiro01casl_feat_inter,shapiro07sc_goal_change}.
When concurrent actions and time are introduced, the successor state
axiom for $K$ is modified to ensure that the agent knows how much
time has passed since the last action, while not inadvertently learning
the real value of the current time unless this was already known \citep{scherl03conc_knowledge}.

In these works there is no explicit representation of the local perspective
of each agent -- rather, the information each agent receives from
an action is specified only in terms of its effect on the agent's
knowledge. The formalism developed in this chapter will allow us to
decouple the dynamics of knowledge from the specific details of how
each action affects the agent's local perspective. As we will show
in Chapter \ref{ch:knowledge}, this can produce a much more general
and robust formalism for knowledge.

The observation-based approach will also allow us to work directly
with the local information available to each agent without needing
to make explicit statements about knowledge. For example, when planning
the cooperative execution of a task, we can formulate a reactive plan
in which each agent can act based directly on its local observations,
without having to introspectively reason about what it knows.\\


A related approach to ours is the work by \citet{pinto98sc_observations}
on axiomatising narratives in the situation calculus. Here the term
{}``observation'' is used in a more general sense to mean some partial
information about the state of the world, such as an action occurring
or a fluent holding at a particular time. These are asserted using
predicates such as $occurs(a,t)$ and $holds(F,t)$, and situations
are defined as \emph{proper} if they respect the asserted $occurs$
and $holds$ facts. Although the focus of \citep{pinto98sc_observations}
is on reasoning from a single omniscient perspective, it could easily
be extended to reason about the local perspective of multiple agents.

The crucial difference between \citep{pinto98sc_observations} and
the approach presented in this chapter is that we provide an explicit
axiomatisation not just of \emph{observations} but of \emph{observability.}
We provide a complete account of what each agent would observe if
any particular action occurred in any particular state of the world.
By virtue of not having made particular observations, agents in our
formalism can conclude that certain actions cannot have occurred.
By contrast, the use of $occurs$ and $holds$ in \citep{pinto98sc_observations}
specifies only what \emph{must} have happened, not what \emph{cannot}
have happened. This distinction will play an important role for effective
reasoning for our formalism.


\subsection{Definitions\label{sec:Observations:Definitions}}

In this section we formally define an explicit representation of the
local information available to each agent, and do so in a manner that
is independent of how that information will eventually be used. Our
approach can be seen as a generalisation of the history-based approach
of \citep{giacomo99indigolog}, explicitly representing the information
available to each agent. However, we encode this information as terms
in the logic rather than in the meta-level reasoning machinery. This
allows us to use this explicit local perspective in more general ways.

We begin by defining the notion of an \emph{observation}, which is
fundamental to the entire approach\emph{.} At the simplest level,
this is an internal notification that an agent receives when some
action has occurred.
\begin{defnL}
[{Observations}] An observation is a notification event received
by an agent, making it aware of some change in the state of the world.
When an agent receives such a notification, we say that it {}``observed'',
{}``made'' or {}``perceived'' that observation. 
\end{defnL}
Since {}``observation'' is quite a loaded term, it is worth re-iterating
this point: our observations are instantaneous \emph{events} generated
internally by each agent in response to actions occurring in the world.
We make no commitment as to how these events are generated, preferring
a clean delineation between the task of observing change and the dynamics
of knowledge update based on those observations.

Since the state of the world may only change in response to some action,
observations can only be made as a result of some action. For simplicity
we assume that agents perceive observations instantaneously, i.e.
in the same instant as the actions that cause them, but see Section
\ref{sec:Observations:Delayed} for a suggestion on how delayed observations
can be modelled.

To make this idea concrete, let us introduce an additional sort \noun{Observation}
to the language $\Lsit$, for the moment without any particular commitment
towards what this sort will contain. We then add an action description
function of the following form to $\Dt_{ad}$:\[
Obs(agt,c,s)=o\]
 This function returns a set of observations, and should be read as
{}``when actions $c$ are performed in situation $s$, agent $agt$
will perceive observations $o$''. Using a set of observations allows
an agent to perceive any number of observations in response to an
action occurrence -- perhaps several observations, perhaps none. When
$Obs(agt,c,s)$ is empty, the agent makes no observations and the
actions $c$ are completely hidden.

The concept of a \emph{view} follows naturally - it is the sequence
of all the observations made by an agent as the world has evolved.
\begin{defnL}
[{Views}] An agent's view in a given situation $\mathrm{s}$ is the
corresponding sequence of observations made by the agent as a result
of each action in $\mathrm{s}$, excluding those actions for which
no observations were made. \label{defn:Observations:View} 
\end{defnL}
We introduce another sort \noun{View} consisting of sequences of sets
of observations, with $\epsilon$ being the empty sequence and the
functional fluent $View$ giving the history of observations associated
with a particular situation. Since these definitions will not change
from one domain to another, they are added to the foundational axioms:\begin{align}
Init(s)\,\rightarrow & \, View(agt,s)=\epsilon\nonumber \\
Obs(agt,c,s)=\{\}\,\rightarrow & \, View(agt,do(c,s))=View(agt,s)\nonumber \\
Obs(agt,c,s)\neq\{\}\,\rightarrow & \, View(agt,do(c,s))=Obs(agt,c,s)\cdot View(agt,s)\label{eq:view_defn}\end{align}


Observations and views can be seen as localised analogues of actions
and situations respectively. An action is a global event that causes
the state of the world to change, while an observation is an internal
event that causes an agent's knowledge of the state of the world to
change. Similarly, a situation represents a complete, global history
of all the actions that have occurred in the world, while a view is
an agent's local history of all the observations it has made. The
situation is an omniscient perspective on the world, the view a local
perspective. This distinction will be fundamental to the new techniques
we develop throughout this thesis.

To provide a global account of the results returned by each action,
we can define a \emph{history} in a similar way to IndiGolog, but
represented explicitly as a term in the language. First, we define
the \emph{outcome} of an action as a mapping from agents to the observations
they made. To represent this mapping we use a set of \noun{Agent\#Observation}
pairs:
\begin{defnL}
[{Outcomes}] The outcome of an action $c$ is the set of $agt\#Obs(agt,c)$
pairs generated by that action:\[
Out(c,s)=y\,\equiv\,\forall agt,o:\, agt\#o\in y\,\equiv\, Obs(agt,c,s)=o\]

\end{defnL}
Then we can build the global history of a situation as a sequence
of actions paired with their respective outcomes:
\begin{defnL}
[{Histories}] The history of a situation $s$ is the sequence of
action\#outcome pairs corresponding to each action in $s$:\begin{gather*}
Init(s)\,\rightarrow\, History(s)=\epsilon\\
History(do(c,s))=h\,\equiv\, h=(c\#Out(c,s))\cdot History(s)\end{gather*}

\end{defnL}
We can also introduce an analogous function $Sit$ that translates
from a history term back into a raw situation:

\begin{gather*}
Sit(\epsilon)=S_{0}\\
Sit((c\#y)\cdot h)=do(c,Sit(h))\end{gather*}


Histories will be useful for planning the cooperative execution of
a shared task, when agents must explicitly reason about both the global
state of the system and the local perspective of each agent. To this
end, we introduce some suggestive notation for accessing the individual
observations in an outcome:\[
Out(c,s)[agt]=o\,\equiv\, agt\#o\in Out(c,s)\]


To ensure that these definitions operate in an intuitively correct
way, we also need a simple consistency constraint. Just as the empty
set of actions is assumed to never be legal, so we should assume that
it generates no observations -- clearly the agents cannot observe
anything if no action has taken place. Formally, we impose the following
consistency requirement on basic actions theories containing $Obs$:
\begin{defnL}
[{Observation~Causality~Requirement}] A basic action theory $\Dt$
specifying the $Obs$ function must ensure that agents do not perceive
observations that are not caused by some action:\[
\Dt\,\models\,\forall agt,s:\, Obs(agt,\{\},s)=\{\}\]

\end{defnL}
The key distinguishing feature of our approach is that the agent's
view excludes cases where $Obs(agt,c,s)$ is empty, so the agent may
not have enough information to determine how many actions have been
performed in the world. As discussed in Chapter \ref{ch:intro}, this
property is fundamental to modelling truly asynchronous domains. Mirroring
the terminology of \citep{vanBentham06tree_of_knowledge}, we can
explicitly define what it means for a domain to be \emph{synchronous}
in the situation calculus.
\begin{defnL}
[{Synchronous~Action~Theory}] A basic action theory $\Dt$ is synchronous
if every agent observes something whenever an action occurs:\label{def:Synchronous-Action-Theory}\[
\Dt\,\models\,\forall agt,c,s:\, Legal(c,s)\,\rightarrow\, Obs(agt,c,s)\neq\{\}\]

\end{defnL}
As we shall see, such domains make reasoning from the local perspective
of an agent significantly easier, as they do not need to consider
arbitrarily-long sequences of hidden actions. Before proceeding with
some example definitions of $Obs$, let us briefly foreshadow how
observations and views will be used in the coming sections.

In Section \ref{ch:jointexec}, we will define a partially-ordered
branching action structure to be generated as the output of the MIndiGolog
execution planning process. This structure, called a \emph{joint execution,}
represents many possible situations that are legal executions of the
program. Since agents can only be expected to act based on their local
information, we will require that if $s$ and $s'$ are two situations
that could be reached while performing a joint execution, and $View(agt,s)=View(agt,s')$,
then the agent's next action in both situations must be the same.
Moreover, if the joint execution requires an agent to execute some
action $a_{2}$ after another action $a_{1}$, we will require that
$Obs(agt,a_{1},s)$ is not empty, so that it will have some local
observation to trigger the performance of $a_{2}$. These restrictions
ensure that the joint execution can feasibly be carried out by the
agents.


\subsection{Axiomatising Observations\label{sec:Observations:Axiomatising-simple}}

We now show how observations and views can be used to model a variety
of common domain dynamics from the situation calculus literature.
We argue that these axiomatisations intuitively capture the {}``correct''
information in each case, but defer a formal comparison between our
approach and existing axiomatisations until we have developed our
theory of knowledge in Chapter \ref{ch:knowledge}.


\subsubsection{Public Actions}

By far the most common assumption about the observability of actions
is that {}``all actions are public'', which can be rephrased as
{}``when an action occurs, all agents will observe that action''.
Letting the \noun{Observation }sort contain \noun{Action }terms, this
can be captured using the following axiom in the definition of $Obs$:\begin{equation}
a\in Obs(agt,c,s)\,\equiv\, a\in c\label{eq:Observations:ObsStd1}\end{equation}


When sensing actions are included, it is typically assumed that only
the performing agent has access to the sensing results. This can be
modelled by extending the \noun{Observation} sort to contain \noun{Action\#Result}
pairs, and including the following in the definition for $Obs$:\begin{equation}
a\#r\in Obs(agt,c,s)\,\equiv\, a\in c\wedge actor(a)=agt\wedge SR(a,s)=r\label{eq:Observations:ObsStd2}\end{equation}


Note that since $Obs$ is an action description function, technically
we must specify it using a single axiom as described in Section \ref{sec:Background:SC:Axioms}.
For the sake of clarity we specify these two cases independently,
and assume that the final axiom defining $Obs$ takes the completion
of the individual cases in the standard way.

It should be clear that these definitions capture the intuition behind
this most common model of action observability. When we develop our
new axiomatisation of knowledge in Chapter \ref{ch:knowledge}, we
will demonstrate that these definitions provide an equivalent account
to the standard knowledge axioms of \citet{scherl03sc_knowledge}.

This approach clearly leads to synchronous domains, since an agent's
set of observations can only be empty if the set of actions is also
empty, and the empty action set is never legal to perform.


\subsubsection{Private Actions}

Another common model for action observability is to assume that {}``all
actions are private'', which can be rephrased as {}``when an action
occurs, only the performing agent will observe it''. This can be
modelled by simply dropping the public-observability axiom from equation
\ref{eq:Observations:ObsStd1}, leaving the following definition of
$Obs$:\[
a\#r\in Obs(agt,c,s)\,\equiv\, a\in c\wedge actor(a)=agt\wedge SR(a,s)=r\]


As noted in \citep{Lesperance99sitcalc_approach}, this approach means
that agents need to consider arbitrarily-long sequences of hidden
actions which may or may not have occurred, and thus forego regression
as an effective reasoning technique. By explicitly formalising this
situation, we will be in a position provide the first formal account
of effective reasoning in such asynchronous domains.


\subsubsection{Speech Acts}

Communication in the situation calculus is traditionally modelled
using explicit communicative actions or {}``speech acts'' \citep{shapiro01casl_feat_inter,shapiro07sc_goal_change}.
These actions are axiomatised as per standard actions, but special-case
handling is introduced in the axioms for knowledge in order to model
their communicative effects.

Instantaneous communication is modelled using actions such as $inform$,
where $inform(agt_{s},agt_{r},\phi)$ means the sender $agt_{s}$
informs the receiver $agt_{r}$ of the truth of some formula $\phi$.
If we assert that only truthful speech acts are allowed, and all actions
are publicly observable, then this requires no further axiomatisation:\[
Poss(inform(agt_{s},agt_{r},\phi),s)\,\equiv\,\phi[s]\]


The $inform$ action will be included in each agent's observations
whenever it occurs, from which the agent can conclude that it was
possible and thus that the contained formula holds in the world.

However, this simple approach can lead to third-party agents being
aware of what was communicated, which is often not desirable. In \citep{shapiro01casl_feat_inter}
encrypted speech acts are introduced to overcome this limitation,
ensuring that only the intended recipient of a message is able to
access its contents by performing a special \emph{decrypt} action.
While it would be straightforward to copy this approach in our formalism,
the problem it was introduced to solve no longer exists; we can directly
limit the accessibility of the message contents to the receiving agent
without introducing another action:\begin{gather*}
inform(s,r)\in Obs(agt,c,s)\,\equiv\,\exists m:\, inform(s,r,m)\in c\\
inform(s,r,m)\in Obs(agt,c,s)\,\equiv\, inform(s,r,m)\in c\wedge\left(agt=r\vee agt=s\right)\end{gather*}


Here all agents will observe that the communication occurred, but
only the sender and recipient can access the contents of the message.

Non-instantaneous communication can be modelled using a message queue
for each agent with separate $send$ and $check$ actions \citep{Lesperance99sitcalc_approach}.
The $send$ action adds a message to the queue, while the $check$
action returns the details of pending messages as its sensing result.
Since this approach uses the standard sensing-result machinery, it
requires no special axiomatisation in our framework.


\subsection{New Axiomatisations\label{sec:Observations:Axiomatising-extended}}

From the above examples, it should be clear that our formalism can
capture the information available to each agent under a variety of
domain dynamics already modelled in the situation calculus. We now
demonstrate some new axiomatisations of domains that have not previously
been explored in the situation calculus.


\subsubsection{Explicit Observability Axioms\label{sec:Observations:CanObs}}

Our approach offers a straightforward way to explore the middle ground
between the two extremes of {}``public actions'' and {}``private
actions'' discussed in the previous section. To axiomatise general
\emph{partial observability} of actions, we introduce a new action
description predicate $CanObs(agt,a,s)$ that defines the conditions
under which agent $agt$ would observe action $a$ being performed
in situation $s$. If $CanObs(agt,a,s)$ is false, then that action
will be hidden. We can then define $Obs$ as follows:\[
a\in Obs(agt,c,s)\equiv a\in c\wedge CanObs(agt,a,s)\]


This permits a great deal of flexibility in the axiomatisation. Consider
a domain in which the agents inhabit several different rooms, and
are aware of all the actions performed in the same room as themselves:\[
CanObs(agt,a,s)\equiv InSameRoom(agt,actor(a),s)\]


It is also possible to allow partial observability of sensing results
using an analo\-gous predicate $CanSense(agt,a,s)$ and the following
definition of $Obs$:\begin{multline*}
a\in Obs(agt,c,s)\equiv a\in c\wedge CanObs(agt,a,s)\wedge\neg CanSense(agt,a,s)\\
\shoveleft{a\#r\in Obs(agt,c,s)\equiv a\in c\wedge SR(a,s)=r}\\
\wedge CanObs(agt,a,s)\wedge CanSense(agt,a,s)\end{multline*}


For example, consider an agent waiting for a train who activates a
speaker to determine when it will arrive. The results of this sensing
action would provide information to any other agent within earshot:\[
CanSense(agt,activateSpeaker(agt_{2}),s)\equiv CloseToSpeaker(agt)\]


We feel that this formulation provides a good balance between simplicity
and expressiveness; it allows the observability of actions to vary
according to the state of the world, but provides agents with a complete
description of each action that they are capable of observing.


\subsubsection{Observability Interaction}

Reasoning about observability of concurrent actions raises the potential
for \emph{observability interaction}, in which some actions produce
different observations when they are performed concurrently with another
action. Like the precondition interaction problem for $Poss$ discussed
in Section \ref{sec:Background:Concurrent-Actions}, we assume that
the axiom defining $Obs$ contains the appropriate logic to handle
such interaction. A simple axiomatisation might have actions being
{}``masked'' by the co-occurrence of another action, and would appear
like so:\[
a\in Obs(agt,c,s)\equiv a\in c\wedge CanObs(agt,a,s)\wedge\neg\exists a'\in c:\, Masks(a',a,s)\]


The important point is that, given an explicit account of the local
perspective of each agent, such interaction can be axiomatised independently
of the rest of the action theory.


\subsubsection{Observing the Effects of Actions}

In many domains it would be infeasible for an agent to observe all
of the details of a particular action when it occurs, but it may observe
some of the effects of that action. For example, suppose that an agent
monitors the state of a light in its environment, such that it notices
it changing from dark to light. While it knows that \emph{some} action
must have occurred to produce that effect, it may not be sure precisely
what action took place (e.g. precisely \emph{who} turned on the light).
This can be modelled by further extending the \noun{Observation} sort
to contain a special {}``effect observation'' term $lightCameOn$,
and axiomatising like so:\[
lightCameOn\in Obs(agt,c,s)\equiv\neg lightIsOn(s)\wedge\exists agt':\, turnLightOn(agt')\in c\]


When the light is switched on, each agent's observation set will contain
the term $lightCameOn$, and they will be able to deduce that this
change has occurred without necessarily knowing the specific action
responsible for the change. This is similar to the {}``fluent change''
actions proposed by \citet{degiacomo98execution_monitoring}, but
embedded in the theory itself rather than generated by the agent when
it discovers that it must update its beliefs.


\subsubsection{Delayed Communication\label{sec:Observations:Delayed}}

Delayed communication can be modelled using separate $send$ and $recv$
actions. However, unlike the use of explicit communication channels
discussed on the previous section, we do not want the receiving agent
to have to poll the message queue. Rather, the $recv$ action should
occur automatically some time after the $send$ action.

This is easily modelled by making $recv$ a natural action. The $send/recv$
pair can then be axiomatised mirroring the standard account of long-running
tasks in the situation calculus. A fluent $PendMsg(s,r,m,t)$ indicates
that some message is pending and will be delivered at time $t$. We
have:\begin{gather*}
natural(recv(agt_{s},agt_{r},m))\\
send(agt_{s},agt_{r},m)\in Obs(agt,c,s)\equiv send(agt_{s},agt_{r},m)\in c\wedge agt=agt_{s}\\
recv(agt_{s},agt_{r},m)\in Obs(agt,c,s)\equiv recv(agt_{s},agt_{r},m)\in c\wedge agt=agt_{r}\\
Poss(recv(agt_{s},agt_{r},m)\#t,s)\equiv PendMsg(agt_{s},agt_{r},m,t,s)\end{gather*}
 \begin{multline*}
PendMsg(s,r,m,t_{m},do(c\#t,s))\,\equiv send(s,r,m)\in c\wedge t_{m}=t+delay(s,r,m,s)\\
\vee PendMsg(s,s,m,t_{m},s)\wedge\left(recv(s,r,m)\not\in c\vee t\neq t_{m}\right)\end{multline*}


A $send$ action thus causes the message to become pending, with its
delivery time determined by the functional fluent $delay$. Once the
delay time has elapsed, the natural action $recv$ will be triggered
and the message delivered. The $send$ and $recv$ messages are observed
only by the sender and receiver respectively.

If the agents have incomplete information about the $delay$ function,
this can easily model domains in which the message delay is unpredictable
or even unbounded, giving asynchronous communication in the style
of \citep{halpern90knowledge_distrib}.


\subsection{Reasoning from Observations\label{sec:Observations:Reasoning}}

With these definitions in place, we can now give a principled account
of what it means for an agent to reason using its local information.
Recall that in the single-agent setting of IndiGolog \citep{giacomo99indigolog}
a pair of macros is used to construct a query of the following form
given the agent's current history $h$:\[
\Dt\,\models\,\mathbf{Sensed}[h]\,\rightarrow\,\phi[\mathbf{end}[h]]\]


This depends crucially on the assumption that all actions are publicly
observable, so that the macro $\mathbf{end}$ can construct the precise
situation term corresponding to a given history. The resulting query
is in a form that can be answered effectively using the standard regression
operator.

We can pose a similar query using the definition of a global history
in our framework. First, define a history to be legal if it contains
the correct sensing results for a legal situation:\[
Legal(h)\,\isdef\, Legal(Sit(h))\wedge History(Sit(h))=h\]
 Then an appropriate query using the current history $h$ would be:\[
\Dt\,\models\, Legal(h)\,\rightarrow\,\phi[Sit(h)]\]


Since these are no longer macros, but are now actual functions in
the logic, this query is not immediately amenable to standard regression
techniques. However, since a history can always be converted into
a unique corresponding situation term, we can easily provide special-purpose
regression rules as follows: \begin{gather*}
\Reg(\phi[Sit(\epsilon)])\,\isdef\,\phi[S_{0}]\\
\Reg(\phi[Sit((c\#y)\cdot h)])\,\isdef\,\Reg(\phi,c)[Sit(h)]\end{gather*}


These rules mirror the definition of $\mathbf{end}$ and preserve
equivalence given the definition of the $History$ function. Since
$Legal$ and $History$ are ordinary fluents they can be handled by
standard regression rules. Agents can therefore use such a query to
do regression-based reasoning about some hypothetical future state
of the world, for example for the purposes of planning.

As we shall see in the coming chapters, for offline planning we can
permit the agents to reason using the hypothetical global history
rather than their local observations. For richer epistemic reasoning
about the current state of the world, we will require a technique
capable of performing inductive reasoning.


\subsection{Discussion\label{sec:Observations:Discussion}}

In this chapter we have constructed an explicit representation of
the local perspective of each agent, in terms of \emph{observations}
and \emph{views}. This terminology has been deliberately chosen to
mirror that used in other formalisms where representing this local
perspective is the norm, such as \citep{parikh85dist_knowledge,halpern90knowledge_distrib}.
As the examples in Sections \ref{sec:Observations:Axiomatising-simple}
and \ref{sec:Observations:Axiomatising-extended} have demonstrated,
this approach is able to capture a very wide variety of domain dynamics
in a flexible way.

Some of our axioms in Sections \ref{sec:Observations:Axiomatising-simple}
and \ref{sec:Observations:Axiomatising-extended} may seem rather
ad-hoc, but we claim they are no more or less ad-hoc than the many
adjustments made to the axioms defining the knowledge fluent $K$
to accommodate different kinds of information-producing action \citep{shapiro98specifying_ma_systems,Lesperance99sitcalc_approach,shapiro01casl_feat_inter,Petrick06thesis,shapiro07sc_goal_change}.
The difference is that these adjustments can now be made separately
from the rest of the theory, rather than in the fundamental axiom
for reasoning about knowledge. This makes our formalism significantly
more elaboration tolerant, a point we will return to in Chapter \ref{ch:knowledge}.
It also means that for certain applications, we can reason about an
agent's local view without the overhead of performing explicit epistemic
reasoning.

Of course, we also pay a price for this extra expressive power: representational
complexity. The theory of action must contain an explicit axiomatisation
of the \noun{Observation} sort and of our new $Obs$ function. There
is something of a tradition in the situation calculus of doing as
much as possible at the meta-level, adding to the theory itself only
when necessary \citep{levesque97golog}. As we will demonstrate in
the remainder of this thesis, the advantages provided by our explicit
representation of each agent's local perspective more than compensate
for the added complexity it introduces to the theory of action.

From the perspective of the rest of the thesis, the key contribution
of this chapter is to provide a uniform representation formalism.
The domain-specific observability dynamics can now be specified independently
from the rest of the theory. By {}``factoring out'' the details
in this way, we are in a position to construct formalisms and reasoning
techniques that do not make any assumptions about action observability.
In particular, we can explicitly represent and reason about asynchronous
domains.


\section{Joint Executions}

In this section we construct a new representation for the actions
to be performed by a team of agents during the cooperative execution
of a shared task. Dubbed \emph{joint executions}, they are partially-ordered
branching sequences of events. Joint executions allow independent
actions to be performed independently, while using each agent's local
view to ensure that synchronisation is always possible when required.

The output of the standard Golog execution planning process is a raw
situation term; a complete, ordered sequence of all actions that are
to be performed. This is suboptimal for generating and representing
plans in an asynchronous multi-agent setting in three ways:
\begin{itemize}
\item it does not permit branching to utilise information obtained at run-time 
\item it enforces a strict execution order on actions that are potentially
independent, requiring inter-agent synchronisation when it is not
actually necessary 
\item it requires a strict execution order on actions that may be unobservable,
demanding inter-agent synchronisation that is not actually feasible 
\end{itemize}
As we have demonstrated in Chapter \ref{ch:mindigolog}, restricting
the domain to be synchronous and completely known lets the agents
make effective use of raw situation terms for planning. In asynchronous
domains with incomplete knowledge they are no longer sufficient, and
the Golog execution planner is required to generate a much richer
representation of the actions to be performed.

To build such a representation, we take inspiration from a model of
concurrent computation known as \emph{prime event} \emph{structures},
which are partially-ordered branching sequences of events \citep{npw79event_structures}.
A \emph{joint execution} is defined as a particular kind of prime
event structure that is rich enough to capture the concurrent execution
of independent actions and can branch on the results of sensing actions.
We use our explicit account of an agent's local view to identify joint
executions that can feasibly be executed based on the local information
available to each agent at runtime.

Joint executions are formalised in a way that translates well into
an implementation. They can be built up one action at a time in much
the same way as ordinary situation terms. If the theory of action
meets some simple restrictions, joint executions can also be reasoned
about using standard regression techniques. We demonstrate an implementation
that performs offline execution planning for an asynchronous, partially
observable domain, and discuss the challenges faced when attempting
a cooperative online execution in such domains.

Joint executions thus allow us to represent the actions that a team
of agents are to perform in service of some shared task, without requiring
constant synchronisation between the agents, and without assuming
that agents know all the actions that have been performed, while utilising
existing reasoning methods and planning machinery. This is a significant
increase in power over existing approaches to planning for multi-agent
teams in the situation calculus.

The chapter proceeds as follows: after some more detailed background
information in Section \ref{sec:JointExec:Background}, we formally
define and axiomatise joint executions in Section \ref{sec:JointExec:JEs}.
Section \ref{sec:JointExec:Planning} then characterises the Golog
execution planning problem in terms of joint executions rather than
raw situation terms, and Section \ref{sec:JointExec:Reasonable} identifies
a restricted kind of joint execution that can be reasoned about effectively
using standard regression techniques. In Section \ref{sec:JointExec:Implementation}
we present an overview of our new MIndiGolog execution planner that
generates joint executions, and show some examples of its output.
Finally, Section \ref{sec:JointExec:Discussion} concludes with some
general discussion and an outline of our ongoing work in this area.


\subsection{Background\label{sec:JointExec:Background}}

The above discussion highlights three important properties of a plan
representation formalism intended for use in asynchronous multi-agent
domains: it must be \emph{partially-ordered} to allow agents to operate
independently, \emph{branching} to allow information to be collected
at run-time, and \emph{feasible to execute} based on the local information
available to each agent. While each of these aspects have been studied
in isolation in the situation calculus, our work is the first to combine
them into a single formalism that is suitable for asynchronous multi-agent
domains.


\subsubsection{Partial Ordering}

There has been little work on partial-order planning in the situation
calculus, most likely because the use of situations heavily biases
the reasoning machinery towards totally-ordered sequences of actions.
While \citet{son00htn_golog} allow the programmer to specify a partial
order on actions by adding operators to the Golog language, the actual
plans produced by their system are still ordinary situation terms.
One exception is \citep{plaisted97sc_aspect}, which extends the situation
calculus with explicit {}``aspects'' and allows partial ordering
between actions that affect different aspects of the world state.
By contrast, we seek to leverage the existing meta-theory of the standard
situation calculus.

Partial-order planning is the mainstay of the closely-related \emph{event
calculus} formalism \citep{kowalski86event_calculus}. In this formalism,
actions are represented as occurring at specific times, rather than
in a specific order as in the situation calculus. Constraints placed
on the relative occurrence times of actions then determine a partial
ordering. \citet{Shanahan97ec_planning} has shown that abductive
theorem proving in the event calculate generates partially-ordered
plans, and the mechanics of the theorem prover naturally mirror various
concepts from the goal-based partial-order planning literature, such
as conflicts, threats and links \citep{peot92conditional_nonlinear}.

The close similarities between the situation and event calculi are
well understood, as are the advantages of the event calculus when
working with partially-ordered action sequences \citep{belleghem97sitcalc_evtcalc}.
Indeed, it is possible to implement a Golog interpreter on top of
the event calculus, and the execution plans it generates are partially-ordered
sets of actions \citep{pereira04ec_golog}. Perhaps we should simply
adopt a formalism such as the event calculus that is naturally partially-ordered,
rather than trying to construct a partially-ordered representation
on top of the naturally sequential situation calculus?

Having a partial-order representation is important, but it is not
the complete picture. While we don't want the agents to have to synchronise
their actions unnecessarily, we also need to ensure the converse:
that when an explicit ordering between actions is \emph{necessary},
the required synchronisation is actually \emph{feasible} based on
the local information available to each agent. It is not clear how
techniques such as \citep{pereira04ec_golog} would extend to the
asynchronous multi-agent case.

By taking advantage of our explicit account of the local information
available to each agent, the formalism developed in this chapter enables
these dual requirements - that some actions don't need to be ordered,
while other actions cannot be ordered - to be captured in an elegant
way. Moreover, we do not need to step outside the bounds of existing
situation calculus theory, and can utilise existing regression techniques
for effective automated reasoning.


\subsubsection{Branching}

Several single-agent formalisms based on the situation calculus have
introduced some form of branching into the structures returned by
the planner, including the conditional action trees of of sGolog \citep{lakemeyer99golog_cats}
and the branching IndiGolog plans of \citep{giacomo04sem_delib_indigolog}.
These structures typically branch based on the truth or falsehood
of test conditions included in the program. For example, the structural
definition of conditional action trees in \citep{lakemeyer99golog_cats}
includes the following branching case:\[
c=[\phi,c_{1},c_{2}]\]


This instructs the agent to execute the sub-tree $c_{1}$ if $\phi$
is true and the sub-tree $c_{2}$ if $\phi$ is false. An alternate
approach, exemplified by the {}``robot programs'' of \citet{levesque98what_robots_can_do},
is to have the plan branch directly on the results returned by actions
rather than on a test condition. Branching on the binary result of
a sensing action is represented in this formalism by the following
structure:\[
branch(action,\delta_{1},\delta_{2})\]


Here the agent continues execution with program $\delta_{1}$ if the
action returns true, and with $\delta_{2}$ if the action returns
false. Plans that branch directly on the results of actions are typically
longer, but easier for the agent to execute reactively since it does
not need to introspect its knowledge base to decide a test condition.


\subsubsection{Feasibility\label{sec:JointExec:BG:Feasibility}}

To allow an agent to execute a plan that depends on information collected
at run-time, it is not sufficient to simply introduce branching into
the plan representation formalism. One must also ensure that, at execution
time, the agent will always \emph{know} which branch of the plan to
take. For example, suppose this simple branching plan will provably
achieve a goal:\[
\mathbf{if}\,\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


The agent can only execute this program if it knows whether or not
$\phi$ holds; otherwise, although one of the branches is guaranteed
to achieve the goal, the agent does not know which branch to take.
Feasibility is typically guaranteed by including sensing actions to
ensure that the test conditions become known when needed:\[
sense_{\phi}\,\,;\,\mathbf{if\,}\,\phi\,\,\mathbf{then}\,\, action_{1}\,\,\mathbf{else\,}\, action_{2}\]


This requirement that an agent {}``knows how'' to execute a plan
is formalised by various notions of \emph{epistemic feasibility},
including those of \citep{levesque98what_robots_can_do,levesque00knowing_how,Lesperance01epi_feas_casl,giacomo04sem_delib_indigolog,baier06programs_that_sense}.

One approach to ensuring feasibility, embodied by \citep{levesque00knowing_how,giacomo04sem_delib_indigolog,baier06programs_that_sense},
is to represent plans by arbitrary programs formulated in a control
language such as Golog. One then semantically characterises the class
of epistemically feasible programs, using direct assertions about
the knowledge of each agent at each stage of execution. While this
allows for potentially very rich, very succinct plans, it is not clear
how to systematically generate an epistemically feasible plan using
such a general characterisation.

Another approach, advocated by \citep{levesque96what_is_planning,levesque98what_robots_can_do}
and used in the implementation section of \citep{giacomo04sem_delib_indigolog},
is to restrict the structure of plans so that they are always epistemically
feasible. For example, the {}``robot programs'' of \citep{levesque98what_robots_can_do}
are restricted to simple operators such as sequencing, branching and
looping:\begin{gather*}
action\\
seq(\delta_{1},\delta_{2})\\
branch(action,\delta_{1},\delta_{2})\\
loop(branch(action,\delta,exit))\end{gather*}


These programs do not contain test conditions, but rather branch and
loop directly according to the sensing results returned from each
action. There is therefore no potential for confusion when executing
such programs; they are essentially equivalent to a kind of finite
automaton that can be executed reactively. Nevertheless, \citet{levesque98what_robots_can_do}
show that these programs are universal, in the sense that any achievable
goal can be achieved by suitable a robot program. We are not aware
of any work extending this approach to represent programs intended
for cooperative execution by a team of agents.

These existing notions of epistemic feasibility can be broadly characterised
as \emph{knowing what}. At each stage of execution, each agent must
know what its next action is. In synchronous domains with public actions,
as typically studied in the situation calculus, this is sufficient
to ensure the feasibility of executing a plan.

In asynchronous domains it is not enough for an agent to know \emph{what}
its next action is; it must also know \emph{when} that action should
be performed. For example, suppose that the following simple plan
provably achieves a goal:\[
action_{1}(agt_{1})\,;\, action_{2}(agt_{2})\]


In a synchronous domain this plan can be executed directly. But suppose
the domain is asynchronous, and $agt_{2}$ is unable to observe the
occurrence of $action_{1}$. Since $agt_{2}$ has no way of knowing
whether or not $action_{1}$ has been performed yet, it will not know
when to perform $action_{2}$ and the plan cannot be executed.

In this chapter we ensure plan feasibility by restricting the structure
used to represent plans, in an approach similar to \citep{levesque98what_robots_can_do}
but without looping constructs. We use the explicit account of an
agent's local view developed in the previous chapter to ensure that
each agent will always have enough information to determine what action
to perform next, and when to perform it.


\subsubsection{Event Structures}

To tackle cooperative execution in a multi-agent setting, we have
adopted a model of concurrent computation known as \emph{event structures}
\citep{npw79event_structures}. The particular variant we are interested
in are \emph{prime event structures}, which are defined as follows.

{[}{Prime~Event~Structure}{]} A prime event structure is a four-tuple
$(\mathcal{V},\gamma,\prec,\oplus)$ where: $\mathcal{V}$ is a set
of events; $\gamma$ is a function assigning a label to each event;
$\prec$ is the precedence relation, a strict partial order on events;
$\oplus$ is the conflict relation, a binary symmetric relation indicating
events that are mutually exclusive. 

The labels assigned by $\gamma$ give the action associated with each
event. By using a labelling scheme rather than identifying events
directly with actions, multiple events can result in the same action
being performed. The precedence relation restricts the order in which
events can occur, so that if $e1\prec e2$ then $e1$ must occur before
$e2$. The conflict relation allows the structure to represent branching,
by having the occurrence of some events preclude the occurrence of
others.

Figure \ref{fig:example-pes} shows a simple example of a prime event
structure. The arrows represent the precedence relation, so in this
diagram we have $e1\prec e3\prec e7$, but $e3\not\prec e4$. The
conflict relation is represented using a dotted line, so we have $e2\oplus e3$
and only one of these two events is permitted to occur. Conflict is
also inherited through the precedence relation, so $e6\oplus e7$
in this diagram.

%
\begin{figure}
\begin{centering}
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.35,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/example_pes.eps}}}{\tiny {}} 
\par\end{center}%
\end{minipage}} 
\par\end{centering}

\caption{An example Prime Event Structure.}


\label{fig:example-pes} 
\end{figure}


As it can be cumbersome to specify $\prec$ and $\oplus$ in their
entirety, we will instead specify only the direct \emph{enablers}
and \emph{alternatives} for each event, denoted by $ens(i)$ and $alts(i)$
respectively. Construction of $(\prec,\oplus)$ from $(ens,alts)$
is a straightforward transitive closure. Indeed, it only the enablers
and alternatives that are represented explicitly in Figure \ref{fig:example-pes},
by arrows and dotted lines respectively.

A \emph{configuration} is a sequence of events consistent with $\prec$
in which no pair of events conflict. Each configuration represents
a potential partial run of execution of the system. Event structures
thus form a directed acyclic graph of the events that could occur
during execution of the system. As shown in \citep{pratt91modeling_conc_with_geom},
these structures are a canonical representation of a variety of formalisms
for representing concurrent execution, and it is straightforward to
execute them in a purely reactive fashion.


\subsection{Joint Executions\label{sec:JointExec:JEs}}

This section defines \emph{joint execution}s as a restricted kind
of prime event structure suitable for representing the actions of
a team of agents in an asynchronous domain. We begin with a high-level
intuitive description to motivate these structures, and then formally
define them using a set of axioms to be included in the theory of
action $\Dt$. Since we intend for agents to synthesise joint executions
as the output of a planning process, they must exist as concrete terms
in the logic.


\subsubsection{Motivation}

To make things more concrete, consider again the {}``cooking agents''
example domain from Chapter \ref{ch:mindigolog} and the $MakeSalad$
program shown in Figure \ref{fig:MIndiGolog:MakeSalad}. In a completely-known,
synchronous domain, the execution found for this program by our MIndiGolog
interpreter was a linear sequence of concurrent actions as shown in
Figure \ref{fig:MIndiGolog:MakeSalad-in-MIndiGolog} on page \pageref{fig:MIndiGolog:MakeSalad-in-MIndiGolog}.

Let us now suppose that the cooking agents domain is asynchronous,
and all actions other than $release$ and $acquire$ are private.
The execution found by a MIndiGolog interpreter for such a domain
cannot assume that the agents perform their actions in lock-step.
Rather, it should allow the agents to process their respective ingredients
independently, synchronising their actions only on the $release$/$acquire$
sequence necessary to gain control of shared utensils.

An appropriate partially-ordered representation of the actions to
be performed for $MakeSalad$ would then look something like the structure
shown in Figure \ref{fig:JE:MakeSalad1}. For simplicity, we do not
consider time or natural actions in this chapter, and have collapsed
the {}``mix'' and {}``chop'' tasks into primitive actions. Without
expanding on the details at this stage, it should be clear that this
structure captures the same basic workflow as the synchronous execution
of $MakeSalad$ from Chapter \ref{ch:mindigolog}, but without imposing
a strict ordering between the independent actions of different agents.

Indeed, Figure \ref{fig:JE:MakeSalad1} is the joint execution produced
for the $MakeSalad$ program by our new execution planner detailed
in Section \ref{sec:JointExec:Implementation}, although with certain
details suppressed for brevity. It may be helpful to keep this structure
in mind as we develop the formal definitions contained in this section.

%
\begin{figure}[!h]
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/salad1_plan.eps}}}{\tiny {}} 
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad$ Program}


\label{fig:JE:MakeSalad1} 
\end{figure}



\subsubsection{Intuitions}

We define a joint execution as a special kind of prime event structure
as follows:

{[}{Joint~Execution}{]} A joint execution is a tuple $(\mathcal{A},\mathcal{O},ens,alts,\gamma,<)$
where: action events $\mathcal{A}$ represent actions to be performed;
outcome events $\mathcal{O}$ represent possible outcomes of actions;
$(\mathcal{A}\cup\mathcal{O},ens,alts,\gamma)$ forms a prime event
structure with precedence relation $\prec$; $<$ is a total order
on events that is consistent with $\prec$. 

A joint execution contains two disjoint sets of events: \emph{action}
events $\mathcal{A}$ representing the actions to be performed, and
\emph{outcome} events $\mathcal{O}$ representing the possible outcomes
of each action. For each action event $i\in\mathcal{A}$, its enablers
$ens(i)$ is a set of outcome events, its alternatives $alts(i)$
is empty, and its label $\gamma(i)$ is the action to be performed.
For each outcome event $i\in\mathcal{O}$, $ens(i)$ is a single action
event for which it is a possible outcome, $alts(i)$ is the set of
all other outcome events $j$ such that $ens(j)=ens(i)$, and $\gamma(i)$
is an outcome as produced by the $Out({a},s)$ function for the action
$\gamma(ens(i))$.

Each action event thus represents a single action to be performed,
which enables several alternative outcome events corresponding to
the potential results returned by that action; since the action can
only produce one actual outcome when it is executed, the enabled outcome
events are all mutually conflicting. Each of these outcome events
can then enable further action events, and so forth.

%
\begin{figure}[!b]
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/example_je.eps}}}{\tiny {} }%
\end{minipage}}

\caption{A simple joint execution.}


\label{fig:example-je} 
\end{figure}


A simple example of a joint execution is shown in Figure \ref{fig:example-je},
again using the {}``cooking agents'' example domain. Here elliptical
nodes are action events and box nodes are the resulting outcome events.
The action $checkFor$ senses the presence of a type of ingredient,
returning either $T$ or $F$, and thus producing two conflicting
outcome events. In this example the agent $Jim$ senses for the availability
of eggs, and if this returns true he acquires one; otherwise, he acquires
a tomato. Meanwhile agent $Joe$ acquires a lettuce, independent of
the actions $Jim$ is performing.

Since we are explicitly considering concurrent actions, there are
many different possible ways that the events in this structure could
translate into action occurrences. The independent actions $checkFor(Jim,Egg)$
and $acquire(Joe,Lettuce1)$ could be performed in either order, or
even concurrently.

These structures are clearly much richer than ordinary situation terms,
as they permit branching and partial-ordering between actions. Still,
they correspond to sets of ordinary situation terms in a straightforward
way. Recall that a \emph{configuration} is a partial run of execution
of a prime event structure. Clearly any configuration ending in an
outcome event corresponds to a unique situation term and also a unique
history term, as it is a sequence of alternating actions and their
outcomes.

We will call a set of unordered, non-conflicting outcome events a
\emph{branch}. A branch identifies a set of partial runs of the joint
execution. In Figure \ref{fig:example-je}, the sets $\{O3\}$, $\{O1,O3\}$
and $\{O5,O3\}$ are examples of branches. A \emph{leaf} is a special
case of a branch, where every event is either in the leaf, conflicts
with something in the leaf, or precedes something in the leaf; it
thus represents potential \emph{terminating} runs of the joint execution
execution. In Figure \ref{fig:example-je} there are two leaves, $\{O3,O4\}$
and $\{O3,O5\}$, generated by the two alternate outcomes of the $checkFor$
action.

A \emph{history} of a branch is a history term (as defined in Chapter
\ref{ch:observations}) that can be generated by performing actions
and observing outcomes from the joint execution until all events in
the branch have occurred. By these definitions, the set of histories
of all leaves gives every possible history that could be produced
by performing the joint execution through to a terminating configuration.

A joint execution has one additional component over a standard prime
event structure: a \emph{total} order on events $<$ that is consistent
with the partial order $\prec$ induced by the enabling relation.
We call this the \emph{canonical ordering}, and it allows any branch
to be unambiguously translated into a single \emph{canonical history}.
When we come to use joint executions for planning, we will use the
canonical history to avoid having to reason about all the (potentially
exponentially-many) histories of each leaf. The canonical ordering
is essentially arbitrary; in practice it is determined by the order
of insertion of events into the structure.


\subsubsection{Structural Axioms}

We introduce new sorts \noun{Event }and \noun{JointExec} to $\Lsit$,
and will collect the axioms defining joint executions in a separate
axiom set $\Dt_{je}$. Events are opaque identifiers with which a
joint execution associates a label, a set of enablers, and a set of
alternatives. In practice we identify events with the integers, although
our definitions require only a total ordering relation over events.
Labels are either \noun{Action} or \noun{Outcome} terms. A joint execution
is then a term containing:
\begin{itemize}
\item a set of \emph{events}, which are opaque ids having total order $<$ 
\item a mapping from each event to a \emph{label}, which is either an action
or an outcome 
\item a mapping from each event to its \emph{enablers}, a set of lower-numbered
events 
\item a mapping from each event to its \emph{alternatives}, a set of events 
\end{itemize}
We will use the function $jexec$ as a constructor for joint execution
terms, specifying each of the four features above as an argument,
and using sets of $key\#value$ pairs to represent a mapping as in
the previous chapter.

First, we require a unique names axiom to specify that a joint execution
is uniquely defined by its four components, and a domain closure axiom
to specify that all joint executions are constructed in this way.
Assuming the variables are restricted to appropriate sorts by $\Lsit$,
the following axioms suffice:\begin{gather*}
\forall ex:\,\exists es,ls,ns,as:\,\, ex=jexec(es,ls,ns,as)\\
\\jexec(es,ls,ns,as)=jexec(es',ls',ns',as')\,\equiv\,\,\,\,\,\,\,\,\\
\,\,\,\,\,\,\,\, es=es'\wedge ls=ls'\wedge ns=ns'\wedge as=as'\end{gather*}


We introduce four functions to access the components of a joint execution:\begin{gather*}
events(ex)=es\,\equiv\exists ls,ns,as:\, ex=jexec(es,ls,ns,as)\\
lblmap(ex)=ls\,\equiv\exists es,ns,as:\, ex=jexec(es,ls,ns,as)\\
ensmap(ex)=ns\,\equiv\exists es,ls,as:\, ex=jexec(es,ls,ns,as)\\
altsmap(ex)=as\,\equiv\exists es,ls,ns:\, ex=jexec(es,ls,ns,as)\end{gather*}


We also define the following shortcut accessors to get the value from
each mapping for a particular event $i$:\begin{gather*}
lbl(ex,i,l)\equiv i\#l\in lblmap(ex)\\
ens(ex,i,ns)\equiv i\#ns\in ensmap(ex)\\
alts(ex,i,as)\equiv i\#as\in altsmap(ex)\end{gather*}


For notational convenience we will often write these as functions,
e.g. $ens(ex,i)=ns$ rather than $ens(ex,i,ns)$, but this should
be understood as an abbreviation since not every joint execution will
contain every event.

We must also define the \emph{precedes} and \emph{conflicts} relations
in terms of enablers and alternatives. These will be written as binary
infix operators $\prec_{ex}$ and $\oplus_{ex}$ respectively. Since
they are transitive closures they require a second-order axiomatisation.
First, the precedence relation is defined as a simple transitive closure
over enablers:\begin{multline*}
\forall P,ex,i,j:\left[\left(i\in ens(ex,j)\,\rightarrow P(i,j)\right)\wedge\left(\forall k:P(i,k)\wedge k\in ens(ex,j)\rightarrow P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\prec_{ex}j\right)\end{multline*}


Then we can define the conflict relation by specifying that $i\oplus_{ex}j$
if they are alternatives to each other, or they have conflicting predecessors:\begin{multline*}
\forall P,ex,i,j:\,\left[\left(i\in alts(ex,j)\,\rightarrow P(i,j)\right)\right.\\
\left.\wedge\,\left(\forall i',j':\, P(i',j')\wedge i'\preceq_{ex}i\wedge j'\preceq_{ex}j\,\rightarrow\, P(i,j)\right)\right]\\
\rightarrow\left(P(i,j)\rightarrow i\oplus_{ex}j\right)\end{multline*}


Next we need axioms defining our terminology of \emph{branches} and
\emph{leaves}. A branch is a set of unordered non-conflicting outcome
events:\begin{multline*}
Branch(ex,br)\,\equiv\,\forall i,j\in br:\, IsOutcome(lbl(ex,i))\wedge IsOutcome(lbl(ex,j))\\
\wedge\,\neg(i\oplus_{ex}j)\,\wedge\, i\not\prec_{ex}j\,\wedge\, j\not\prec_{ex}\, j\end{multline*}


A \emph{leaf} is defined as a special case of a branch, so that every
event in the joint execution is either in the leaf, precedes something
in the leaf, or conflicts with something in the leaf:\begin{multline*}
Leaf(ex,lf)\,\equiv\, Branch(ex,lf)\\
\wedge\forall i\in events(ex):\, i\in lf\,\equiv\,\neg(\exists i'\in lf:\,\, i\oplus_{ex}i'\,\vee\, i\prec_{ex}i')\end{multline*}


Finally, we say a joint execution is \emph{proper} if it respects
the basic structural intuitions we discussed in the previous section.
Every event must be proper according to its type, and events cannot
be enabled by higher-numbered events:\begin{gather*}
Proper(ex)\,\equiv\,\forall i\in events(ex):\, ProperAct(ex,i)\vee ProperOut(ex,i)\\
\wedge\forall i,j:\,\left(i\in events(ex)\wedge j\in ens(ex,i)\,\rightarrow\, j<i\right)\end{gather*}


Note that this does not result in a loss of expressivity, since we
we want event $i$ to precede event $j$, then $j$ cannot also precede
$i$ and we simply give $j$ the higher event number. This restriction
will play an important role in Section \ref{sec:JointExec:Reasonable}.

An action event is proper if it has no alternatives, enables at least
one outcome event, and is enabled by a branch. Restricting the enablers
to be a branch ensures that they do not contain any redundant or conflicting
information.\begin{gather*}
ProperAct(ex,i)\,\equiv\, IsAction(lbl(ex,i))\\
\wedge Branch(ex,ens(ex,i))\wedge alts(ex,i)=\{\}\wedge\exists j:\, ens(ex,j)=\{i\}\end{gather*}


An outcome event is proper if it is enabled by a unique action event,
and has as its alternatives the set of all other events enabled by
that action.\begin{gather*}
ProperOut(ex,i)\,\equiv\, IsOutcome(lbl(ex,i))\\
\wedge\exists j:\, ens(ex,i)=\{j\}\wedge IsAction(lbl(ex,j))\\
\wedge\forall k:\,\left(k\in alts(ex,i)\,\equiv\, ens(ex,k)=\{j\}\wedge k\neq i\right)\end{gather*}


These definitions enforce the basic structure of a joint execution
according to the intuitions discussed in the previous section, but
do not constrain it to be something that could actually be performed
in the world -- for example, outcomes can be enabled by actions that
will never actually produce that outcome. Like situation terms, we
focus first on getting the appropriate structure, and then specify
additional conditions that joint executions must satisfy in order
to be legal in the real world.


\subsubsection{Performing Events}

We introduce a predicate $Perform$ that axiomatises how events from
a joint execution can be performed. Since we explicitly consider concurrent
actions, this predicate selects a \emph{set} of action events to be
performed: \begin{gather*}
Perform(ex,es_{a},es_{o},ex')\equiv\,\,\,\,\, es_{a}\neq\{\}\wedge es_{o}\neq\{\}\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\, IsAction(lbl(ex,i))\wedge ens(ex,i)=\{\}\right)\\
\wedge\,\forall i:\,\left(i\in es_{o}\,\rightarrow\exists j:\, ens(ex,i)=\{j\}\wedge j\in es_{a}\right)\\
\wedge\,\forall i:\,\left(i\in es_{a}\,\rightarrow\,\exists j:\, j\in es_{o}\wedge ens(ex,j)=\{i\}\right)\\
\wedge\,\forall i,j:\,\left(i\in es_{o}\wedge j\in es_{o}\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall i:\,\left(i\in events(ex')\,\equiv\, i\not\in es_{a}\wedge i\not\in es_{o}\wedge\neg\exists j:\,(j\in es_{o}\wedge i\oplus_{je}j)\wedge\right)\\
\wedge\,\forall i,lb:\,\left(i\#lb\in lblmap(ex')\equiv\, lbl(ex,i)=lb\wedge i\in events(ex')\right)\\
\wedge\,\forall i,as:\,\left(i\#as\in altsmap(ex')\equiv alts(ex,i)=as\wedge i\in events(ex')\right)\\
\wedge\,\forall i,ns:\,\left(i\#ns\in ensmap(ex')\equiv(ens(ex,i)-es_{o})=ns\wedge i\in events(ex')\right)\end{gather*}


The first four lines of this definition select $es_{a}$ and $es_{o}$
as sets of action and outcome events respectively. The events in $es_{a}$
are any subset of the action events in the joint execution that have
no enablers, and are therefore possible to perform. The set $es_{o}$
contains one outcome event enabled by each event in $es_{a}$.

The remaining four lines specify how the events remaining in the joint
execution are updated: events that conflict with the performed events
are removed, and the performed events are removed from all lists of
enablers.

As an example, consider again the simple joint execution shown in
Figure \ref{fig:example-je}. The possible values of $es_{a}\#es_{o}$
generated by $Perform$ for this joint execution are:\begin{gather*}
\{A1\}\#\{O1\}\\
\{A1\}\#\{O2\}\\
\{A2\}\#\{O3\}\\
\{A1,A2\}\#\{O1,O3\}\\
\{A1,A2\}\#\{O2,O3\}\end{gather*}


These correspond to all potential next steps of execution of this
structure. The $Perform$ predicate is clearly quite non-deterministic,
permitting any subset of the enabled events to be performed; the different
choices it can make correspond to different potential orderings of
events when performing the joint execution.


\subsubsection{Histories}

Every branch identifies a family of potential partial runs of the
execution, which are given by the branch's \emph{histories}. The predicate
$History$ constructs a branch history by recursively performing events
that do not conflict with the branch, until all events in the branch
have been performed. This predicate depends on $Perform$ to identify
an enabled set of action events $es_{a}$ and outcome events $es_{o}$,
the labels of which are translated into action and outcome terms $c$
and $y$ respectively. \begin{gather*}
History(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


The second and third lines of this definition select sets $es_{a}$
and $es_{o}$ that do not conflict with the given branch. The fourth
line constructs the concurrent action $c$ as the union of each action
in the set $es_{a}$, while the fifth line constructs the corresponding
outcome $y$ as the agent-wise union of the outcomes in the set $es_{o}$.
Such pairs $c\#y$ are repeatedly selected until every event in the
branch is performed.

Clearly, if there are many unordered events then there are many potential
histories for a given branch; in fact there may be exponentially-many
histories in general. In Section \ref{sec:JointExec:Reasonable} we
show how to avoid reasoning about each history individually, which
is crucial if these structures are to be of practical use. Instead,
we reason about only the \emph{canonical} \emph{history,} the unique
history obtained by performing events in the strict order determined
by the $<$ relation:\begin{gather*}
CHistory(ex,br,h)\equiv\,\,\,\, b=\{\}\wedge h=\epsilon\\
\vee\,\left(\exists ex',h',br',es_{a},es_{o},c,y:\, Perform(ex,es_{a},es_{o},ex')\right.\\
\wedge\,\exists i:\, es_{a}=\{i\}\wedge\forall j\in events(ex):\, i<j\,\\
\wedge\,\forall i,j:\,\left(i\in br\wedge j\in(es_{a}\cup es_{o})\,\rightarrow\,\neg(i\oplus_{ex}j)\right)\\
\wedge\,\forall a:\,\left(a\in c\,\equiv\,\exists i:\, i\in es_{a}\wedge lbl(ex,i)=a\right)\\
\wedge\,\forall agt,o:\,\left(o\in y[agt]\,\equiv\,\exists i:\, i\in es_{o}\wedge o\in lbl(ex,i)[agt]\right)\\
\forall i:\,\left(i\in br'\,\equiv\, i\in br\wedge i\in events(ex')\right)\\
\left.\wedge\, History(ex',br',h')\,\wedge\, h=h'\cdot(c\#y)\right]\end{gather*}


For convenience, we also define a predicate $Sit$ that gives the
situation terms corresponding to the branch histories:\[
Sit(ex,br,s)\,\equiv\,\exists h:\, History(ex,br,h)\wedge Sit(h)=s\]


From these definitions it should be clear that joint executions constitute
a plan of action that can be executed reactively in the world. It
is simply a matter of picking some subset of the enabled actions,
executing them and obtaining the corresponding outcomes, then rolling
the joint execution forward according to the $Perform$ predicate.
The set of histories of all leaves of a joint execution gives every
possible situation that could be reached by performing it in the world.

Of course, this simple account of performing a joint execution assumes
public observability of all actions and outcomes. For a team of agents
to be able to feasibly execute it based only on their local information,
we must enforce some additional restrictions on the structure of a
joint execution.


\subsubsection{Feasible Joint Executions}

Since we intend for joint executions to be performed reactively by
a team of agents in an asynchronous environment, we must formalise
the relationship between the global histories of a joint execution
and each agent's local view of those histories. First, we define the
$View$ function over a history in the obvious way:\begin{gather*}
View(agt,\epsilon)=\epsilon\\
y[agt]=\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=View(agt,h)\\
y[agt]\neq\{\}\,\rightarrow\, View(agt,(c\#y)\cdot h)=y[agt]\cdot View(agt,h)\end{gather*}


A branch can \emph{generate a view} if one of its histories corresponds
to that view:\[
GeneratesView(ex,br,agt,v)\,\equiv\,\exists h:\, History(ex,br,h)\,\wedge\, View(agt,h)=v\]
 Let $actor(ex,i)$ be the agent responsible for performing an action
event $i$. Then that event is \emph{enabled by a view} if there is
a history of its enablers that can generate that view for the performing
agent:\begin{multline*}
EnabledByView(ex,i,agt,v)\equiv\\
actor(ex,i)=agt\,\wedge\, GeneratesView(ex,ens(ex,i),agt,v)\end{multline*}


Since an agent's view does not have complete information, $EnabledByView$
identifies events that the agent \emph{might} be required to perform
based on its local information. It is not sufficient to precisely
identify a particular branch, and therefore cannot be used to determine
for certain whether any particular event should be performed.

To ensure the feasibility of performing a joint execution based on
each agent's local information, we must assert two additional structural
restrictions to ensure each agent can always determine the action
it is to perform.

The first restriction corresponds to the idea of \emph{knowing when}
to perform an action. If an action event $i$ is enabled by an outcome
event $j$, then $j$ must not be hidden from the agent performing
$i$. Otherwise, it has no way of enforcing the required ordering
between the two events. This requirement is formalised by:\begin{multline*}
KnowsWhen(ex)\,\isdef\,\\
\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\,\wedge j\in ens(ex,i)\\
\rightarrow\, lbl(ex,i)[actor(ex,i)]\neq\{\}\end{multline*}


Figure \ref{fig:not-knows-when} shows an example of a joint execution
that does not meet this requirement. This plan calls for $Jim$ to
place an egg in the bowl, and then for $Joe$ to mix the bowl's contents.
However, since $Joe$ cannot observe the occurrence of $Jim$'s action,
he cannot enforce the ordering between these two events.

%
\begin{figure}[!t]
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/unfeas_je2.eps}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhen$ restriction}


\label{fig:not-knows-when} 
\end{figure}


%
\begin{figure}[!t]
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\textsf{\textbf{\tiny \includegraphics[scale=0.35,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/unfeas_je.eps}}}{\tiny {} }%
\end{minipage}}

\caption{A joint execution that violates the $KnowsWhat$ restriction}


\label{fig:not-knows-what} 
\end{figure}


The second restriction corresponds to the idea of \emph{knowing what}
action to perform. For any given view $v$, there may be multiple
branches with a history that could generate that view, and the agent
has no means of knowing precisely branch has been performed in the
world. We require that if an event is enabled by a view, then \emph{all}
branches that could generate that view enable a similar event:\begin{multline*}
KnowsWhat(ex)\,\isdef\,\\
\forall agt,v,i,br:\,\, EnabledByView(ex,i,agt,v)\,\wedge GeneratesView(ex,br,agt,v)\,\rightarrow\\
\exists j:\, ens(ex,j)=br\,\wedge\, lbl(ex,i)=lbl(ex,j)\end{multline*}
 While the agent may not know precisely which \emph{event} is enabled,
its local information is enough to determine the specific \emph{action}
that it is to perform. Figure \ref{fig:not-knows-what} shows an example
of a joint execution that does not meet this requirement. This plan
calls for $Jim$ to check for the availability of eggs, then for $Joe$
to acquire an appropriate ingredient depending on whether they are
available. But since $Joe$ cannot distinguish between outcome events
$O1$ and $O2$ after he observes $checkFor(egg)$, he doesn't know
what action to perform and the plan cannot be executed.

We say a joint execution is \emph{feasible} if it meets both of these
restrictions:\[
Feasible(ex)\,\isdef\, KnowsWhat(ex)\wedge KnowsWhen(ex)\]



\subsubsection{Legal Joint Executions}

So far, we have not restricted joint executions to correspond to any
sort of \emph{legal} run of execution. A joint execution may have
action events enabling outcome events that they would never produce
under the given theory of action. It may call for actions to be performed
in situations where they are not legal, or allow actions to be performed
concurrently that could be in conflict.

To avoid such undesirable cases, we identify \emph{legal} joint executions
as ones that are constrained enough to be performed in the real word.
We will say that a particular leaf of a joint execution is legal if
every history of that leaf is legal:\[
Legal(ex,lf)\,\isdef\,\forall h:\, History(ex,lf,h)\,\rightarrow\, Legal(h)\]


This ensures that the leaf is constrained enough to prevent precondition
interaction between independent action events, that its outcome events
are correct for their corresponding actions, etc. However, the agents
will generally not have enough information to determine whether a
particular leaf is legal, since this would imply that they already
know what sensing results will occur. We call an entire joint execution
legal if is proper and contains a legal leaf:\[
Legal(ex)\,\isdef\, Proper(ex)\,\wedge\,\exists lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\]


This definition does not require that we establish \emph{which} leaf
is legal, only that we are able to prove that \emph{some} leaf must
be legal. In practise this would be done by enumerating the possible
outcomes of each action. Since the leaves of a joint execution represent
all its possible terminating configurations, this requirement means
that a legal joint execution can legally be performed to completion
in the world.

The definition is also \emph{permissive}, in that there may be leaves
of the joint execution that are provably never be legal. Since the
outcomes along these leaves will not occur in reality, the agents
will never follow them at execution time. This permissiveness will
therefore not affect an agent's ability to carry out the plan in practice.


\subsubsection{Summary}

This section has formally defined a \emph{joint execution}, a partially-ordered
branching action structure that we claim is particularly well suited
for representing the actions to be performed by a team of agents in
service of a shared task. The partially-ordered nature of joint executions
allows them to explicitly account for inter-agent synchronisation
of actions in the face of partial observability, while their branching
nature allows them to account for incomplete information that must
be augmented with runtime sensing results.

In asynchronous domains, where raw situation terms cannot feasibly
be executed in the world, joint executions are an ideal alternative
as a plan representation structure for use by the Golog execution
planning process. In the next section we identify precisely what such
a planning process would entail.


\subsection{Planning with Joint Executions\label{sec:JointExec:Planning}}

With the above definitions and axioms in place, we are now in a position
to plan the cooperative execution of a shared Golog program using
joint executions rather than raw situation terms. For the moment we
focus on \emph{offline} execution planning, in the style of the original
Golog and ConGolog. Recall that the semantics of execution planning
in Golog involve finding a situation term $s$ satisfying:\[
\Dt\cup\Dt_{golog}\,\models\,\exists s:\,\Do(\delta,S_{0},s)\]


Before extending this query to search for a joint execution, notice
an important consequence of our definitions: two events can occur
in either order if and only if they can also occur concurrently. Since
the standard Golog/ConGolog semantics do not permit true concurrency,
they would force all events to be ordered and we would gain no benefit
from using joint executions. We must therefore adopt the concurrency
semantics of MIndiGolog from Chapter \ref{ch:mindigolog}, which permit
true concurrency of actions.

The execution planning problem then reduces to the task of finding
a \emph{legal}, \emph{feasible} joint execution such that for every
leaf, if that leaf is legal, then it constitutes a legal execution
of the program:\begin{multline}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\label{eq:JE-Plan-Defn}\end{multline}


This query neatly captures dual soundness and completeness requirements.
For soundness, it requires that for every leaf of the joint execution,
\emph{if} that leaf is legal then it will be a legal execution of
the program $\delta$. For completeness, it requires that there must
in fact be \emph{some} leaf that is legal, so the joint execution
can actually be performed in the world. The joint execution must contain
enough branching to account for any incomplete knowledge the agents
have about the state of the world.

%
\begin{algorithm}[t]
\caption{Offline Execution Algorithm using Joint Executions}


\label{alg:je_offline_exec} \begin{algorithmic}

\STATE

\STATE $v\,\Leftarrow\,\epsilon$

\STATE Find a joint execution $ex$ such that:\begin{multline*}
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists ex:\, Legal(ex)\wedge Feasible(ex)\wedge\\
\forall lf:\, Leaf(ex,lf)\wedge Legal(ex,lf)\,\rightarrow\,\left[\forall s:\, Sit(ex,lf,s)\rightarrow\Do(\delta,S_{0},s)\right]\end{multline*}


\WHILE{$ex$ contains action events to be performed by me}

\STATE Find an action $a$ such that\[
\Dt\cup\Dt_{mgolog}\cup\Dt_{je}\models\exists i:\, EnabledByView(ex,i,agt,v)\wedge lbl(ex,i)=a\]


\IF {there is such an action}

\STATE Execute action $a$

\ENDIF

\STATE Wait for a new observation $o$

\STATE $v\,\Leftarrow\, o\cdot v$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


Algorithm \ref{alg:je_offline_exec} presents a simple modification
of the Golog offline planning algorithm that can be used by each agent
to plan the execution of a shared program $\delta$ and then perform
it in the world. A restricted version of this algorithm is used by
our implementation that will be described in Section \ref{sec:JointExec:Implementation}.

Since this algorithm is to be executed independently by each agent
in the team, it must identify actions to perform using only the agent's
local view. We restrict the joint execution to be feasible so that
the $EnabledByView$ query is sufficient to identify what action to
perform next. If we did not have this restriction, Algorithm \ref{alg:je_offline_exec}
would not be correct.

If we turn our attention to \emph{online} execution in the style of
IndiGolog, things are not so straightforward. Although we have not
presented the axioms for doing so, it is simple enough to extend the
leaves of a joint execution one action at a time in the style of the
IndiGolog execution algorithm presented in Algorithm \ref{alg:indigolog_exec}.
The difficulty comes in trying to coordinate this process across multiple
agents when they have differing knowledge about the state of the world.

To demonstrate the issues involved, consider the hypothetical, \textbf{\emph{incorrect}}
online execution algorithm presented in Algorithm \ref{alg:je_online_exec_invalid},
which mirrors the ReadyLog execution algorithm used by our first MIndiGolog
implementation. Since joint executions are a branching structure,
the agent must extend each leaf of the joint execution with a new
step of execution of the program; if any leaf cannot be extended then
execution will potentially fail. To avoid this the agent discards
leaves that it knows are not legal before planning the next step of
execution.

%
\begin{algorithm}[t]
\caption{Hypothetical (Incorrect) Online Execution Algorithm}


\label{alg:je_online_exec_invalid} \begin{algorithmic}

\STATE

\STATE $v\,\Leftarrow\,\epsilon$

\STATE $ex\,\Leftarrow\, jexec(\{\},\{\},\{\},\{\})$

\WHILE{$\delta$ is not final according to my current view $v$}

\STATE Discard any leaves of $ex$ incompatible with $v$

\STATE Extend each leaf of $ex$ with a legal step of $\delta$

\STATE Find an action in $ex$ that is enabled by $v$

\IF {there is such an action}

\STATE Execute that action

\ENDIF

\STATE Wait for a new observation $o$

\STATE $v\,\Leftarrow\, o\cdot v$

\ENDWHILE

\end{algorithmic} 
\end{algorithm}


However, the implicit coordination scheme used by ReadyLog and MIndiGolog
depends on all agents generating the same {}``next step'' at every
iteration. It is therefore incorrect for the agent to discard leaves
based only on its local information -- it must retain any leaves that
its teammates could still consider possible, in order to guarantee
that they generate the same plan. Worse, it must also consider that
its teammates will retain leaves that they think \emph{it} could still
consider possible, and so-on ad infinitum.

The difficulty here is the well-known correspondence between coordination
and common knowledge \citep{halpern90knowledge_distrib}. In order
to extend this execution algorithm to the case of incomplete information,
the agents must plan based on what is \emph{commonly known} at each
step of execution, rather than based on their own individual view.
Unfortunately the situation calculus currently offers no tools for
reasoning about common knowledge, not even in synchronous domains.

Coordinating the online execution of a shared Golog program in asynchronous
domains thus requires more explicit reasoning about the knowledge
of each agent, and the common knowledge of the team. In the coming
chapters of this thesis we will explore the foundations for such reasoning,
but we are yet to incorporate it into our implementation. Our joint-execution
based MIndiGolog planner is therefore currently limited to offline
execution planning.


\subsection{Reasonable Joint Executions\label{sec:JointExec:Reasonable}}

While joint executions can clearly provide a powerful formal account
of execution planning for asynchronous multi-agent domains, in their
current form they are not suitable for an effective implementation.
The difficulty arises from the definition of $History(ex,br,h)$,
which due to the partial ordering on events can generate an exponentially-large
number of possible histories. To verify that a joint execution is
legal, the planner needs to examine each of these histories individually.

To overcome this difficulty and produce an effective implementation,
we identify a restricted class of joint executions in which all possible
histories of a branch are provably equivalent. Such executions can
be reasoned about using the canonical ordering over events, rather
than having to enumerate each possible distinct history.


\subsubsection{Independent Actions}

To construct families of situation terms that are all equivalent,
we need a way to identify \emph{independent actions.} Intuitively,
we want independent actions to be able to be performed in either order,
or even concurrently, without affecting what holds in the resulting
situation, or the preconditions or outcomes of each action. This section
formally identifies the conditions that independent actions must satisfy.

For simplicity, we identify actions that are independent regardless
of the situation they are performed in. Let us assume that the theory
of action $\Dt$ is equipped with a rigid predicate $indep(a,a')$
identifying actions that are independent. We identify sets of mutually-independent
actions with this simple definition:\[
mIndep(c)\isdef\forall a,a':\, a\in c\wedge a'\in c\,\rightarrow\, indep(a,a')\]
 We then restrict the theory of action to satisfy the following conditions:

{[}{Independent~Actions}{]} A theory of action $\Dt$ correctly
specifies independent actions when it contains a rigid predicate $indep(a,a')$
and entails the following, where $\mathcal{F}$ is a meta-variable
ranging over fluents:\label{def:Independent-Actions} 
\begin{enumerate}
\item $\Dt\,\models\, indep(a,a')\equiv indep(a',a)$ 
\item $\Dt\,\models\, Legal(\{a\},s)\equiv Legal(\{a\},do(\{a'\},s))$ 
\item $\Dt\,\models\, Out(\{a\},s)=Out(\{a\},do(\{a'\},s))$ 
\item $\Dt\,\models\,\mathcal{F}(do(\{a\},do(\{a'\},s)))\equiv\mathcal{F}(do(\{a'\},do(\{a\},s)))$ 
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(Legal(c,s)\equiv\,\forall a\in c:\, Legal(\{a\},s)\right)$ 
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\left(o\in Out(c,s)[agt]\equiv\exists a\in c:\, o\in Out(\{a\},s)[agt]\right)$ 
\item $\Dt\,\models\, mIndep(c)\,\rightarrow\,\forall a\in c:\left(\,\mathcal{F}(do(c,s))\equiv\mathcal{F}(do(\{a\},do(c-\{a\},s)))\right)$ 
\end{enumerate}
The first restriction simply ensures that independence is symmetrical.
The next three restrictions ensure that independent actions do not
interfere with each other's preconditions, outcomes or effects. The
final three restrictions ensure that there is no interference between
preconditions, outcomes or effects when independent actions are performed
concurrently.

The following theorems are direct consequences of correctly specifying
independent actions; indeed, they are the motivation for the restrictions
in Definition \ref{def:Independent-Actions}.

Let $h$ and $h'$ be two histories of the same length, containing
the same action\#outcome pairs, and differing only by transposition
of $(\{a\}\#y)$ and $(\{a'\}\#y')$. If $indep(a,a')$ holds, then
$h$ is legal if and only if $h'$ is legal.\label{thm:Indep-Trans-Equiv} 

Let $h_{p}$ be the common prefix of these histories and $h_{s}$
the common suffix:\begin{gather*}
h\,=\, h_{s}\cdot(\{a\}\#y)\cdot(\{a'\}\#y')\cdot h_{p}\\
h'\,=\, h_{s}\cdot(\{a'\}\#y')\cdot(\{a\}\#y)\cdot h_{p}\end{gather*}


By restrictions 2 and 3 from Definition \ref{def:Independent-Actions},
we have:\begin{gather*}
Legal(\{a\},Sit(h_{p}))\,\equiv\, Legal(\{a\},Sit((\{a'\}\#y')\cdot h_{p}))\\
Out(\{a\},Sit(h_{p}))\,=\, Out(\{a\},Sit((\{a'\}\#y')\cdot h_{p}))\end{gather*}


And vice-versa. If $h_{s}$ is empty, this is sufficient to establish
$Legal(h)$ iff $Legal(h')$ as desired. Alternately, suppose $h_{s}$
contains $n$ items, then we can apply regression $n$ times to state
the legality of the $h_{s}$ component as a uniform formula evaluated
at $Sit((\{a\}\#y)\cdot(\{a'\}\#y')\cdot h_{p})$. By restriction
4, whether this formula holds will be unaffected by the order of $\{a\}$
and $\{a'\}$ and we have the equivalence as desired. 

Let $h$ and $h'$ be two histories that differ only by the concurrent
execution of adjacent mutually-independent actions, and the corresponding
agent-wise union of their outcomes. Then $h$ is legal iff $h'$ is
legal.\label{thm:Indep-Conc-Equiv} 

Assume that the histories differ by concurrent execution of a single
action. Let $h_{p}$ be the common prefix of these histories and $h_{s}$
the common suffix:\begin{gather*}
h\,=\, h_{s}\cdot(\{a\}\#y)\cdot(\{c\}\#y')\cdot h_{p}\\
h'\,=\, h_{s}\cdot(c\cup\{a\}\#y'')\cdot h_{p}\end{gather*}


Furthermore, we're given that:\begin{gather*}
agt\#o\in y''\,\equiv\, o\in y[agt]\vee\, o\in y'[agt]\\
mIndep(c\cup\{a\})\end{gather*}


By mutual independence, and restrictions 2 and 5, we have: \begin{gather*}
Legal(\{a\},Sit((\{c\}\#y')\cdot h_{p}))\,\equiv\, Legal(\{a\},Sit(h_{p}))\\
Legal(c\cup\{a\},Sit(h_{p}))\,\equiv\, Legal(\{a\},Sit(h_{p}))\wedge\forall a'\in c:\, Legal(\{a'\},Sit(h_{p}))\end{gather*}


Similarly for outcomes, using restrictions 3 and 6:\begin{gather*}
Out(\{a\},Sit((\{c\}\#y')\cdot h_{p}))\,=\, Out(\{a\},Sit(h_{p}))\\
o\in Out(c\cup\{a\},Sit(h_{p}))[agt]\,\equiv o\in\left(Out(\{a\},Sit(h_{p}))\cup Out(c,Sit(h_{p}))\right)[agt]\end{gather*}


This is sufficient to establish $Legal(h)$ iff $Legal(h')$ if $h_{s}$
is empty. Alternately, suppose $h_{s}$ contains $n$ items, then
we can apply regression $n$ times to state the legality of the $h_{s}$
component as a uniform formula evaluated at $Sit((c\cup\{a\}\#y'')\cdot h_{p})$.
By restriction 7, whether this formula holds will be unaffected if
$\{a\}$ is executed separately, and we have the equivalence as desired.

If the histories differ by concurrent execution of more than a single
action, we can simply unfold them into a sequence of histories differing
by only one action, with each being legal iff its adjacent history
is legal. 

Note that we make no attempt to derive action independence from the
theory of action, but simply assume an appropriate predicate $indep(a,a')$
is available for the purposes of planning. This predicate need not
identify \emph{all} independent actions, although the more actions
that can be identified as independent, the better for our implementation.


\subsubsection{Reasonability}

We can now define a \emph{reasonabl}e joint execution as one in which
every pair of action events is either ordered, in conflict, or independent:

{[}{Reasonable~Joint~Execution}{]} A joint execution is reasonable
if it satisfies the following restriction:\begin{multline*}
\Dt\,\models\,\forall i,j\in events(ex):\, IsAction(lbl(ex,i))\wedge IsAction(lbl(ex,j))\\
\rightarrow\, i\prec_{ex}j\,\vee\, j\prec_{ex}i\,\vee\, i\oplus_{ex}j\,\vee\, indep(lbl(ex,i),lbl(ex,j))\end{multline*}


We call such executions {}``reasonable'' because a planner can reason
about then effectively, using the unique canonical history of each
leaf rather than enumerating every individual history.

Let $ex$ be a reasonable joint execution, then:\begin{multline*}
\Dt\cup\Dt_{je}\,\models\,\forall lf:\, Leaf(ex,lf)\,\rightarrow\,\\
\left[Legal(ex,lf)\,\equiv\,\exists h:\, CHistory(ex,lf,h)\,\wedge\, Legal(h)\right]\end{multline*}


By definition, a leaf is legal if every possible history of that leaf
is legal, so the \emph{if} direction is trivial. For the \emph{only-if}
direction, assume that the canonical history of the leaf if legal.
The histories of a leaf can differ only by the ordering or concurrent
execution of unordered action events, and all unordered action events
in a reasonable execution are independent. Therefore every history
of the leaf differs from the canonical history by transposition or
concurrent execution of independent action events. So if the canonical
history is legal, by Theorems \ref{thm:Indep-Trans-Equiv} and \ref{thm:Indep-Conc-Equiv}
we have legality of every history and hence legality of the leaf as
required. 

This result is key to our implementation of a MIndiGolog execution
planner based on joint executions - by restricting its search to reasonable
executions, it can verify the legality of each leaf by querying the
legality of the canonical leaf history, which can be done using standard
regression techniques.

We thus trade completeness for efficiency in our implementation. There
can certainly be non-reasonable joint executions that are valid plans
of execution according to equation \eqref{eq:JE-Plan-Defn}, but it
is computationally too expensive to search for them in practice.


\subsection{Implementation\label{sec:JointExec:Implementation}}

We have modified our MIndiGolog execution planner from Chapter \ref{ch:mindigolog}
to perform offline execution planning and generate a joint execution
rather than a raw situation term. For details on obtaining the full
source code see Appendix \ref{ch:implementation}; for the full axiomatisation
of observability in our example domain see Appendix \ref{ch:cookingagents}.

As mentioned in Section \ref{sec:JointExec:JEs}, Figure \ref{fig:JE:MakeSalad1}
shows the output of our planner when run on the $MakeSalad$ program
from Chapter \ref{ch:mindigolog}. Since all actions in this execution
have a single outcome, the outcome events have been suppressed for
brevity.

In the cooking agents domain, actions are independent if they deal
with different objects. As seen in Figure \ref{fig:JE:MakeSalad1},
the use of a partial order structure facilitates independent execution
between the agents, with each processing a different ingredient and
only synchronising on the availability of the required resources.
This execution provides the maximum potential for concurrency given
the resource constraints of the domain, and is clearly a significant
improvement over totally ordered sequences of actions as produced
by the earlier MIndiGolog planner.

However, the simple $MakeSalad$ program does not demonstrate a key
feature of joint executions: branching. Consider instead the program
$MakeSalad2$ shown in Figure \ref{fig:MIndiGolog:MakeSalad2}. In
this case the agents are unsure whether there are any eggs available,
so the sensing action $checkFor$ is required. If there are eggs then
they should make an egg salad, otherwise they should make the standard
vegetable salad. Note that since lettuce appears in both dishes, they
are permitted to begin processing that ingredient before checking
for the eggs.

%
\begin{figure}
\begin{centering}
\framebox{%
\parbox[t]{0.85\columnwidth}{%
\begin{gather*}
\mathbf{proc}\, MakeSalad2(dest)\\
\left[\,\,\,\pi(agt,ChopTypeInto(agt,Lettuce,dest))\,||\right.\\
\left.ChopEggOrVeg(dest)\,\,\,\,\right]\,;\\
\pi(agt,\left[acquire(agt,dest)\,;\,\right.\\
beginTask(agt,mix(dest,1))\,;\\
endTask(agt,mix(dest,1))\,;\\
\left.\, release(agt,dest)\right])\,\,\mathbf{end}\\
\\\\\mathbf{proc}\, ChopEggOrVeg(dest)\\
\pi(agt,\, checkFor(agt,Egg))\,;\\
\mathbf{if}\\
\exists e:\, IsType(e,Egg)\wedge\neg Used(e)\\
\mathbf{then}\\
\left[\pi(agt,ChopTypeInto(agt,Egg,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Cheese,dest))\right]\\
\mathbf{else}\\
\left[\pi(agt,ChopTypeInto(agt,Carrot,dest))\,||\right.\\
\left.\pi(agt,ChopTypeInto(agt,Tomato,dest))\right]\,;\\
\mathbf{endif}\,\,\mathbf{end}\end{gather*}
 %
}} 
\par\end{centering}

\caption{A Golog program for making Egg or Veg Salad\label{fig:MIndiGolog:MakeSalad2}}

\end{figure}


The joint execution found by our implementation for $MakeSalad2$
is shown in Figure \ref{fig:JE:MakeSalad2-Exec}. The event nodes
in this diagram are colour-coded into three groups: white nodes can
occur independently of the sensing results from $checkFor$; light-grey
nodes can only occur if $checkFor$ returns false; dark-grey nodes
can only occur if $checkFor$ returns true.

%
\begin{figure}
\framebox{%
\begin{minipage}[t]{0.97\columnwidth}%
\begin{center}
\textsf{\textbf{\tiny \includegraphics[scale=0.25,bb = 0 0 200 100, draft, type=eps]{/storage/pgrad/writings/thesis/listings/jointexec/salad2_plan.eps}}}{\tiny {}} 
\par\end{center}%
\end{minipage}}

\caption{Joint Execution for the $MakeSalad2$ program}


\label{fig:JE:MakeSalad2-Exec} 
\end{figure}


We see from this joint execution that $Joe$ can indeed prepare the
lettuce without needing to know whether eggs are available. $Jim$
is assigned to check for the eggs, and acquires either an egg or a
tomato depending on the outcome of his sensing action. Importantly,
$Jon$ has to wait until $Jim$ acquires his ingredient before he
knows whether to process the cheese, or the carrot. This is due to
him being unable to directly observe the outcome of the $checkFor$
action.

Again, there is a significant amount of independence between agents
in this execution. They do not need to be able to observe the private
processing actions such as $chop$ and $mix$, and only need to synchronise
their actions when they come to $release$/$acquire$ the shared resources.
By basing branching and synchronisation directly on the observations
made by each agent, joint executions allow us to capture this kind
of rich branching and partial-order structure while ensuring that
the agents can still feasibly execute the plan based solely on their
local information.

In the following sections we highlight some key aspects of our implementation.


\subsubsection{Program Steps}

The $Trans$ predicate of MIndiGolog is modified to generate \emph{steps}
instead of constructing a new situation term. These are records that
describe not only the next action to perform, but also meta-data about
that action's role in the overall program. Step records have the following
attributes.
\begin{itemize}
\item action: the action performed in that step, or $nil$ if it is an internal
program transition 
\item test: an additional fluent formula that must hold immediately before
performing the step 
\item thread: a sequence of 'l' and 'r' characters indicating the concurrent
thread in which the step is performed 
\item outcome: the outcome of performing the action. 
\end{itemize}
Step records track the necessary information to determine whether
the program allows any given pair of actions to be performed independently.
A sequence of steps can be used as a history term in the obvious way,
taking only the actions and outcomes.

The thread-naming scheme used here is similar to that of \citep{fritz08congolog_sin_trans}.
Each time $Trans$ chooses to execute a step from the left-hand side
of a concurrency operator it appends an {}``l'' to the thread name,
and each time it chooses the right-hand side it appends an {}``r''.
If one step's thread name is a prefix of another step's thread name,
then those two steps must be performed in the order they are generated;
if not, they are steps from different threads and can potentially
be performed concurrently.

The procedure implementing $Trans$ takes a program and a history
as input, returning a new step of execution along with the remainder
of the program to be executed. The code below is representative of
this procedure:

\programinput{listings/jointexec/Trans.oz}

In particular, note that the evaluation of test conditions calls $Sitcalc.holds$
passing it the input history. This procedure performs standard regression-based
reasoning using a {}``just-in-time history'' assumption to handle
sensing results, in the same manner as standard IndiGolog \citep{giacomo99indigolog}.
The planner ensures that this is the canonical history of the leaf
that is being planned for, so we can be sure that the test will hold
in all possible histories of the leaf if it holds in the given history.

We say that two steps are \emph{ordered} if any of the following holds:
their action terms are not independent; one's thread is a prefix of
the other; one's action falsifies the test condition associated with
the other. When building a joint execution, ordered steps are forced
to be executed in the order they were generated by the planner, while
unordered steps may be performed independently and potentially concurrently.

Note that we no longer require a separate clause to handle true concurrency
in the $conc(D1\, D2)$ case, unlike the MIndiGolog implementation
from Chapter \ref{ch:mindigolog}. Rather, the potential for truly
concurrent execution is captured in the partial ordering of the joint
execution itself, which allows independent actions to be performed
concurrently while forcing non-independent actions to occur in a particular
order.


\subsubsection{Building Joint Executions}

Our implementation builds up joint executions by inserting one action
at a time, in much the same way that the standard Golog planning loop
builds up situation terms. The procedure $Insert$ is called with
the step object whose action is to be inserted, the leaf for which
it is a new program step, and a function $MustPrec$ that will be
used to determine the action's enablers.

\programinput{listings/jointexec/JointExec.oz}

The joint execution code enumerates all possible outcomes of the action
and inserts corresponding outcome events. This extends the input leaf
by the given action, and if the input leaf was legal, then one the
new leaves so generated is also guaranteed to be legal. The updated
joint execution is returned along with the new outcome events.

The call to $FixFeasibility$ ensures that the joint execution remains
feasible, by inserting additional action events if it discovers branches
that have identical views for the performing agent. Currently this
is done using a brute-force search through all possible histories,
but it is able to eliminate many branches quickly by first checking
whether they will always contain an incompatible observation.

When determining the enablers for a new action, the joint execution
code has potentially many choices, and generates choice points accordingly.
It processes all existing events on the leaf in turn, first checking
if they are \emph{orderable} according to the restrictions on feasible
joint executions. If they are orderable, the function $MustPrec$
is called to determine whether they must be \emph{ordered} according
to the semantics of the program. If they are orderable, but need not
be ordered, a choice point is generated.

\programinput{listings/jointexec/FindEnablers.oz}


\subsubsection{Planning Loop}

The main execution planning loop operates by extending a joint execution
one leaf at a time. At each iteration, the current state of the plan
is represented by the joint execution built so far, along with a list
of program\#history\#leaf tuples tracking each leaf in the joint execution.
The history here is the list of program steps performed on that leaf,
and also gives the canonical leaf history, while the program represents
what remains to execute on that leaf. The planning loop can only terminate
when every leaf has a program that is final in its canonical history.

The top-level procedure $Plan$ takes a program as input, and calls
$MakePlan$ with an empty joint execution and a single, empty leaf:

\programinput{listings/jointexec/Planner.oz}

$MakePlan$ is a recursive procedure implementing the planning loop.
Note that it cannot discard leaves or process them in isolation, since
extending one leaf with an action may cause actions to be added to
other leaves in order to maintain the feasibility restrictions.

\programinput{listings/jointexec/MakePlan.oz}

Each iteration of the planning loop proceeds as follows. First, it
searches for an \emph{open leaf,} one for which a terminating execution
of the program has not yet been found. If no open leaves are found,
planning can terminate. Otherwise, the procedure $FindTrans1$ is
called to find a new step of execution for that leaf. The action is
inserted into the joint execution, which returns a list of new leaves,
one for each possible outcome of the action. Each is added to the
list of leaves to be processed, and the loop repeats.

The procedure to find an open leaf must also deal with any new events
that were inserted into the joint execution to maintain its feasibility
invariants. The procedure $HandleExistingEvents$ rolls the leaf forward
to account for these new events, or fails if an event was added that
does not form part of a legal program execution.

\programinput{listings/jointexec/FindOpenBranch.oz}

Of particular interest is the procedure $FindTrans1$, which uses
the encapsulated search functionality of Mozart to yield possible
next steps according to an estimate of their potential for concurrency.
The procedure $LP.yieldOrdered$ yields the solutions of the given
search context, sorted using the procedure $CompareSteps$. This procedure
gives preference to steps that can be performed concurrently with
as many existing actions as possible.

\programinput{listings/jointexec/FindTrans1.oz}

This use of encapsulated search allows our implementation to find
highly concurrent executions, such as the one shown in Figure \ref{fig:JE:MakeSalad2-Exec}.


\subsection{Discussion\label{sec:JointExec:Discussion}}

In this chapter we have defined a \emph{joint execution} as a special
kind of prime event structure. We contend that such structures are
highly suitable for planning the actions to be performed by a team
of agents in service of some shared task, such as executing a shared
Golog program.

On one hand, joint executions are restricted enough to be practical
for such use. By restricting ourselves to \emph{reasonable} joint
executions, each leaf can be easily converted into a single history
term for the purposes of reasoning, and can be extended one action
at a time. This allows us to re-use much of the standard IndiGolog
reasoning machinery. By ensuring that the joint execution is \emph{feasible},
the agent are guaranteed to be able to carry it out in a purely reactive
fashion using only their local information.

Joint executions are also significantly more flexible than previous
approaches. They allow independent actions to be performed without
synchronisation, in any order. The agents need never know precisely
what actions have been executed, as long as their local observations
are sufficient to determine the next action to perform. Synchronisation
is automatically achieved when required by explicitly reasoning about
what actions each agent can observe, rather than requiring that all
actions be public.

To demonstrate the utility of these structures, we have implemented
a new version of our MIndiGolog interpreter that produces joint executions
as its output, and shown that the resulting executions can enable
significant independence among agents when cooperatively executing
the plan.\\


An alternate approach to coordinating concurrent execution in Golog-like
languages is the TeamGolog language developed in \citep{farinelli07team_golog},
where agents explicitly synchronise through communication and a shared
state. By contrast, our approach constructs synchronisation implicitly
by reasoning about the actions that can be observed by each agent.
This has the advantage of requiring no changes to the form or semantics
of the agents' control program, but the disadvantage that joint execution
construction may fail if too many actions are unobservable. It would
be interesting to combine these approaches by automatically incorporating
explicit communication when implicit synchronisation is not possible.

There is, of course, an extensive body of work on partial-order planning
in the context of goal-based planning. Unsurprisingly, the joint execution
structure we develop here has deep similarities to the structures
used in conditional partial-order planners such as \citep{peot92conditional_nonlinear}.
It is, however, intentionally specific to the situation calculus.
We make no use of many concepts common in partial-order goal-based
planning (causal links, threats, conflicts, etc) because we do not
deal explicitly with goals, but with steps generated by an underlying
transition semantics. Our approach can be considered roughly equivalent
to \emph{deordering} of a totally-ordered plan as described in \citep{backstrom99reordering};
we plan as if actions are performed in the specific order identified
by the canonical leaf history, but allow actions to be performed out-of-order
if they are independent.

Our use of a restrictive plan representation that branches directly
on the sensing results returned by actions has strong parallels with
the {}``robot programs'' of \citep{levesque96what_is_planning,levesque98what_robots_can_do},
but is significantly less expressive. In particular, joint executions
do not allow looping constructs and thus lack the universality of
general robot programs. It would be interesting to incorporate loops
in our structures, but how to do so if far from clear in the face
of partial observability. Indeed, producing iterative plans is still
an active area of research even in the single-agent case \citep{levesque05planning_with_loops}\\


By explicitly formalising the local perspective of each agent, we
have given an account of planning with coordination and feasibility
guarantees without needing to perform explicit epistemic reasoning.
On the one hand, this means we can implement a practical planning
system without concern for the computational difficulties involved
in epistemic reasoning. But this has also limited us to purely offline
planning, when each agent can reasonably be expected to have the same
knowledge about the domain.

As discussed in Section \ref{sec:JointExec:Planning}, extending the
use of joint executions for online execution in asynchronous domains
poses a significant challenge, and seems to require explicit reasoning
about knowledge and common knowledge. The remainder of this thesis
is devoted to developing the foundations of such a reasoning system,
by extending the standard account of epistemic reasoning in the situation
calculus to handle asynchronous domains.


\section{Conclusion}

\label{ch:conclusion}

This thesis has laid the foundations for cooperative execution in
asynchronous multi-agent domains in the situation calculus. As highlighted
by our initial investigations and implementation of the multi-agent
Golog variant MIndiGolog, the standard reasoning and planning machinery
of the situation calculus often depends on an assumption of synchronicity.
In many cases, this synchronicity is enforced by requiring all actions
to be publicly observable.

At the core of our approach to overcoming this limitation is a new,
explicit representation of the local perspective of each agent. By
formalising what each agent \emph{observes} when a particular set
of actions is performed, and its corresponding local \emph{view} in
each situation, we are able to approach reasoning and planning in
a principled way without making any assumptions about the dynamics
of the domain. In particular, we can explicitly define and represent
asynchronous domains as those in which some action occurrences generate
no observations; in other words, domains in which agents cannot determine
how many actions have been performed.

Our first key contribution defines a partially-ordered branching action
structure to replace raw situation terms as the output of the Golog
execution planning process. Called \emph{joint executions}, they represent
a set of many possible histories that could constitute a legal execution
of the program. They allow independent actions to be performed independently,
while ensuring that inter-agent synchronisation is always possible
when required. By formulating these requirements explicitly in terms
of the local view available to each agent, we identify joint executions
that are feasible to perform in the world despite potential asynchronicity
in the domain.

The utility of these structures was demonstrated by implementing an
offline execution planner that produces joint executions as its output.
By imposing some simple restrictions on the theory of action, the
planner is able to reason about joint executions without having to
explicitly consider the exponentially-many possible histories of such
a partially-ordered structure. It can thus make use of the standard
reasoning machinery of the situation calculus developed in existing
Golog implementations.\\


\appendix

\section{Extended Proofs}

Extended proofs go here, if we need any.


\section{Axioms for the {}``Cooking Agents''}

This appendix provides the axioms for the {}``cooking agents'' example
domain used in Sections \ref{ch:mindigolog} and \ref{ch:jointexec}.
While the different sections use slightly different variants of the
domain, the major details are unchanged between chapters.


\subsection*{Synchronous, completely-known}

In this domain there are three agents named $Jon$, $Jim$ and $Joe$:\[
\forall agt:\,\, agt=Jim\,\vee\, agt=Jon\,\vee\, agt=Joe\]


There are various types of ingredient and utensil, and types are represented
explicitly as terms such as $Lettuce$ and $Bowl.$ Individual objects
of these types are named e.g. $Lettuce1$, $Bowl2$: We have a rigid
predicate $ObjIsType(obj,typ)$ that relates these two sorts of object.
It is defined as the completion of the following clauses:\begin{gather*}
IsType(obj,Bowl)\,\rightarrow\, obj=Bowl1\,\vee\, obj=Bowl2\,\vee\, Bowl3\\
IsType(obj,Board)\,\rightarrow\, obj=Board1\,\vee\, obj=Board2\\
IsType(obj,Egg)\,\rightarrow\, Egg1\\
IsType(obj,Tomato)\,\rightarrow\, obj=Tomato1\,\vee\, obj=Tomato2\,\vee\, obj=Tomato3\\
IsType(obj,Lettuce)\,\rightarrow\, obj=Lettuce1\,\vee\, obj=Lettuce2\\
IsType(obj,Carrot)\,\rightarrow\, obj=Carrot1\,\vee\, obj=Carrot2\,\vee\, obj=Carrot3\\
IsType(obj,Cheese)\,\rightarrow\, obj=Cheese1\,\vee\, obj=Cheese2\end{gather*}


Different object super-types are identified using:\begin{gather*}
IsContainer(obj)\,\equiv\, IsType(obj,Bowl)\,\vee\, IsType(obj,Board)\\
IsIngredient(obj)\,\equiv\, IsType(obj,Egg)\,\vee\, IsType(obj,Lettuce)\,\vee\,\dots\end{gather*}


The available actions are $release$, $acquire$, $placeIn$, $transer$,
$mix$ and $chop$. 

We have the following fluents and successor state axioms. An ingredient
is used if the agent places it in some container:\begin{multline*}
Used(obj,do(c\#t,s))\,\equiv\, IsIngredient(obj)\\
\wedge\,\left(\exists agt,cnt:placeIn(agt,obj,cnt)\in c\right)\vee\, Used(obj,s)\end{multline*}


An agent has an object after he acquires it, and ceases to have it
when it is released or becomes used:\begin{multline*}
HasObject(agt,obj,do(c\#t,s))\,\equiv\, acquire(agt,obj)\in c\\
\vee HasObject(agt,obj,s)\,\wedge\neg\left(release(agt,obj)\in c\right.\\
\left.\vee IsIngredient(obj)\wedge\exists cnt:\, placeIn(agt,obj,cnt)\in c\right)\end{multline*}


The contents of a container is simply the set of things that have
been placed into it. For this simple example, we do not represent
the \emph{state} of those ingredients, e.g. mixed or chopped:\begin{multline*}
Contents(obj,cnts,do(c\#t,s))\,\equiv\,\left(\exists cnts_{n},cnts_{o}:\,\mathbf{NewConts}(obj,cnts_{n},c,s)\right.\\
\left.\wedge\, Contents(obj,cnts_{o},s)\wedge cnts=cnts_{n}\cup cnts_{o}\right)\\
\vee\,\,\left(cnts=\{\}\wedge\mathbf{LostContents}(obj,c)\right)\\
\vee\,\,\left(Contents(obj,cnts,s)\right.\wedge\\
\left.\neg(\exists cnts_{n},cnts_{o}:\,\mathbf{NewConts}(obj,cnts_{n},c,s)\vee\mathbf{LostContents}(obj,c)\right)\end{multline*}
 \begin{multline*}
\mathbf{NewConts}(obj,cnts,c,s)\,\equiv\,\exists agt,igr:\, placeIn(agt,igr,obj)\in c\wedge cnts=\{igr\}\\
\vee\,\,\exists agt,obj':\, transfer(agt,obj',obj)\in c\wedge Contents(obj',cbts,s)\end{multline*}
 \[
\mathbf{LostConts}(obj,c)\,\equiv\,\exists agt,obj':\, transfer(agt,obj,obj')\in c\]


An agent can be doing a long-running task, with time $t_{r}$ remaining
until completion. The rigid function $duration(tsk)$ gives the running
time of a task:\begin{multline*}
DoingTask(agt,tsk,t_{r},do(c\#t,s))\,\equiv\,\\
beginTask(agt,tsk)\in c\wedge t_{r}=duration(tsk)\\
\vee\exists t_{r}':\, DoingTask(agt,tsk,t_{r}',s)\wedge t_{r}=t_{r}'-t\wedge endTask(agt,tsk)\not\in c\end{multline*}


The possibility axioms for individual actions are:\[
Poss(acquire(agt,obj)\#t,s)\,\equiv\,\neg Used(obj)\,\wedge\,\neg\exists agt':\, HasObject(agt,obj,s)\]
 \[
Poss(release(agt,obj)\#t,s)\,\equiv\, HasObject(agt,obj,s)\]
 \[
Poss(placeIn(agt,obj,cnt)\#t,s)\,\equiv\, HasObject(agt,obj,s)\wedge HasObject(agt,cnt,s)\]
 \begin{multline*}
Poss(transfer(agt,cnt,cont')\#t,s)\,\equiv\\
\, HasObject(agt,cnt,s)\wedge HasObject(agt,cnt',s)\end{multline*}
 \begin{multline*}
Poss(beginTask(agt,tsk)\#t,s)\,\equiv\,\\
\exists cnt,t:\, tsk=mix(cnt,t)\wedge HasObject(agt,cnt,s)\wedge ObjIsType(cnt,Bowl)\\
\vee\exists cnt:\, tsk=chop(cnt)\wedge HasObject(agt,cnt,s)\wedge ObjIsType(cnt,Board)\end{multline*}
 \[
Poss(endTask(agt,tsk)\#t,s)\,\equiv\,\exists t_{r}:\, DoingTask(agt,tsk,t_{r},s)\wedge t=start(s)+t_{r}\]


Concurrent actions are possible if they are all individually possible
and no pair of action is in conflict:\[
Poss(c\#t,s)\,\equiv\,\forall a,a'\in c:\, Poss(a\#t,s)\wedge Poss(a'\#t,s)\wedge\neg Conflicts(a,a',s)\]


Actions conflict if they are performed by the same agent, or are attempts
to acquire the same resource:\begin{multline*}
Conflicts(a,a',s)\,\equiv\, actor(a)=actor(a')\\
\vee\,\exists agt,agt',obj:\, a=acquire(agt,obj)\wedge a'=acquire(agt',obj)\end{multline*}


Initially all containers are empty, no-one has any objects, and all
ingredients apart from possibly the egg are not used:\begin{gather*}
\forall cnt:\, IsContainer(cnt)\,\rightarrow\, Contents(cnt,\{\},S_{0})\\
\forall agt,obj:\,\neg HasObject(agt,obj,S_{0})\\
\forall igr:\, ObjIsType(igr,Egg)\,\vee\,\neg Used(igr,S_{0})\end{gather*}


These axioms suffice for the example domain used in Chapter \ref{ch:mindigolog}


\subsection*{Asynchronous, with sensing}

For Chapter \ref{ch:jointexec} we drop the temporal component, and
collapse the tasks $mix$ and $chop$ into primitive actions:\[
Poss(mix(agt,cnt),s)\,\equiv\, HasObject(agt,cnt,s)\wedge ObjIsType(cnt,Bowl)\]
 \[
Poss(chop(agt,cnt),s)\,\equiv\, HasObject(agt,cnt,s)\wedge ObjIsType(cnt,Board)\]


We introduce a sensing action $checkFor(agt,typ)$ which determines
whether all objects of that type are unused:\[
Poss(checkFor(agt,typ),s)\,\equiv\,\top\]
 \begin{multline*}
SR(checkFor(agt,typ),s)=r\,\equiv\,\\
\shoveright{r="T"\wedge\forall obj:\, ObjIsType(obj,typ)\rightarrow\neg Used(obj,s)}\\
\vee r="F"\wedge\exists obj:\, ObjIsType(obj,typ)\wedge Used(obj,s)\end{multline*}


We adopt the $CanObs/CanSense$ axioms for observability and make
all actions private except $acquire$ and $release$:\begin{multline*}
CanObs(agt,a,s)\,\equiv\, actor(a)=agt\,\vee\,\exists agt',obj:\, a=acquire(agt',obj)\\
\vee\,\exists agt',obj:\, a=release(agt',obj)\end{multline*}
 \[
CanSense(agt,a,s)\,\equiv\, actor(a)=agt\]


Finally, we identify independent actions as those that deal with different
objects, which much be axiomatised by enumerating the each possible
case. We will not present such an enumeration here.

These axioms suffice for the example domain in Chapter \ref{ch:jointexec}.



\bibliographystyle{theapa}
\bibliography{/storage/pgrad/library/references}

\end{document}
